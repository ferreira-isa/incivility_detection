Unnamed: 0,thread_id,email_id,email_code,email_body,previous_email_id,previous_email_code,previous_email_body,concat_body,author_name,author_email,author_role,is_first_author_thread,nr_characters,ratio_words_email_thread,ratio_words_email_comment,position_sentence_comment,position_sentence_thread,is_last_comment,time_start_to_email,time_email_to_end,time_previous_to_email,time_email_to_next
3,152625,157636,civil,"Thanks for the details. Initially i was sceptical of rst & once instead of hitting the fly, hit ""make htmldocs"" on the keyboard :), and the opinion about it was changed. It was easy to navigate through various docs & the realized that various topics (& many) were present (yes, it was there earlier also, but had to dive inside Documentation & search, while viewing the toplevel index.html made them standout). It was like earlier you had to go after docs, but now it was docs coming after you, that is my opinion. 
Later while fighting with memory-barriers.txt, felt that it might be good for it as well as to be in that company. And the readability as a text is not hurt as well. It was thought that rst conversion could be done quickly, but since this was my first attempt with rst, had to put some effort to get a not so bad output, even if this patch dies, i am happy to have learnt rst conversion to some extent. When one of the author of the original document objected, i felt it is better to backoff. But if there is a consensus, i will proceed.",156871,uncivil,"IMO symlinks are mostly ending in a mess, URLs are never stable. There is an object to handle such requirements. Take a look at intersphinx to see how it works:  Each Sphinx HTML build creates a file named objects.inv that contains a mapping from object names to URIs relative to the HTML sets root.  This means articles from external (like lwn articles) has to be recompiled. Not perfect, but a first solution. I really like them, factually valuable comments .. please express your concern so that we have a chance to move on. I think that's a pity. ","IMO symlinks are mostly ending in a mess, URLs are never stable. There is an object to handle such requirements. Take a look at intersphinx to see how it works:  Each Sphinx HTML build creates a file named objects.inv that contains a mapping from object names to URIs relative to the HTML sets root.  This means articles from external (like lwn articles) has to be recompiled. Not perfect, but a first solution. I really like them, factually valuable comments .. please express your concern so that we have a chance to move on. I think that's a pity.  Thanks for the details. Initially i was sceptical of rst & once instead of hitting the fly, hit ""make htmldocs"" on the keyboard :), and the opinion about it was changed. It was easy to navigate through various docs & the realized that various topics (& many) were present (yes, it was there earlier also, but had to dive inside Documentation & search, while viewing the toplevel index.html made them standout). It was like earlier you had to go after docs, but now it was docs coming after you, that is my opinion. 
Later while fighting with memory-barriers.txt, felt that it might be good for it as well as to be in that company. And the readability as a text is not hurt as well. It was thought that rst conversion could be done quickly, but since this was my first attempt with rst, had to put some effort to get a not so bad output, even if this patch dies, i am happy to have learnt rst conversion to some extent. When one of the author of the original document objected, i felt it is better to backoff. But if there is a consensus, i will proceed.",afzal mohammed,afzal.mohd.ma@gmail.com,0,1,1605,1.0,1.0,0.09090909090909091,0.045454545454545456,0,0.5,0.0,0.0,0.0
6,165231,165261,civil,"According to my comment on the other thread, this stands true in case the child is managed by runtime PM as well. Otherwise this looks good to me. How about adding an additional patch on top taking into account the ignore_children flag and folding that into the series, kind of as you also suggested? My point is, we might as well take the opportunity to fix this right away, don't you think?",165230,technical,"One of the limitations of pm_runtime_force_suspend/resume() is that if a parent driver wants to use these functions, all of its child drivers generally have to do that too because of the parent usage counter manipulations necessary to get the correct state of the parent during system-wide transitions to the working state (system resume). However, that limitation turns out to be artificial, so remove it.  Namely, pm_runtime_force_suspend() only needs to update the children counter of its parent (if there's is a parent) when the device can stay in suspend after the subsequent system resume transition, as that counter is correct already otherwise.  Now, if the parent's children counter is not updated, it is not necessary to increment the parent's usage counter in that case any more, as long as the children counters of devices are checked along with their usage counters in order to decide whether or not the devices may be left in suspend after the subsequent system resume transition.  Accordingly, modify pm_runtime_force_suspend() to only call pm_runtime_set_suspended() for devices whose usage and children counters are at the no references"" level (the runtime PM status of the device needs to be updated to ""suspended"" anyway in case this function is called once again for the same device during the transition under way), drop the parent usage counter incrementation from it and update pm_runtime_force_resume() to compensate for these changes. ","One of the limitations of the resume function is that if a parent driver wants to use these functions, all of its child drivers generally have to do that too because of the parent usage counter manipulations necessary to get the correct state of the parent during system-wide transitions to the working state (system resume). However, that limitation turns out to be artificial, so remove it.  Namely, pm_runtime_force_suspend() only needs to update the children counter of its parent (if there's is a parent) when the device can stay in suspend after the subsequent system resume transition, as that counter is correct already otherwise.  Now, if the parent's children counter is not updated, it is not necessary to increment the parent's usage counter in that case any more, as long as the children counters of devices are checked along with their usage counters in order to decide whether or not the devices may be left in suspend after the subsequent system resume transition.  Accordingly, the suspend function to only call this function for devices whose usage and children counters are at the no references"" level (the runtime PM status of the device needs to be updated to ""suspended"" anyway in case this function is called once again for the same device during the transition under way), drop the parent usage counter incrementation from it and update the resume function to compensate for these changes.  According to my comment on the other thread, this stands true in case the child is managed by runtime PM as well. Otherwise this looks good to me. How about adding an additional patch on top taking into account the ignore_children flag and folding that into the series, kind of as you also suggested? My point is, we might as well take the opportunity to fix this right away, don't you think?",Ulf Hansson,ulf.hansson@linaro.org,1,0,1807,1.0,1.0,0.25,0.25,0,0.0,1.0,0.0,0.0
9,167856,174594,civil,"No problem, at the beginning, I only wanted to enable the strict. Doing this involves that I have to remove pinctrl nodes for the pins which are going to be request through the gpiolib to avoid conflicts. These pins were configured with bias-pull-up. That's why I try to add the bias support. Thanks for the detailed answer about what you have in mind. Well, yes and not! As a consequence of enabling strict mode, I have to find another way to configure the pins. Yes, I have noticed this issue. Right, I have spotted some drivers to fix. I will try to handle the ones related to the platforms I am using.",174357,technical,"I think we need to think over what is a good way to share ownership of a pin.  Russell pointed me to a similar problem incidentally and I briefly looked into it: there are cases when several devices may need to hold the same pin.  Can't we just look up the associated gpio_chip from the GPIO range, and in case the pin is connected between the pin controller and the GPIO chip, then we allow the gpiochip to also take a reference?  I.e. in that case you just allow gpio_owner to proceed and take the pin just like with a non-strict controller. ","I think we need to think over what is a good way to share ownership of a pin.  Russell pointed me to a similar problem incidentally and I briefly looked into it: there are cases when several devices may need to hold the same pin.  Can't we just look up the associated gpio_chip from the GPIO range, and in case the pin is connected between the pin controller and the GPIO chip, then we allow the gpiochip to also take a reference?  I.e. in that case you just allow gpio_owner to proceed and take the pin just like with a non-strict controller.  No problem, at the beginning, I only wanted to enable the strict. Doing this involves that I have to remove pinctrl nodes for the pins which are going to be request through the gpiolib to avoid conflicts. These pins were configured with bias-pull-up. That's why I try to add the bias support. Thanks for the detailed answer about what you have in mind. Well, yes and not! As a consequence of enabling strict mode, I have to find another way to configure the pins. Yes, I have noticed this issue. Right, I have spotted some drivers to fix. I will try to handle the ones related to the platforms I am using.",Ludovic Desroches,ludovic.desroches@microchip.com,1,1,1150,1.0,1.0,0.1,0.1,0,0.15384615384615385,0.7692307692307693,0.0,0.0
11,168169,173259,civil,"Thanks a lot for all this work! It was long overdue and it is nice to see the project finally getting to an end, after passing into so many hands!
I am not sure I understand the purpose of this level here. As far as I understand, you only have per-engine control whether you want to enable CG or not. What you call BLCG and SLCG levels just mean ""don't use the boot values, but rather use our values (taken from nvidia)"". 
Now, here comes the nasty part: NVIDIA only ever validated the boot values (I guess they are extremely safe ones), and the optimised values (the ones coming from your patch 2, 3, and 4 along with the level 3. I think introducing a single parameter that controls both CG, PG, and automatic reclocking would be safer. For CG and PG, it would be a all-or-nothing (either boot values, or everything like nvidia). This message is a bit odd, whether we keep the notion of levels or not. Can you get rid of the mention of powergating given that this is not part of this patchset? If you agree with having a single enable bit for CG, then a simple: ""Clockgating status: (boot|optimized)"" would work perfectly. All this time, I thought these parameters were for power gating... I also did not expect that clock gating had to be disabled before we could program them.

Great find! Why introduce it? I can't find references to it in this patch (outside of the function below) or in the following patches. As you even export this function, it looks like you used to use this function in an earlier revision of this series.
Aside from all these nitpicks, the approach is quite self contained and I like the following patches. Well done! Once we settle on the configuration parameter, I can give you my R-b :smile:",173260,technical,"FWIW, SLCG stands for second level clock gating","FWIW, SLCG stands for second level clock gating Thanks a lot for all this work! It was long overdue and it is nice to see the project finally getting to an end, after passing into so many hands!
I am not sure I understand the purpose of this level here. As far as I understand, you only have per-engine control whether you want to enable CG or not. What you call BLCG and SLCG levels just mean ""don't use the boot values, but rather use our values (taken from nvidia)"". 
Now, here comes the nasty part: NVIDIA only ever validated the boot values (I guess they are extremely safe ones), and the optimised values (the ones coming from your patch 2, 3, and 4 along with the level 3. I think introducing a single parameter that controls both CG, PG, and automatic reclocking would be safer. For CG and PG, it would be a all-or-nothing (either boot values, or everything like nvidia). This message is a bit odd, whether we keep the notion of levels or not. Can you get rid of the mention of powergating given that this is not part of this patchset? If you agree with having a single enable bit for CG, then a simple: ""Clockgating status: (boot|optimized)"" would work perfectly. All this time, I thought these parameters were for power gating... I also did not expect that clock gating had to be disabled before we could program them.
Great find! Why introduce it? I can't find references to it in this patch (outside of the function below) or in the following patches. As you even export this function, it looks like you used to use this function in an earlier revision of this series.
Aside from all these nitpicks, the approach is quite self contained and I like the following patches. Well done! Once we settle on the configuration parameter, I can give you my R-b :smile:",Martin Peres,martin.peres@free.fr,0,0,1770,1.0,1.0,0.05,0.05,1,1.0,0.0,0.6,0.0
15,169133,179802,civil,"Sorry about being late, just returned home and am trying to get all the backlogs under control. I remember the PPP standard is a bit cloudy about the possible issue, but the latter indeed exists (the PPP state machine was written directly to STD-51). There is related (more visible in practice, though we aren't affected) issue of ""active"" vs ""passive"" mode (hdlc_ppp.c is ""active"", and two ""passives"" wouldn't negotiate at all). 
Anyway the problem is real (though not very visible in practice, especially on relatively modern links rather than 300 or 1200 bps dialup connections) and should be fixed. Looking at the patch, my first impression is it makes the code differ from STD-51 a little bit. On the other hand, perhaps applying it as is and forgetting about the issue is the way to go. Ideally, I think the negotiation failure should end up (optionally, in addition to the current behavior) in some configurable sleep, then the negotiation should restart. If it's worth the effort at this point, I don't know. Perhaps I could look at this later, but no promises (this requires pulling on and setting up some legacy hardware). Anyway, since the patch is safe and can solve an existing problem.",177642,uncivil,"Ok, I check the source code again. It have nothing to do with the interrupts, it is related how the hdlc.c is implemented. My case is the carrier always good, but protocol will fail due to perfect noise, and this issue was found and complained by our customers. So it is not my theory guessing, it is a real problem.","Ok, I check the source code again. It have nothing to do with the interrupts, it is related how the hdlc.c is implemented. My case is the carrier always good, but protocol will fail due to perfect noise, and this issue was found and complained by our customers. So it is not my theory guessing, it is a real problem. Sorry about being late, just returned home and am trying to get all the backlogs under control. I remember the PPP standard is a bit cloudy about the possible issue, but the latter indeed exists (the PPP state machine was written directly to STD-51). There is related (more visible in practice, though we aren't affected) issue of ""active"" vs ""passive"" mode (this file is ""active"", and two ""passives"" wouldn't negotiate at all). 
Anyway the problem is real (though not very visible in practice, especially on relatively modern links rather than 300 or 1200 bps dialup connections) and should be fixed. Looking at the patch, my first impression is it makes the code differ from STD-51 a little bit. On the other hand, perhaps applying it as is and forgetting about the issue is the way to go. Ideally, I think the negotiation failure should end up (optionally, in addition to the current behavior) in some configurable sleep, then the negotiation should restart. If it's worth the effort at this point, I don't know. Perhaps I could look at this later, but no promises (this requires pulling on and setting up some legacy hardware). Anyway, since the patch is safe and can solve an existing problem.",Krzysztof Halasa,khc@pm.waw.pl,1,0,1515,1.0,1.0,0.09090909090909091,0.023809523809523808,0,0.2972972972972973,0.6756756756756757,0.10810810810810811,0.24324324324324326
16,169133,193114,civil,"How  do you think my patch? As you see, Krzysztof  think my patch is ok to be accepted. But if you have a better idea to fix it,I am glad to see it. Anyway, this issue have to be fixed.
",179802,civil,"Sorry about being late, just returned home and am trying to get all the backlogs under control.  I remember the PPP standard is a bit cloudy about the possible issue, but the latter indeed exists (the PPP state machine was written directly to STD-51). There is related (more visible in practice, though we aren't affected) issue of active"" vs ""passive"" mode (hdlc_ppp.c is ""active"", and two ""passives"" wouldn't negotiate at all).  Anyway the problem is real (though not very visible in practice, especially on relatively modern links rather than 300 or 1200 bps dialup connections) and should be fixed. Looking at the patch, my first impression is it makes the code differ from STD-51 a little bit. On the other hand, perhaps applying it as is and forgetting about the issue is the way to go.  Ideally, I think the negotiation failure should end up (optionally, in addition to the current behavior) in some configurable sleep, then the negotiation should restart. If it's worth the effort at this point, I don't know.  Perhaps I could look at this later, but no promises (this requires pulling on and setting up some legacy hardware).  Anyway, since the patch is safe and can solve an existing problem: ","Sorry about being late, just returned home and am trying to get all the backlogs under control.  I remember the PPP standard is a bit cloudy about the possible issue, but the latter indeed exists (the PPP state machine was written directly to STD-51). There is related (more visible in practice, though we aren't affected) issue of active"" vs ""passive"" mode (this file is ""active"", and two ""passives"" wouldn't negotiate at all).  Anyway the problem is real (though not very visible in practice, especially on relatively modern links rather than 300 or 1200 bps dialup connections) and should be fixed. Looking at the patch, my first impression is it makes the code differ from STD-51 a little bit. On the other hand, perhaps applying it as is and forgetting about the issue is the way to go.  Ideally, I think the negotiation failure should end up (optionally, in addition to the current behavior) in some configurable sleep, then the negotiation should restart. If it's worth the effort at this point, I don't know.  Perhaps I could look at this later, but no promises (this requires pulling on and setting up some legacy hardware).  Anyway, since the patch is safe and can solve an existing problem:  How  do you think my patch? As you see, Krzysztof  think my patch is ok to be accepted. But if you have a better idea to fix it, I am glad to see it. Anyway, this issue have to be fixed.
",Denis Du,dudenis2000@yahoo.ca,0,1,1390,0.9314641744548287,1.0,0.06666666666666667,0.2857142857142857,0,0.5405405405405406,0.43243243243243246,0.24324324324324326,0.0
20,170193,188745,civil,"ok. ok, this is all new stuff to me ... I suppose I should do it also for all the other new files I create. But what is the license for the documentation? It's not code, so GPL seems wrong. Creative commons? I just noticed a patch for checkpatch.pl about SPDX and asked the same question there. ok. I'll move it to the Use section. I will add a reference to the selftest file. In practice it can also work as example. ok, the example route should be more explicative. thanks again for the review.",190492,technical,Thank you for the patch! Yet something to improve:,"Thank you for the patch! Yet something to improve: ok. ok, this is all new stuff to me ... I suppose I should do it also for all the other new files I create. But what is the license for the documentation? It's not code, so GPL seems wrong. Creative commons? I just noticed a patch for checkpatch.pl about SPDX and asked the same question there. ok. I'll move it to the Use section. I will add a reference to the selftest file. In practice it can also work as example. ok, the example route should be more explicative. thanks again for the review.",Igor Stoppa,igor.stoppa@huawei.com,0,1,547,1.0,1.0,0.7142857142857143,0.29411764705882354,0,0.23076923076923078,0.7692307692307693,0.0,0.0
30,180488,180837,civil,"Then, I am wondering why we are holding mmap_sem when calling migrate_pages() in existing code. Sorry, I missed that. If mmap_sem is not needed for migrate_pages(), please ignore this patch.",180546,technical,"This doesn't make much sense to me, to be honest. We are holding mmap_sem for _read_ so we allow parallel updates like page faults or unmaps. Therefore we are isolating pages prior to the migration.  The sole purpose of the mmap_sem in add_page_for_migration is to protect from vma going away _while_ need it to get the proper page.  Moving the lock up is just wrong because it allows caller to hold the lock for way too long if a lot of pages is migrated. Not only that, it is even incorrect because we are doing get_user() (aka page fault) and while read lock recursion is OK, we might block and deadlock when there is a writer pending. I haven't checked the current implementation of semaphores but I believe we do not allow recursive locking.","This doesn't make much sense to me, to be honest. We are holding this so we allow parallel updates like page faults or unmaps. Therefore we are isolating pages prior to the migration.  The sole purpose of this in add_page_for_migration is to protect from vma going away _while_ need it to get the proper page.  Moving the lock up is just wrong because it allows caller to hold the lock for way too long if a lot of pages is migrated. Not only that, it is even incorrect because we are getting the user (aka page fault) and while read lock recursion is OK, we might block and deadlock when there is a writer pending. I haven't checked the current implementation of semaphores but I believe we do not allow recursive locking. Then, I am wondering why we are holding this when calling migrate_pages in existing code. Sorry, I missed that. If it is not needed for migrate_pages, please ignore this patch.",Zi Yan,zi.yan@cs.rutgers.edu,0,0,900,1.0,1.0,0.3333333333333333,0.3333333333333333,0,0.0,0.0,0.0,0.0
31,183468,183472,civil,Thanks for testing this and letting me know.,183473,technical,"stable: 62 boots: 0 failed, 58 passed with 2 offline, 2 untried/unknown Full Boot Summary here. Full build summary here. For more info write here.","stable: 62 boots: 0 failed, 58 passed with 2 offline, 2 untried/unknown Full Boot Summary here. Full build summary here. For more info write here. Thanks for testing this and letting me know.",Greg Kroah-Hartman,gregkh@linuxfoundation.org,1,1,191,1.0,1.0,1.0,1.0,0,0.0,0.0,0.0,0.0
43,207400,207934,civil,"Cool. I would say this is done right. How about writing an i2c bus driver which sits directly on top of another i2c bus? Basically a one port i2c mux. The current mux code does not seem to directly allow it, since it calls i2c_transfer() directly on the parent, where as you want it to call your own i2c_transfer function. But maybe you could expended the core mux code to allow the i2c_mux_core structure to contain a transfer function?",207917,technical,"You didn't miss it - I probably need to explain it better.  The 'emulated devices' do respond on different slave addresses (which match one of or the only the slave addresses those parts support). For example the device-tree for the GW54xx has the following which are all from the GSC which is the only thing on i2c1 One issue I'm trying to figure out the best way to deal with is the fact that the GSC can 'NAK' transactions occasionally which is why I override the regmap read/write functions and provide retries. This resolves the issue for the mfd core driver and sub-module drivers but doesn't resolve the issue with these 'emulated devices' which have their own stand-alone drivers. I'm not sure how to best deal with that yet. I tried to add retires to the i2c adapter but that wasn't accepted upstream because it was too generic and I was told I need to work around it in device-drivers. I'm guessing I need to write my own sub-module drivers that will largely duplicate whats in the stand-alone drivers.""","You didn't miss it - I probably need to explain it better.  The 'emulated devices' do respond on different slave addresses (which match one of or the only the slave addresses those parts support). For example the device-tree for the GW54xx has the following which are all from the GSC which is the only thing on i2c1 One issue I'm trying to figure out the best way to deal with is the fact that the GSC can 'NAK' transactions occasionally which is why I override the regmap read/write functions and provide retries. This resolves the issue for the mfd core driver and sub-module drivers but doesn't resolve the issue with these 'emulated devices' which have their own stand-alone drivers. I'm not sure how to best deal with that yet. I tried to add retires to the i2c adapter but that wasn't accepted upstream because it was too generic and I was told I need to work around it in device-drivers. I'm guessing I need to write my own sub-module drivers that will largely duplicate whats in the stand-alone drivers."" Cool. I would say this is done right. How about writing an i2c bus driver which sits directly on top of another i2c bus? Basically a one port i2c mux. The current mux code does not seem to directly allow it, since it calls i2c_transfer() directly on the parent, where as you want it to call your own i2c_transfer function. But maybe you could expended the core mux code to allow the i2c_mux_core structure to contain a transfer function?",Andrew Lunn,andrew@lunn.ch,1,0,1451,1.0,1.0,0.16666666666666666,0.045454545454545456,0,0.0,0.0,0.0,0.0
44,207400,208102,civil,"thanks for the review! Ok. ok - will have this in v2. oops, did not mean to submit that. it was for original debugging and not needed - will remove this. Yes, that makes sense. I'll propose something like the following in v2.",208059,technical,There appears to be a few spaces vs tabs issues in this file.,"There appears to be a few spaces vs tabs issues in this file. thanks for the review! Ok. ok - will have this in v2. oops, did not mean to submit that. it was for original debugging and not needed - will remove this. Yes, that makes sense. I'll propose something like the following in v2.",Tim Harvey,tharvey@gateworks.com,1,1,287,0.22996515679442509,1.0,0.14285714285714285,0.7727272727272727,0,0.0,0.0,0.0,0.0
45,207400,208141,civil,"No, at this point it requires both I2C and OF. I may add platform data to support an older non-device-tree family of boards but it still would require I2C. I will remove this. Thanks for catching that.",208102,civil," thanks for the review!   ok   ok - will have this in v2. oops, did not mean to submit that   it was for original debugging and not needed - will remove   Yes, that makes sense. I'll propose something like the following in. right - thanks!   I am using this with thread_fn with thread_fn (vs handler).  Do you mean why use a work procedure? I guess I don't need that and can call input_report_key directly from the irq.   ok. can you point me to an example dts/driver? "," thanks for the review!   ok   ok - will have this in v2. oops, did not mean to submit that   it was for original debugging and not needed - will remove   Yes, that makes sense. I'll propose something like the following in. right - thanks!   I am using this with thread_fn with thread_fn (vs handler).  Do you mean why use a work procedure? I guess I don't need that and can call input_report_key directly from the irq.   ok. can you point me to an example dts/driver?  No, at this point it requires both I2C and OF. I may add platform data to support an older non-device-tree family of boards but it still would require I2C. I will remove this. Thanks for catching that.",Tim Harvey,tharvey@gateworks.com,1,1,671,0.49477351916376305,1.0,0.3333333333333333,0.6363636363636364,0,0.0,0.0,0.0,0.0
46,207400,208159,civil,"Thanks for the review! oops - left that in by mistake. It has 16x ADC channels where some can be temperatures and others can be voltage inputs (based on device tree). understood - a much cleaner pattern. right - removed. yikes - thanks for catching that. ok. yes, that static arrays are not very forward-thinking and yes my arrays are not consistent. I'll convert to dynamically allocating the channels for v2. right - certainly an issue. will do. will add validation. ok. Do you mean stuffing a u32 into a u8? will fix. will fix. will do this. It could also return -EINVAL but not with the args I'm passing in so I'll change it to this. Thanks!",208144,technical,Thanks. I'll run through checkpatch prior to v2.,"Thanks. I'll run through checkpatch prior to v2. Thanks for the review! oops - left that in by mistake. It has 16x ADC channels where some can be temperatures and others can be voltage inputs (based on device tree). understood - a much cleaner pattern. right - removed. yikes - thanks for catching that. ok. yes, that static arrays are not very forward-thinking and yes my arrays are not consistent. I'll convert to dynamically allocating the channels for v2. right - certainly an issue. will do. will add validation. ok. Do you mean stuffing a u32 into a u8? will fix. will fix. will do this. It could also return -EINVAL but not with the args I'm passing in so I'll change it to this. Thanks!",Tim Harvey,tharvey@gateworks.com,1,1,694,0.5296167247386759,1.0,0.16666666666666666,0.7727272727272727,0,0.0,0.0,0.0,0.0
50,216128,216133,civil,"Sorry for being dense. What tree is this against? I can't find mention of amdcz in Linus's tree nor linux-next. Where does that get used where it isn't defined? (i.e. why is the #ifdef needed here?) Otherwise, sure, sounds good. :smile:",216131,technical,"The old_serial_port global array in 8250_core is supposed to hold an entry for each serial port on the system that cannot be discovered via a standard enumeration mechanism (aka these).  The array is populated at compile-time from the value specified in the SERIAL_PORT_DFNS macro. This macro is defined in arch/serial.h.  For x86, this macro is currently unconditionally initialized to supply four ioport UARTs.  However, not all x86 CPUs have these four ioport UARTs.  For example, the UARTs on AMD Carrizo and later are separate memory mapped Designware IP blocks.  Fairly early in boot the console_initcall univ8250_console_init iterates over this array and installs these old UARTs into the global array serial8250_ports.  Further, it attempts to register them for use as the console.  In other words, if, for example, the kernel commandline has console=ttyS0, the console will be switched over to one of these non-existent UARTs.  Only later, when the real UART drivers are probed and their devices are instantiated will the console switch back over to the proper UART.  This is noticeable when using earlycon, since part of the serial console log will appear to disappear (when the bogus old takes over) and then re-appear (when the real UART finally gets registered for the console).  The problem is even more noticable when *not* using earlycon, since in this case the entire console output is missing, having been incorrectly played back to the non-existing serial port.  Create a global variable to allow skipping old serial port initialization and wire it up to the quirk and the special amdcz earlycon setup handler.  ","The old serial port global array in 8250_core is supposed to hold an entry for each serial port on the system that cannot be discovered via a standard enumeration mechanism (aka these).  The array is populated at compile-time from the value specified in the serial port macro. This macro is defined in arch/serial.h.  For x86, this macro is currently unconditionally initialized to supply four ioport UARTs.  However, not all x86 CPUs have these four ioport UARTs.  For example, the UARTs on AMD Carrizo and later are separate memory mapped Designware IP blocks.  Fairly early in boot the console init call universal console iterates over this array and installs these old UARTs into the global array serial ports.  Further, it attempts to register them for use as the console.  In other words, if, for example, the kernel commandline has this condition, the console will be switched over to one of these non-existent UARTs.  Only later, when the real UART drivers are probed and their devices are instantiated will the console switch back over to the proper UART.  This is noticeable when using earlycon, since part of the serial console log will appear to disappear (when the bogus old takes over) and then re-appear (when the real UART finally gets registered for the console).  The problem is even more noticable when *not* using earlycon, since in this case the entire console output is missing, having been incorrectly played back to the non-existing serial port.  Create a global variable to allow skipping old serial port initialization and wire it up to the quirk and the special amdcz earlycon setup handler.   Sorry for being dense. What tree is this against? I can't find mention of amdcz in Linus's tree nor linux-next. Where does that get used where it isn't defined? (i.e. why is the #ifdef needed here?) Otherwise, sure, sounds good. :smile:",Kees Cook,keescook@chromium.org,1,0,1857,1.0,1.0,0.1111111111111111,0.1,0,0.0,1.0,0.0,0.0
51,216128,216130,civil,"Can you possibly send the entire series again and CC all patches to linux-acpi
and fix the kbuild warnings if the are relevant for that matter?",216132,technical,"Thank you for the patch! Yet something to improve:  if your patch is applied to the wrong git tree, please drop us a note to help improve the system.","Thank you for the patch! Yet something to improve:  if your patch is applied to the wrong git tree, please drop us a note to help improve the system. Can you possibly send the entire series again and CC all patches to linux-acpi and fix the kbuild warnings if the are relevant for that matter?",Rafael J. Wysocki,rjw@rjwysocki.net,1,0,293,0.1671309192200557,1.0,0.5,0.9,1,1.0,0.0,0.25,0.0
54,222860,230472,civil,"Can you add a commit message explaining why you add a specific defconfig for this board. FYI, previously, the same defconfig was used for all STM32F7 boards. You will also need to resync with the last master branch regarding defconfig content.",224687,technical,Does this use driver model? I cannot see it.,"Does this use driver model? I cannot see it. Can you add a commit message explaining why you add a specific defconfig for this board. FYI, previously, the same defconfig was used for all boards. You will also need to resync with the last master branch regarding defconfig content.",Patrice CHOTARD,patrice.chotard@st.com,0,0,280,1.0,1.0,0.3333333333333333,0.06666666666666667,0,1.0,0.0,0.6,0.0
55,230843,231058,civil,"This is indeed guaranteed. For FTRACE use case. If it's being called from FTRACE in run time, this would mean there were long calls in this module section, which in turn means, get_module_plt() was called at least once for this module and this section. This doesn't hold in general, though. In any case, if you insist, I can try to rework the whole stuff implementing module_finalize().",231041,technical,"Right, ok. That's a problem.  This means that you are relying on get_module_plt() being called at least once at module load time, which is not guaranteed.  Instead, you should set this member (and perhaps the entire prealloc routine) in a module_finalize() implementation.","Right, ok. That's a problem.  This means that you are relying on get_module being called at least once at module load time, which is not guaranteed.  Instead, you should set this member (and perhaps the entire prealloc routine) in a module_finalize implementation. This is indeed guaranteed. For FTRACE use case. If it's being called from FTRACE in run time, this would mean there were long calls in this module section, which in turn means, get_module was called at least once for this module and this section. This doesn't hold in general, though. In any case, if you insist, I can try to rework the whole stuff implementing this function.",Alexander Sverdlin,alexander.sverdlin@nokia.com,1,1,641,1.0,1.0,0.2,0.2,0,0.0,1.0,0.0,0.0
56,231231,232204,civil,So make it fit by returning an unsigned int.,232201,technical,"There is no limit on CPU equivalence table length in this patch series like it was in the previous version.  The maximum possible value returned by install_equiv_cpu_table() of comes from the maximum value of this 'size' variable (that is UINT_MAX) plus the header length of CONTAINER_HDR_SZ. This won't fit in 'int' type, hence this patch.  That's because this functions tells its caller how much bytes to skip from the beginning of a microcode container file to the first patch section contained in it.","There is no limit on CPU equivalence table length in this patch series like it was in the previous version.  The maximum possible value returned by install_equiv_cpu_table of comes from the maximum value of this 'size' variable (that is UINT_MAX) plus the header length of the container. This won't fit in 'int' type, hence this patch.  That's because this functions tells its caller how much bytes to skip from the beginning of a microcode container file to the first patch section contained in it. So make it fit by returning an unsigned int.",Borislav Petkov,bp@alien8.de,1,0,544,1.0,1.0,0.5,0.5,0,1.0,0.0,0.0,0.0
59,239101,240572,civil,"Thank you so much for many style, formatting and other issues fixes and also for integration of 'check_at_most_once' patch, it saved me several review iterations. Regarding free of sg in two error paths, you were correct. I fixed it by placing several error labels to differentiate each handling. I also noted that reqdata_arr[b].req was not released properly, this is also fixed. following is a diff of my fix based on your modifications. (I can send it in a patch format, but it doesn't include a fix for Eric Biggers comments) I took your modifications and working upon it.",240255,uncivil,"They've been dropped.  BUT please do note that the patches I pushed to linux-dm.git were rebased ontop of the 'check_at_most_once' patch.  I never did get an answer about how the sg array is free'd in certain error paths (see FIXME:"" in the 2nd patch).  Also, I fixed some issues I saw in error paths, and lots of formatting.  I'll be pretty frustrated if you submit v2 that is blind to the kinds of changes I made.  I'll send you a private copy of the patches just so you have them for your reference.""","They've been dropped.  BUT please do note that the patches I pushed to linux-dm.git were rebased ontop of the 'check_at_most_once' patch.  I never did get an answer about how the sg array is free'd in certain error paths (see FIXME:"" in the 2nd patch).  Also, I fixed some issues I saw in error paths, and lots of formatting.  I'll be pretty frustrated if you submit v2 that is blind to the kinds of changes I made.  I'll send you a private copy of the patches just so you have them for your reference."" Thank you so much for many style, formatting and other issues fixes and also for integration of 'check_at_most_once' patch, it saved me several review iterations. Regarding free of sg in two error paths, you were correct. I fixed it by placing several error labels to differentiate each handling. I also noted that this was not released properly, this is also fixed. following is a diff of my fix based on your modifications. (I can send it in a patch format, but it doesn't include a fix for Eric Biggers comments) I took your modifications and working upon it.",Unkown Name,yael.chemla@foss.arm.com,0,0,1066,1.0,1.0,0.16666666666666666,0.07692307692307693,0,0.06666666666666667,0.9333333333333333,0.0,0.9333333333333333
61,245912,245953,civil,"The driver is looking good!

It looks like you've done some kind of review that we weren't allowed
to see, which is a double edged sword - I might be asking about things
that you've already spoken about with someone else.

I'm only just learning about PECI, but I do have some general comments below.


I think just saying ASPEED PECI support is enough. That way if the
next ASPEED SoC happens to have PECI we don't need to update all of
the help text :)


Nit: we use ASPEED instead of AST in the upstream kernel to distingush
from the aspeed sdk drivers. If you feel strongly about this then I
won't insist you change.


I know these come from the ASPEED sdk driver. Do we need them all?


Could the above use regmap_read_poll_timeout instead?


That looks like an endian swap. Can we do something like this?

 regmap_write(map, reg, cpu_to_be32p((void *)msg->tx_buff))


Having #defines is frowned upon. I think print_hex_dump_debug will do
what you want here.


I find this hard to read. Use a few more lines to make it clear what
your code is doing.

Actually, the entire for loop is cryptic. I understand what it's doing now. Can you rework it to make it more readable? You follow a similar pattern above in the write case. 
Given the regmap_read is always going to be a memory read on the aspeed, I can't think of a situation where the read will fail.
On that note, is there a reason you are using regmap and not just accessing the hardware directly? regmap imposes a number of pointer lookups and tests each time you do a read or write. 
Again, a memory mapped read won't fail. How about we check that the regmap is working once in your _probe() function, and assume it will continue working from there (or remove the regmap abstraction all together). All of this code is for debugging only. Do you want to put it behind some kind of conditional? We have a framework for doing clocks in the kernel. Would it make sense to write a driver for this clock and add it to this?
The property is optional so I suggest we don't print a message if it's not present. We certainly don't want to print a message saying ""invalid"". The same comment applies to the other optional properties below. Can we probe in parallel? If not, putting a sleep in the _probe will hold up the rest of drivers from being able to do anything, and hold up boot. 
If you decide that you do need to probe here, please add a comment. (This is the wait for the clock to be stable?). This interrupt is only for the peci device. Why is it marked as shared?",245922,uncivil,"Is this include needed?   Please use bool.  I am quite completely missing how the two functions above are different.   There is a lot of duplication in those functions. Would it be possible to find common code and use functions for it instead of duplicating everything several times ?   What if nothing is found ?   FWIW, it might be better to pass channel - DEFAULT_CHANNEL_NUMS as parameter.  What if find_core_index() returns this, ie if it didn't find a core ?   This attribute should not exist.   lcrit is tcontrol - tjmax, and crit_hyst above is tjmax - tcontrol ? How does this make sense ?   Am I missing something, or is the same temperature reported several times ? tjmax is also reported as temp_crit cputemp_read_die(), for example.   There is again a lot of duplication in those functions.   Can this be made less magic with some defines ?   Does this mean there will be an error message for each non-supported CPU ? Why ?   -ENODEV is not an error, and should not result in an error message. Besides, the error can also be propagated from peci core code, and may well be something else.   Then what ? Shouldn't this result in probe deferral or something more useful instead of just being ignored ?   FWIW, this should be two separate patches.   Needed?  It might make sense to provide the duplicate functions in a core file.   This again looks like duplicate code.   Please handle error cases first.   More duplicate code.   One set of brackets is unnecessary on each side of the expression.   Why is this invalid"", and why does it warrant an error message ?   Is priv->addr guaranteed to be this?  Or the peci command failed.?","Is this include needed?   Please use bool.  I am quite completely missing how the two functions above are different.   There is a lot of duplication in those functions. Would it be possible to find common code and use functions for it instead of duplicating everything several times ?   What if nothing is found ?   FWIW, it might be better to pass channel as parameter.  What if find_core_index returns this, ie if it didn't find a core ?   This attribute should not exist.  How does this make sense ?   Am I missing something, or is the same temperature reported several times ? tjmax is also reported as temp_crit cputemp_read_die(), for example.   There is again a lot of duplication in those functions.   Can this be made less magic with some defines ?   Does this mean there will be an error message for each non-supported CPU ? Why ?   -ENODEV is not an error, and should not result in an error message. Besides, the error can also be propagated from peci core code, and may well be something else. Then what ? Shouldn't this result in probe deferral or something more useful instead of just being ignored ?   FWIW, this should be two separate patches. Needed?  It might make sense to provide the duplicate functions in a core file.   This again looks like duplicate code.   Please handle error cases first. More duplicate code. One set of brackets is unnecessary on each side of the expression.   Why is this invalid"", and why does it warrant an error message?   Is this guaranteed to be this?  Or the peci command failed.? The driver is looking good!
It looks like you've done some kind of review that we weren't allowed to see, which is a double edged sword - I might be asking about things that you've already spoken about with someone else.
I'm only just learning about PECI, but I do have some general comments below. I think just saying ASPEED PECI support is enough. That way if the next ASPEED SoC happens to have PECI we don't need to update all of the help text :smile:
we use ASPEED instead of AST in the upstream kernel to distingush from the aspeed sdk drivers. If you feel strongly about this then I won't insist you change.
I know these come from the ASPEED sdk driver. Do we need them all? Could the above use timeout instead? That looks like an endian swap. Can we do something like this? Having #defines is frowned upon. I think debug will do.
what you want here. I find this hard to read. Use a few more lines to make it clear what your code is doing.
Actually, the entire for loop is cryptic. I understand what it's doing now. Can you rework it to make it more readable? You follow a similar pattern above in the write case.  Given the regmap_read is always going to be a memory read on the aspeed, I can't think of a situation where the read will fail.
On that note, is there a reason you are using regmap and not just accessing the hardware directly? regmap imposes a number of pointer lookups and tests each time you do a read or write. 
Again, a memory mapped read won't fail. How about we check that the regmap is working once in your _probe() function, and assume it will continue working from there (or remove the regmap abstraction all together). All of this code is for debugging only. Do you want to put it behind some kind of conditional? We have a framework for doing clocks in the kernel. Would it make sense to write a driver for this clock and add it to this?
The property is optional so I suggest we don't print a message if it's not present. We certainly don't want to print a message saying ""invalid"". The same comment applies to the other optional properties below. Can we probe in parallel? If not, putting a sleep in the _probe will hold up the rest of drivers from being able to do anything, and hold up boot. 
If you decide that you do need to probe here, please add a comment. (This is the wait for the clock to be stable?). This interrupt is only for the peci device. Why is it marked as shared?",Joel Stanley,joel@jms.id.au,1,0,3948,1.0,1.0,0.02702702702702703,0.013513513513513514,0,0.0,1.0,0.0,0.0
65,258997,259513,civil,I'm really sorry for this. could you please illustrate me what the kconfig & warning is? I didn't get such warnings from 0-day.,259457,uncivil,"Pulled, and then immediately unpulled again.  The code causes new compiler warnings, and the warnings are valid.  If people don't care enough about their code to even check the warnings, I'm not going to waste one second pulling the resulting garbage. It's that simple.","Pulled, and then immediately unpulled again.  The code causes new compiler warnings, and the warnings are valid.  If people don't care enough about their code to even check the warnings, I'm not going to waste one second pulling the resulting garbage. It's that simple. I'm really sorry for this. could you please illustrate me what the kconfig & warning is? I didn't get such warnings from 0-day.",Zhang Rui,rui.zhang@intel.com,1,1,397,0.8723404255319149,1.0,0.3333333333333333,0.07142857142857142,0,0.0,0.75,0.0,0.0
68,258997,260193,civil,I'm not the one that added this switch statement (it has been there since 2011) and I would be happy to remove it.  However could we please defer this to v4.17 and merge the current set of Exynos thermal fixes/cleanups (they simplify the driver a lot and make ground for future changes)?,260189,uncivil,The init function is making sure cal_type is one or another. Can you fix it correctly by replacing the 'switch' by a 'if' instead of adding dead branches to please gcc?,The init function is making sure cal_type is one or another. Can you fix it correctly by replacing the 'switch' by a 'if' instead of adding dead branches to please gcc? I'm not the one that added this switch statement (it has been there since 2011) and I would be happy to remove it.  However could we please defer this to v4.17 and merge the current set of Exynos thermal fixes/cleanups (they simplify the driver a lot and make ground for future changes)?,Bartlomiej Zolnierkiewicz,b.zolnierkie@samsung.com,1,0,456,1.0,1.0,0.3333333333333333,0.2857142857142857,0,0.5,0.25,0.0,0.0
70,259276,259489,civil,"Thanks for your reply :smile:
I admit I am not familiar with this driver. I did not know this driver is only loaded during system boot-up time, I thought this driver can be loaded as a kernel module (like many drivers) after system booting. After knowing this, I admit my patch is not proper, sorry...",259487,technical,"James is right, You have added all usleep_range() during system boot-up  time. During boot-up system will run as single threaded. Where this change will not make much sense. System first priority is match the exact timing on each and every boot-up.  ","James is right, You have added all usleep_range() during system boot-up  time. During boot-up system will run as single threaded. Where this change will not make much sense. System first priority is match the exact timing on each and every boot-up.   Thanks for your reply :smile:
I admit I am not familiar with this driver. I did not know this driver is only loaded during system boot-up time, I thought this driver can be loaded as a kernel module (like many drivers) after system booting. After knowing this, I admit my patch is not proper, sorry...",Jia-Ju Bai,baijiaju1990@gmail.com,0,1,552,1.0,1.0,0.3333333333333333,0.125,1,0.0,0.0,0.0,0.0
74,266017,266029,civil,"Well, I am not sure. Could you please give me hints, how to debug this further? Is there some debug flag? I am only aware of the Ftrace framework, but in my experience it also skews the timings quite a bit, so might not be the best choice.",266025,uncivil,What actually took so long?  Could you analyze further instead of blindly putting the flag?,"What actually took so long?  Could you analyze further instead of blindly putting the flag? Well, I am not sure. Could you please give me hints, how to debug this further? Is there some debug flag? I am only aware of the Ftrace framework, but in my experience it also skews the timings quite a bit, so might not be the best choice.",Paul Menzel,pmenzel+alsa-devel@molgen.mpg.de,0,1,331,1.0,1.0,0.25,0.14285714285714285,0,0.0,1.0,0.0,0.0
76,266279,266331,civil,I see I've missed some obvious things that you've pointed out here. I'll mark these warnings as False Positives and take your points into account for the analysis of the rest of the Spectre issues reported by Smatch. Sorry for the noise and thanks for the feedback.,266313,uncivil,"Please enlighten me: how do you think this could be exploited?  When an application calls this from a video0 device, it will just enumerate a hardware functionality, with is constant for a given hardware piece.  The way it works is that userspace do something like:   in order to read an entire const table.  Usually, it doesn't require any special privilege to call this ioctl, but, even if someone changes its permission to 0x400, a simple lsusb output is enough to know what hardware model is there. A lsmod or cat /proc/modules) also tells that the tm6000 module was loaded, with is a very good hint that the tm6000 is there or was there in the past.  In the specific case of tm6000, all hardware supports exactly the same formats, as this is usually defined per-driver. So, a quick look at the driver is enough to know exactly what the ioctl would answer.  Also, the net is full of other resources that would allow anyone to get the supported formats for a piece of hardware.  Even assuming that the OS doesn't have lsusb, that /proc is not mounted, that video0 require special permissions, that the potential attacker doesn't have physical access to the equipment (in order to see if an USB board is plugged), etc... What possible harm he could do by identifying a hardware feature?  Similar notes for the other patches to drivers/media in this series: let's not just start adding bloatware where not needed.  Please notice that I'm fine if you want to submit potential Spectre variant 1 fixups, but if you're willing to do so, please provide an explanation about the potential threat scenarios that you're identifying at the code.  Dan,  It probably makes sense to have somewhere at smatch a place where we could explicitly mark the false-positives, in order to avoid use to receive patches that would just add an extra delay where it is not needed.""","Please enlighten me: how do you think this could be exploited?  When an application calls this from a video0 device, it will just enumerate a hardware functionality, with is constant for a given hardware piece.  The way it works is that userspace do something like:   in order to read an entire const table.  Usually, it doesn't require any special privilege to call this ioctl, but, even if someone changes its permission to 0x400, a simple lsusb output is enough to know what hardware model is there. A lsmod or cat /proc/modules) also tells that the tm6000 module was loaded, with is a very good hint that the tm6000 is there or was there in the past.  In the specific case of tm6000, all hardware supports exactly the same formats, as this is usually defined per-driver. So, a quick look at the driver is enough to know exactly what the ioctl would answer.  Also, the net is full of other resources that would allow anyone to get the supported formats for a piece of hardware.  Even assuming that the OS doesn't have lsusb, that /proc is not mounted, that video0 require special permissions, that the potential attacker doesn't have physical access to the equipment (in order to see if an USB board is plugged), etc... What possible harm he could do by identifying a hardware feature?  Similar notes for the other patches to drivers/media in this series: let's not just start adding bloatware where not needed.  Please notice that I'm fine if you want to submit potential Spectre variant 1 fixups, but if you're willing to do so, please provide an explanation about the potential threat scenarios that you're identifying at the code.  Dan,  It probably makes sense to have somewhere at smatch a place where we could explicitly mark the false-positives, in order to avoid use to receive patches that would just add an extra delay where it is not needed."" I see I've missed some obvious things that you've pointed out here. I'll mark these warnings as False Positives and take your points into account for the analysis of the rest of the Spectre issues reported by Smatch. Sorry for the noise and thanks for the feedback.",Gustavo A. R. Silva,gustavo@embeddedor.com,0,1,2123,1.0,1.0,0.3333333333333333,0.037037037037037035,0,0.0,1.0,0.0,0.0
77,266279,266334,civil,"Please, drop this series. Further analysis is required as it seems all these are False Positives. Sorry for the noise.",266331,civil,I see I've missed some obvious things that you've pointed out here. I'll  mark these warnings as False Positives and take your points into account  for the analysis of the rest of the Spectre issues reported by Smatch.  Sorry for the noise and thanks for the feedback.,"I see I've missed some obvious things that you've pointed out here. I'll  mark these warnings as False Positives and take your points into account  for the analysis of the rest of the Spectre issues reported by Smatch.  Sorry for the noise and thanks for the feedback. Please, drop this series. Further analysis is required as it seems all these are False Positives. Sorry for the noise.",Gustavo A. R. Silva,gustavo@embeddedor.com,0,1,387,0.18333333333333332,1.0,0.3333333333333333,0.14814814814814814,0,0.0,1.0,0.0,0.0
78,266279,267299,civil,"Thanks for a comprehensive explanation about that. It now makes more sense to me. Yeah, better to apply a fix to avoid the issue with VIDIOC_ENUM_FMT.  Btw, on almost all media drivers, the implementation for enumerating the supported formats are the same (and we have a few other VIDOC_ENUM_foo ioctls that usually do similar stuff): the V4L2 core calls a driver, with looks into an array, returning the results to the core.
So, a fix like that should likely go to almost all media drivers (there are a lot of them!), and, for every new one, to take care to avoid introducing it again during patch review process.
So, I'm wondering if are there any way to mitigate it inside the core itself, instead of doing it on every driver, e. g. changing v4l_enum_fmt() implementation at v4l2-ioctl. Ok, a ""poor man"" approach would be to pass the array directly to the core and let the implementation there to implement the array fetch logic, calling array_index_nospec() there, but I wonder if are there any other way that won't require too much code churn.",266764,technical,"Just had a better look at v4l_fill_fmtdesc() and actually read the comment. The code cannot be compiled as a array because it is big and sparse. But the log(n) condition tree is a prime candidate for the branchscope side-channel, which would be able to reconstruct a significant number of bits of the original value. A denser tree gives more bits etc.","Just had a better look at the function and actually read the comment. The code cannot be compiled as a array because it is big and sparse. But the log(n) condition tree is a prime candidate for the branchscope side-channel, which would be able to reconstruct a significant number of bits of the original value. A denser tree gives more bits etc. Thanks for a comprehensive explanation about that. It now makes more sense to me. Yeah, better to apply a fix to avoid the issue with this.  Btw, on almost all media drivers, the implementation for enumerating the supported formats are the same (and we have a few other functions that usually do similar stuff): the V4L2 core calls a driver, with looks into an array, returning the results to the core.
So, a fix like that should likely go to almost all media drivers (there are a lot of them!), and, for every new one, to take care to avoid introducing it again during patch review process.
So, I'm wondering if are there any way to mitigate it inside the core itself, instead of doing it on every driver, e. g. changing v4l_enum_fmt() implementation at v4l2-ioctl. Ok, a ""poor man"" approach would be to pass the array directly to the core and let the implementation there to implement the array fetch logic, calling array_index_nospec() there, but I wonder if are there any other way that won't require too much code churn.",Mauro Carvalho Chehab,mchehab@kernel.org,1,0,1371,0.6857142857142857,1.0,0.125,0.25925925925925924,0,0.037037037037037035,0.9629629629629629,0.0,0.0
79,266918,267111,civil,"please don't submit such a huge number of patches all at one time. Also, please fix the indentation of the functions whose arguments span multiple lines as has been pointed out to you in patch feedback. Finally, make this a true patch series.  It is so much easier for maintainers to work with a set of changes all doing the same thing if you make them a proper patch series with an appropriate ""[PATCH 0/N] ..."" header posting.",266918,technical,"The method ndo_start_xmit() is defined as returning an 'netdev_tx_t', which is a typedef for an enum type, but the implementation in this driver returns an 'int'.  Fix this by returning 'netdev_tx_t' in this driver too.","The method is defined as returning this, which is a typedef for an enum type, but the implementation in this driver returns an 'int'.  Fix this by returning this in this driver too. please don't submit such a huge number of patches all at one time. Also, please fix the indentation of the functions whose arguments span multiple lines as has been pointed out to you in patch feedback. Finally, make this a true patch series.  It is so much easier for maintainers to work with a set of changes all doing the same thing if you make them a proper patch series with an appropriate patch header posting.",David Miller,davem@davemloft.net,1,0,598,1.0,1.0,0.16666666666666666,0.07142857142857142,0,0.0,1.0,0.0,1.0
83,289026,291846,civil,"One of the basic questions/concerns I have is accounting for surplus huge pages in the default memory resource controller.  The existing huegtlb resource controller already takes hugetlbfs huge pages into account, including surplus pages.  This series would allow surplus pages to be accounted for in the default  memory controller, or the hugetlb controller or both. 
I understand that current mechanisms do not meet the needs of the above use case.  The question is whether this is an appropriate way to approach the issue.  My cgroup experience and knowledge is extremely limited, but it does not appear that any other resource can be controlled by multiple controllers.  Therefore, I am concerned that this may be going against basic cgroup design philosophy.
It would be good to get comments from people more cgroup knowledgeable, and especially from those involved in the decision to do separate hugetlb control.",291684,technical,That looks a lot better. Thanks for giving it a go.,"That looks a lot better. Thanks for giving it a go. One of the basic questions/concerns I have is accounting for surplus huge pages in the default memory resource controller.  The existing huegtlb resource controller already takes hugetlbfs huge pages into account, including surplus pages.  This series would allow surplus pages to be accounted for in the default  memory controller, or the hugetlb controller or both. 
I understand that current mechanisms do not meet the needs of the above use case.  The question is whether this is an appropriate way to approach the issue.  My cgroup experience and knowledge is extremely limited, but it does not appear that any other resource can be controlled by multiple controllers.  Therefore, I am concerned that this may be going against basic cgroup design philosophy.
It would be good to get comments from people more cgroup knowledgeable, and especially from those involved in the decision to do separate hugetlb control.",Mike Kravetz,mike.kravetz@oracle.com,1,0,970,0.22440944881889763,1.0,0.125,0.01818181818181818,0,0.5,0.5,0.0,0.0
84,289026,292549,civil,"I am sorry that I didn't join the discussion for the previous version but time just didn't allow that. So sorry if I am repeating something already sorted out. There was a deliberate decision to keep hugetlb and ""normal"" memory cgroup controllers separate. Mostly because hugetlb memory is an artificial memory subsystem on its own and it doesn't fit into the rest of memcg accounted memory very well. I believe we want to keep that status quo.
Well such a usecase requires an explicit configuration already. Either by using special wrappers or modifying the code. So I would argue that you have quite a good knowlege of the setup. If you need a greater flexibility then just do not use hugetlb at all and rely on THP. I do not really think this is a good idea. We really do not want to make the current hugetlb code more complex than it is already. The current hugetlb cgroup controller is simple and works at least somehow. I would not add more on top unless there is a _really_ strong usecase behind. Please make sure to describe such a usecase in details before we even start considering the code.
Well, then I would argue that you shouldn't use 64kB pages for your setup or allow THP for smaller sizes. Really hugetlb pages are by no means a substitute here.",292515,technical,"Thank you for your feedback. That makes sense, surplus hugepages are charged to both memcg and hugetlb cgroup, which may be contrary to cgroup design philosophy.  Based on the above advice, I have considered the following improvements, what do you think about?  The 'charge_surplus_hugepages' of v2 patch-set was an option to switch whether to charge memcg in addition to hugetlb cgroup"", but it will be abolished. Instead, change to ""switch only to memcg instead of hugetlb cgroup"" option. This is called 'surplus_charge_to_memcg'.  The surplus_charge_to_memcg option is created in per hugetlb cgroup. If it is false(default), charge destination cgroup of various page types is the same as the current kernel version. If it become true, hugetlb cgroup stops accounting for surplus hugepages, and memcg starts accounting instead.  A table showing which cgroups are charged.  I stared at the commit log of mm/hugetlb_cgroup.c, but it did not seem to have specially considered of surplus hugepages. Later, I will send a mail to hugetlb cgroup's committer to ask about surplus hugepages charge specifications. ","Thank you for your feedback. That makes sense, surplus hugepages are charged to both memcg and hugetlb cgroup, which may be contrary to cgroup design philosophy.  Based on the above advice, I have considered the following improvements, what do you think about?  The 'charge_surplus_hugepages' of v2 patch-set was an option to switch whether to charge memcg in addition to hugetlb cgroup"", but it will be abolished. Instead, change to ""switch only to memcg instead of hugetlb cgroup"" option. This is called 'surplus_charge'.  The surplus_charge option is created in per hugetlb cgroup. If it is false(default), charge destination cgroup of various page types is the same as the current kernel version. If it become true, hugetlb cgroup stops accounting for surplus hugepages, and memcg starts accounting instead.  A table showing which cgroups are charged.  I stared at the commit log of this file, but it did not seem to have specially considered of surplus hugepages. Later, I will send a mail to hugetlb cgroup's committer to ask about surplus hugepages charge specifications.  I am sorry that I didn't join the discussion for the previous version but time just didn't allow that. So sorry if I am repeating something already sorted out. There was a deliberate decision to keep hugetlb and ""normal"" memory cgroup controllers separate. Mostly because hugetlb memory is an artificial memory subsystem on its own and it doesn't fit into the rest of memcg accounted memory very well. I believe we want to keep that status quo.
Well such a usecase requires an explicit configuration already. Either by using special wrappers or modifying the code. So I would argue that you have quite a good knowlege of the setup. If you need a greater flexibility then just do not use hugetlb at all and rely on THP. I do not really think this is a good idea. We really do not want to make the current hugetlb code more complex than it is already. The current hugetlb cgroup controller is simple and works at least somehow. I would not add more on top unless there is a _really_ strong usecase behind. Please make sure to describe such a usecase in details before we even start considering the code.
Well, then I would argue that you shouldn't use 64kB pages for your setup or allow THP for smaller sizes. Really hugetlb pages are by no means a substitute here.",Michal Hocko,mhocko@kernel.org,1,0,2343,0.5958005249343832,1.0,0.05555555555555555,0.14545454545454545,0,0.6666666666666666,0.3333333333333333,0.0,0.0
86,289026,294078,civil,"I apologize for having confused. The hugetlb pages obtained from the pool do not waste the buddy pool. On the other hand, surplus hugetlb pages waste the buddy pool. Due to this difference in property, I thought it could be distinguished.
Although my memcg knowledge is extremely limited, memcg is accounting for various kinds of pages obtained from the buddy pool by the task belonging to it. I would like to argue that surplus hugepage has specificity in terms of obtaining from the buddy pool, and that it is specially permitted charge requirements for memcg.
It seems very strange that charge hugetlb page to memcg, but essentially it only charges the usage of the compound page obtained from the buddy pool, and even if that page is used as hugetlb page after that, memcg is not interested in that.
I will completely apologize if my way of thinking is wrong. It would be greatly appreciated if you could mention why we can not charge surplus hugepages to memcg. I could not understand the intention of this question, sorry. When resize the pool, I think that the number of surplus hugepages in use does not change. Could you explain what you were concerned about?",294072,technical,"Thank you for your time.  I do not know if it is really a strong use case, but I will explain my motive in detail. English is not my native language, so please pardon my poor English.  I am one of the developers for software that managing the resource used from user job at HPC-Cluster with Linux. The resource is memory mainly. The HPC-Cluster may be shared by multiple people and used. Therefore, the memory used by each user must be strictly controlled, otherwise the user's job will runaway, not only will it hamper the other users, it will crash the entire system in OOM.  Some users of HPC are very nervous about performance. Jobs are executed while synchronizing with MPI communication using multiple compute nodes. Since CPU wait time will occur when synchronizing, they want to minimize the variation in execution time at each node to reduce waiting times as much as possible. We call this variation a noise.  THP does not guarantee to use the Huge Page, but may use the normal page. This mechanism is one cause of variation(noise).  The users who know this mechanism will be hesitant to use THP. However, the users also know the benefits of the Huge Page's TLB hit rate performance, and the Huge Page seems to be attractive. It seems natural that these users are interested in HugeTLBfs, I do not know at all whether it is the right approach or not.  At the very least, our HPC system is pursuing high versatility and we have to consider whether we can provide it if users want to use HugeTLBfs.  In order to use HugeTLBfs we need to create a persistent pool, but in our use case sharing nodes, it would be impossible to create, delete or resize the pool.  One of the answers I have reached is to use HugeTLBfs by overcommitting without creating a pool(this is the surplus hugepage).  Surplus hugepages is hugetlb page, but I think at least that consuming buddy pool is a decisive difference from hugetlb page of persistent pool. If nr_overcommit_hugepages is assumed to be infinite, allocating pages for surplus hugepages from buddy pool is all unlimited even if being limited by memcg. In extreme cases, overcommitment will allow users to exhaust the entire memory of the system. Of course, this can be prevented by the hugetlb cgroup, but even if we set the limit for memcg and hugetlb cgroup respectively, as I asked in the first mail(set limit to 10GB), the control will not work.  I thought I could charge surplus hugepages to memcg, but maybe I did not have enough knowledge about memcg. I would like to reply to another mail for details.   Actually, I am opposed to the 64KB page, but the proposal to change the page size is expected to be dismissed as a problem. ","Thank you for your time.  I do not know if it is really a strong use case, but I will explain my motive in detail. English is not my native language, so please pardon my poor English.  I am one of the developers for software that managing the resource used from user job at HPC-Cluster with Linux. The resource is memory mainly. The HPC-Cluster may be shared by multiple people and used. Therefore, the memory used by each user must be strictly controlled, otherwise the user's job will runaway, not only will it hamper the other users, it will crash the entire system in OOM.  Some users of HPC are very nervous about performance. Jobs are executed while synchronizing with MPI communication using multiple compute nodes. Since CPU wait time will occur when synchronizing, they want to minimize the variation in execution time at each node to reduce waiting times as much as possible. We call this variation a noise.  THP does not guarantee to use the Huge Page, but may use the normal page. This mechanism is one cause of variation(noise).  The users who know this mechanism will be hesitant to use THP. However, the users also know the benefits of the Huge Page's TLB hit rate performance, and the Huge Page seems to be attractive. It seems natural that these users are interested in HugeTLBfs, I do not know at all whether it is the right approach or not.  At the very least, our HPC system is pursuing high versatility and we have to consider whether we can provide it if users want to use HugeTLBfs.  In order to use HugeTLBfs we need to create a persistent pool, but in our use case sharing nodes, it would be impossible to create, delete or resize the pool.  One of the answers I have reached is to use HugeTLBfs by overcommitting without creating a pool(this is the surplus hugepage).  Surplus hugepages is hugetlb page, but I think at least that consuming buddy pool is a decisive difference from hugetlb page of persistent pool. If number of overcommited hugepages is assumed to be infinite, allocating pages for surplus hugepages from buddy pool is all unlimited even if being limited by memcg. In extreme cases, overcommitment will allow users to exhaust the entire memory of the system. Of course, this can be prevented by the hugetlb cgroup, but even if we set the limit for memcg and hugetlb cgroup respectively, as I asked in the first mail(set limit to 10GB), the control will not work.  I thought I could charge surplus hugepages to memcg, but maybe I did not have enough knowledge about memcg. I would like to reply to another mail for details.   Actually, I am opposed to the 64KB page, but the proposal to change the page size is expected to be dismissed as a problem.  I apologize for having confused. The hugetlb pages obtained from the pool do not waste the buddy pool. On the other hand, surplus hugetlb pages waste the buddy pool. Due to this difference in property, I thought it could be distinguished.
Although my memcg knowledge is extremely limited, memcg is accounting for various kinds of pages obtained from the buddy pool by the task belonging to it. I would like to argue that surplus hugepage has specificity in terms of obtaining from the buddy pool, and that it is specially permitted charge requirements for memcg.
It seems very strange that charge hugetlb page to memcg, but essentially it only charges the usage of the compound page obtained from the buddy pool, and even if that page is used as hugetlb page after that, memcg is not interested in that.
I will completely apologize if my way of thinking is wrong. It would be greatly appreciated if you could mention why we can not charge surplus hugepages to memcg. I could not understand the intention of this question, sorry. When resize the pool, I think that the number of surplus hugepages in use does not change. Could you explain what you were concerned about?",TSUKADA Koutaro,tsukada@ascade.co.jp,0,1,3860,1.0,1.0,0.08333333333333333,0.45454545454545453,0,1.0,0.0,0.0,0.0
87,289026,271213,civil,"As you said, my patch did not consider handling when manipulating the pool. And even if that handling is done well, it will not be a valid reason to charge surplus hugepage to memcg. I understood the concept of memcg. As you said, it must be an alien. Thanks to the interaction up to here, I understood that my solution is inappropriate. I will look for another way. Thank you for your kind explanation.",294650,technical,"Note.  You do not want to use THP because THP does not guarantee"".   Using hugetlbfs overcommit also does not provide a guarantee.  Without doing much research, I would say the failure rate for obtaining a huge page via THP and hugetlbfs overcommit is about the same.  The most difficult issue in both cases will be obtaining a ""huge page"" number of pages from the buddy allocator.  I really do not think hugetlbfs overcommit will provide any benefit over THP for your use case.  Also, new user space code is required to ""fall back"" to normal pages in the case of hugetlbfs page allocation failure.  This is not needed in the THP case. ","Note.  You do not want to use THP because THP does not guarantee"".   Using hugetlbfs overcommit also does not provide a guarantee.  Without doing much research, I would say the failure rate for obtaining a huge page via THP and hugetlbfs overcommit is about the same.  The most difficult issue in both cases will be obtaining a ""huge page"" number of pages from the buddy allocator.  I really do not think hugetlbfs overcommit will provide any benefit over THP for your use case.  Also, new user space code is required to ""fall back"" to normal pages in the case of hugetlbfs page allocation failure.  This is not needed in the THP case.  As you said, my patch did not consider handling when manipulating the pool. And even if that handling is done well, it will not be a valid reason to charge surplus hugepage to memcg. I understood the concept of memcg. As you said, it must be an alien. Thanks to the interaction up to here, I understood that my solution is inappropriate. I will look for another way. Thank you for your kind explanation.",TSUKADA Koutaro,tsukada@ascade.co.jp,0,1,1040,0.2782152230971129,1.0,0.25,0.6909090909090909,0,1.0,0.0,0.0,0.0
88,289431,289688,civil,"I'm not sure I understand what you intend here. If __sync_blockdev fails, then the error should have already been marked in this (via patch #6). We wouldn't want to record that again at syncfs time. Note that __sync_blockdev will return errors based on the legacy flags. We really do need to record it in the superblock as soon as possible after an error occurs. If we want to allow userland to eventually be able to scrape this value out of the kernel (as we discussed at LSF/MM) then we can't assume that it'll be doing any sort of syncfs call beforehand. The main reason to push this down into the filesystems is to allow them control over whether to report errors at syncfs time via the superblock errseq_t or not. If we don't really care about allowing this to be an opt-in thing, then we could just take the patch that I sent on April 17th: track per-sb writeback errors and report them to syncfs. We'd also want patch #6 from this series, I think, but that's more or less enough to implement this over all filesystems, assuming they use mapping_set_error to record writeback errors. I'm fine with either approach.",271302,technical,"XFS never uses the block device mapping for anything, so this is not needed.   The proper name for this would be vfs_sync_fs.  And I don't think it warrants an inline.","XFS never uses the block device mapping for anything, so this is not needed.   The proper name for this would be this.  And I don't think it warrants an inline. I'm not sure I understand what you intend here. If this fails, then the error should have already been marked in this (via patch #6). We wouldn't want to record that again at syncfs time. Note that it will return errors based on the legacy flags. We really do need to record it in the superblock as soon as possible after an error occurs. If we want to allow userland to eventually be able to scrape this value out of the kernel (as we discussed at LSF/MM) then we can't assume that it'll be doing any sort of syncfs call beforehand. The main reason to push this down into the filesystems is to allow them control over whether to report errors at syncfs time via the superblock errseq_t or not. If we don't really care about allowing this to be an opt-in thing, then we could just take the patch that I sent on April 17th: track per-sb writeback errors and report them to syncfs. We'd also want patch #6 from this series, I think, but that's more or less enough to implement this over all filesystems, assuming they use mapping_set_error to record writeback errors. I'm fine with either approach.",Jeff Layton,jlayton@kernel.org,1,1,1257,1.0,1.0,0.1111111111111111,0.07142857142857142,0,0.0,1.0,0.0,0.0
91,306145,317171,civil,"Please don't top post. And wrap your lines at around 75 characters. Look closely at the two implementations. Look at what
mmd_phy_indirect() does. I _think_ these are identical. So don't add your own helper, please use the core code.",317094,technical,"thanks for the hint. But actually I cannot confirm - or I don't see it yet.     Without having tested, just from the code, the struct phy_driver instance for thos in micrel.c does not have a .write_mmd function assigned, thus phy_write_mmd should evaluate to its else-clause (see below) and not to mdiobus_write (as in phy_write).    Also the  function which I have added uses the same principle as already existing HW-specific functions in micrel.c for simular reasons.  They use phy_write all over the place in that file and never phy_write_mmd - for whatever reason they had.  Thus I thought it would be a good idea ...    PHY link failure after cable connect. This looks a lot like phy_write_mmd(). ","thanks for the hint. But actually I cannot confirm - or I don't see it yet.     Without having tested, just from the code, the struct phy_driver instance for thos in micrel.c does not have a .write_mmd function assigned, thus phy_write_mmd should evaluate to its else-clause (see below) and not to mdiobus_write (as in phy_write).    Also the  function which I have added uses the same principle as already existing HW-specific functions in micrel.c for simular reasons.  They use phy_write all over the place in that file and never phy_write_mmd - for whatever reason they had.  Thus I thought it would be a good idea ...    PHY link failure after cable connect. This looks a lot like phy_write_mmd().  Please don't top post. And wrap your lines at around 75 characters. Look closely at the two implementations. Look at what this function does. I _think_ these are identical. So don't add your own helper, please use the core code.",Andrew Lunn,andrew@lunn.ch,1,0,932,1.0,1.0,0.2,0.125,0,0.24074074074074073,0.7407407407407407,0.0,0.7407407407407407
93,307410,307390,civil,"Oops, sorry, I double posted patch 5. Please disregard the second one.",307830,technical,"When remote files are counted in get_files_count, without using SSH, the code returns 0 because there is a colon prepended to LOC. VPATH should have been used instead of LOC. (NTB: test)","When remote files are counted in get_files_count, without using SSH, the code returns 0 because there is a colon prepended to LOC. VPATH should have been used instead of LOC. (NTB: test) Oops, sorry, I double posted patch 5. Please disregard the second one.",Logan Gunthorpe,logang@deltatee.com,1,1,257,0.1371571072319202,1.0,0.5,0.0625,0,0.0,1.0,0.0,0.024390243902439025
94,307410,311549,civil,"Well, clients not checking the error code made this harder to debug for sure, but removing the error code is a side effect and not what is happening here (in fact someone should probably still go back and add error checking because these functions can still return errors but that's not really something I have time to do). After the next couple patches, the clients will use this change to detect that there are no port numbers and handle things similarly to the way they did before they were broken by the multiport changes. This is the opposite of what I've ever heard before. Having a commit message that explains what led up to this commit is a good thing and allows people debugging in the future to better understand the decisions made. People debugging commits will never find the 0/X cover letter which is just intended to introduce the series to reviewers and describe changes if the series is posted multiple times. No this is not a feature request. This is fixing a regression that broke previously working code in the only sensible way I can come up with. If you have a better way to fix this, I'd be glad to hear it. But this should *not* be treated as a feature request.",311538,technical,"I disagree strongly. You can tell it's not device specific seeing we have 4 devices that need the exact same code. In fact, there is nothing device specific in those lines of code as the device specific part comes when a driver sets the PCI parent device's DMA mask. These lines just initialize the dma_mask for the new NTB device with its parent's mask. This is just sensible given that nothing now works if it is not done and trusting driver writers to get it right is not a good idea seeing we already screwed it up once. Furthermore, it violates DRY (do not repeat yourself).  If there is something driver specific that must be done (although I can't actually imagine what this would be) the drivers are free to change the mask after calling ntb_register but getting the common case setup in common code is just good design.","I disagree strongly. You can tell it's not device specific seeing we have 4 devices that need the exact same code. In fact, there is nothing device specific in those lines of code as the device specific part comes when a driver sets the PCI parent device's DMA mask. These lines just initialize the dma_mask for the new NTB device with its parent's mask. This is just sensible given that nothing now works if it is not done and trusting driver writers to get it right is not a good idea seeing we already screwed it up once. Furthermore, it violates DRY (do not repeat yourself).  If there is something driver specific that must be done (although I can't actually imagine what this would be) the drivers are free to change the mask after calling ntb_register but getting the common case setup in common code is just good design. Well, clients not checking the error code made this harder to debug for sure, but removing the error code is a side effect and not what is happening here (in fact someone should probably still go back and add error checking because these functions can still return errors but that's not really something I have time to do). After the next couple patches, the clients will use this change to detect that there are no port numbers and handle things similarly to the way they did before they were broken by the multiport changes. This is the opposite of what I've ever heard before. Having a commit message that explains what led up to this commit is a good thing and allows people debugging in the future to better understand the decisions made. People debugging commits will never find the 0/X cover letter which is just intended to introduce the series to reviewers and describe changes if the series is posted multiple times. No this is not a feature request. This is fixing a regression that broke previously working code in the only sensible way I can come up with. If you have a better way to fix this, I'd be glad to hear it. But this should *not* be treated as a feature request.",Logan Gunthorpe,logang@deltatee.com,1,1,2014,1.0,1.0,0.1111111111111111,0.1875,0,0.07317073170731707,0.926829268292683,0.0,0.07317073170731707
97,314071,314224,civil,"The commit description is not quite correct.  What the NO_HIDE_STALE flag does is allow a discard request for those block devices which do not have the DISCARD_ZEROES_DATA flag. I will note that the FALLOC_FL_NO_HIDE_STALE flag is a bit controversial in linux-fsdevel.  I have a similar patch in the VFS in Google's internal data center kernel, as well as an internal patch which implements support for this flag in ext4.  However, the patches are out of tree, because pretty much all of the file system developers who work for enterpise distributions were against this functionality. I know of one other major cloud provider (in China) using the functionality as an out-of-tree patch, but with no one else speaking in favor of it, and everyone else NAK'ing the patch and enterprise distro's saying they would revert the patch in their distro kernels, the compromise we came to was that the code point for NO_HIDE_STALE_FL would be reserved so that users of the out-of-tree patches wouldn't collide with future fallocate flags; and I would stop trying to push the patches upstream. I have no idea how Darrick was able to get this commit upstream, but I guess it was less controversial for block devices than for file systems. So I'm certainly in favor of this patch landing in mainline, but you should be aware that there may be some opposition to it.",314071,technical,"The flag must be set if user want to issue a discard request for block devices. But vfs_fallocate() will return with an error indicating lack of support if this flag is set.  fix it by allowing  flag in vfs_fallocate  Fixes: (block: implement (some of) fallocate for block devices"") 	","The flag must be set if user want to issue a discard request for block devices. But it will return with an error indicating lack of support if this flag is set.  fix it by allowing  flag in vfs_fallocate  Fixes: (block: implement (some of) fallocate for block devices""). The commit description is not quite correct.  What the NO_HIDE_STALE flag does is allow a discard request for those block devices which do not have the DISCARD_ZEROES_DATA flag. I will note that the FALLOC_FL_NO_HIDE_STALE flag is a bit controversial in linux-fsdevel.  I have a similar patch in the VFS in Google's internal data center kernel, as well as an internal patch which implements support for this flag in ext4.  However, the patches are out of tree, because pretty much all of the file system developers who work for enterpise distributions were against this functionality. I know of one other major cloud provider (in China) using the functionality as an out-of-tree patch, but with no one else speaking in favor of it, and everyone else NAK'ing the patch and enterprise distro's saying they would revert the patch in their distro kernels, the compromise we came to was that the code point for NO_HIDE_STALE_FL would be reserved so that users of the out-of-tree patches wouldn't collide with future fallocate flags; and I would stop trying to push the patches upstream. I have no idea how Darrick was able to get this commit upstream, but I guess it was less controversial for block devices than for file systems. So I'm certainly in favor of this patch landing in mainline, but you should be aware that there may be some opposition to it.",Theodore Y. Ts'o,tytso@mit.edu,1,0,1622,1.0,1.0,0.125,0.125,1,0.0,0.0,0.0,0.0
104,346223,347267,civil,"As far as I can tell, the above is the whole reason for the patchset, yes?  To avoid confusing users. Is that sufficient?  Can we instead simplify their lives by providing better documentation or informative printks or better Kconfig text, etc? And who *are* the people who are performing this configuration?  Random system administrators?  Linux distro engineers?  If the latter then they presumably aren't easily confused!
In other words, I'm trying to understand how much benefit this patchset will provide to our users as a whole.",346227,technical,"For file loading, if this is 'true', the memory which is used to load kernel/initrd/purgatory is supposed to be allocated from top to down. This is what we have been doing all along in the old kexec loading interface and the kexec loading is still default setting in some distributions. However, the current kexec_file loading interface doesn't do like this. The function it calls ignores checking that, but calls walk_system_ram_res() directly to go through all resources of System RAM from bottom to up, to try to find memory region which can contain the specific kexec buffer, then call it to allocate memory in that found memory region from top to down. This brings confusion especially when KASLR is widely supported , users have to make clear why kexec/kdump kernel loading position is different between these two interfaces in order to exclude unnecessary noises. Hence these two interfaces need be unified on behaviour.  Here add checking if kexec_buf.top_down is 'true' in it, if yes, call the newly added function to find memory region from top to down to load kernel. ","For file loading, if this is 'true', the memory which is used to load purgatory is supposed to be allocated from top to down. This is what we have been doing all along in the old kexec loading interface and the kexec loading is still default setting in some distributions. However, the current kexec_file loading interface doesn't do like this. The function it calls ignores checking that, but calls this function directly to go through all resources of System RAM from bottom to up, to try to find memory region which can contain the specific kexec buffer, then call it to allocate memory in that found memory region from top to down. This brings confusion especially when KASLR is widely supported , users have to make clear why kexec/kdump kernel loading position is different between these two interfaces in order to exclude unnecessary noises. Hence these two interfaces need be unified on behaviour.  Here add checking if kexec_buf.top_down is 'true' in it, if yes, call the newly added function to find memory region from top to down to load kernel.  As far as I can tell, the above is the whole reason for the patchset, yes?  To avoid confusing users. Is that sufficient?  Can we instead simplify their lives by providing better documentation or informative printks or better Kconfig text, etc? And who *are* the people who are performing this configuration?  Random system administrators?  Linux distro engineers?  If the latter then they presumably aren't easily confused!
In other words, I'm trying to understand how much benefit this patchset will provide to our users as a whole.",Andrew Morton,akpm@linux-foundation.org,1,0,1592,1.0,1.0,0.1111111111111111,0.1111111111111111,0,0.0,0.875,0.0,0.0
105,347183,348381,civil,"Hopefully I'm not missing anything here, but this doesn't really make any sense. I'm not sure I explained myself as well as I thought I did. To be honest, I had to double check this about literally 20 times to make sure I was actually understanding this issue correctly. Turns out I was missing a couple of parts, so I'm going to try again at explaining this using a diagram that shows the various threads running concurrently. phew. that took a LONG time to come up with. Anyway-that's why your explanation doesn't make sense: the deadlock is happening because we're calling pm_runtime_get_sync(). If we were to make that call conditional (e.g. drm_kms_helper_is_poll_worker()), all that would mean is that we wouldn't grab any runtime power reference and the GPU would immediately suspend once the atomic commit finished, as the suspend request in Thread 5 would finally get unblocked and thus----suspend. Hopefully I explained that better this time, I'll definitely make sure to actually include that diagram in the patch. As for whether or not this patch is even the right solution, I will need to confirm that tommorrow (if you don't think it is still, please feel free to say so!) because it's getting late here.",347502,technical,"Hm, a runtime PM ref is already acquired in nouveau_connector_detect(). I'm wondering why that's not sufficient?","Hm, a runtime PM ref is already acquired in nouveau_connector_detect(). I'm wondering why that's not sufficient? Hopefully I'm not missing anything here, but this doesn't really make any sense. I'm not sure I explained myself as well as I thought I did. To be honest, I had to double check this about literally 20 times to make sure I was actually understanding this issue correctly. Turns out I was missing a couple of parts, so I'm going to try again at explaining this using a diagram that shows the various threads running concurrently. phew. that took a LONG time to come up with. Anyway-that's why your explanation doesn't make sense: the deadlock is happening because we're calling this function. If we were to make that call conditional (e.g. this function), all that would mean is that we wouldn't grab any runtime power reference and the GPU would immediately suspend once the atomic commit finished, as the suspend request in Thread 5 would finally get unblocked and thus----suspend. Hopefully I explained that better this time, I'll definitely make sure to actually include that diagram in the patch. As for whether or not this patch is even the right solution, I will need to confirm that tommorrow (if you don't think it is still, please feel free to say so!) because it's getting late here.",Lyude Paul,lyude@redhat.com,1,1,1305,0.4694589877835951,1.0,0.1,0.029411764705882353,0,0.05555555555555555,0.9444444444444444,0.0,0.0
106,347183,349692,civil,"First of all, I was mistaken when I wrote above that a check for! It would solve the problem.  Sorry! It doesn't because the call to pm_runtime_get_sync() is not happening in this but in this.

Looking once more at the three stack traces you've provided, we've got:
- output_poll_execute() stuck waiting for fb_helper->lock which is held by drm_dp_mst_link_probe_work()
- this is stuck waiting for it to finish
- this is stuck waiting in here. For the moment we can ignore the first task, i.e. output_poll_execute(), and focus on the latter two. As said I'm unfamiliar with MST but browsing through this I notice that drm_dp_mst_link_probe_work() is the ->work element in this and is queued on HPD.  I further notice that the work item is flushed on runtime_suspend. And before the work item is flushed, the HPD source is quiesced.
So it looks like drm_dp_mst_link_probe_work() can only ever run while the GPU is runtime resumed, it never runs while the GPU is runtime suspended.  This means that you don't have to acquire any runtime PM references in or below drm_dp_mst_link_probe_work(). Au contraire, you must not acquire any because it will deadlock while the GPU is runtime suspending.  If there are functions which are called from drm_dp_mst_link_probe_work() as well as from other contexts, and those other contexts need a runtime PM ref to be acquired, you need to acquire the runtime PM ref conditionally on not being drm_dp_mst_link_probe_work() (using the current_work() technique). Alternatively, move acquisition of the runtime PM ref further up in the call chain to those other contexts. Right, that seems to be a bug nouveau_pmops_runtime_suspend().
If a display is plugged in while the GPU is about to runtime suspend, the display may be lit up by output_poll_execute() but the GPU will then nevertheless be powered off. 
I guess after calling drm_kms_helper_poll_disable() we should re-check if a crtc has been activated.  This should have bumped the runtime PM refcount and have_disp_power_ref should be true.  In that case, the nouveau_pmops_runtime_suspend() should return -EBUSY to abort the runtime_suspend.
The same check seems necessary after flushing drm_dp_mst_link_probe_work(): If the work item lit up a new display, all previous suspend steps need to be unwound and -EBUSY needs to be returned to the PM core.
Communication with an MST hub exceeding the autosuspend timeout is just one scenario where this bug manifests itself.
BTW, drm_kms_helper_poll_disable() seems to be called twice in the runtime_suspend code path, once in nouveau_pmops_runtime_suspend() and a second time in nouveau_display_fini(). A stupid question, I notice that this only if encoder_type is not equal to this. Why isn't that equal?",348395,technical,"As an additional note, I realized this might seem wrong but it isn't  this function calls down to nouveau's runtime idle callback, which does this. So, it doesn't actually synchronously suspend the GPU, it just starts up the autosuspend thread  Just wanted to make sure there wasn't any confusion :) ","As an additional note, I realized this might seem wrong but it isn't  this function calls down to nouveau's runtime idle callback, which does this. So, it doesn't actually synchronously suspend the GPU, it just starts up the autosuspend thread  Just wanted to make sure there wasn't any confusion :)  First of all, I was mistaken when I wrote above that a check for! It would solve the problem.  Sorry! It doesn't because the call to pm_runtime_get_sync() is not happening in this but in this.

Looking once more at the three stack traces you've provided, we've got:
- output_poll_execute stuck waiting for the lock which is held by this function
- this function is stuck waiting for it to finish
- this functiion is stuck waiting in here. For the moment we can ignore the first task, i.e. output_poll_execute(), and focus on the latter two. As said I'm unfamiliar with MST but browsing through this I notice that this is the function is the ->work element in this and is queued on HPD.  I further notice that the work item is flushed on runtime_suspend. And before the work item is flushed, the HPD source is quiesced.
So it looks like this function can only ever run while the GPU is runtime resumed, it never runs while the GPU is runtime suspended.  This means that you don't have to acquire any runtime PM references in or below this function. Au contraire, you must not acquire any because it will deadlock while the GPU is runtime suspending.  If there are functions which are called from this function as well as from other contexts, and those other contexts need a runtime PM ref to be acquired, you need to acquire the runtime PM ref conditionally on not being this function (using the current_work() technique). Alternatively, move acquisition of the runtime PM ref further up in the call chain to those other contexts. Right, that seems to be a bug function.
If a display is plugged in while the GPU is about to runtime suspend, the display may be lit up by output_poll_execute() but the GPU will then nevertheless be powered off. 
I guess after calling helper_poll_disable() we should re-check if a crtc has been activated.  This should have bumped the runtime PM refcount and have_disp_power_ref should be true.  In that case, the runtime_suspend() should return -EBUSY to abort the runtime_suspend.
The same check seems necessary after flushing link_probe_work(): If the work item lit up a new display, all previous suspend steps need to be unwound and -EBUSY needs to be returned to the PM core.
Communication with an MST hub exceeding the autosuspend timeout is just one scenario where this bug manifests itself.
BTW, poll_disable() seems to be called twice in the runtime_suspend code path, once in runtime_suspend() and a second time in this function. A stupid question, I notice that this only if encoder_type is not equal to this. Why isn't that equal?",Lukas Wunner,lukas@wunner.de,1,0,2873,1.0,1.0,0.041666666666666664,0.3235294117647059,0,0.1111111111111111,0.8333333333333334,0.05555555555555555,0.1111111111111111
109,365796,367141,civil,"Just a blind shot, without going into details - could you please check if led-sources property documented in the common LED bindings couldn't help here?",367140,technical,"Yes, and LED strings are statically assigned to banks, right?  So why not simply forget about LED strings for sake of hw abstractions, and work just with banks? ","Yes, and LED strings are statically assigned to banks, right?  So why not simply forget about LED strings for sake of hw abstractions, and work just with banks?  Just a blind shot, without going into details - could you please check if led-sources property documented in the common LED bindings couldn't help here?",Jacek Anaszewski,jacek.anaszewski@gmail.com,1,0,314,0.40131578947368424,1.0,1.0,0.041666666666666664,0,0.16666666666666666,0.8333333333333334,0.0,0.0
110,365796,367690,civil,This is better than my proposal. Thanks!,367623,technical,"led-sources was designed for describing the topology where one LED can be connected to more then one output, see bindings of max77693-led (in Documentation).  Here the topology is a bit different - more than one LED (string) can be connected to a single bank, but this is accomplished inside the chip. Logically LEDs configured that way can be treated as a single LED (string) connected to two outputs, and what follows they should be described by a single DT child node.  led-sources will fit very well for this purpose. You could do the following mapping: Then, in the child DT nodes you would use these identifiers to describe the topology:  Following node would describe strings connected to the outputs HVLED1 and HVLED2 controlled by bank A.","led-sources was designed for describing the topology where one LED can be connected to more then one output, see bindings of max77693-led (in Documentation).  Here the topology is a bit different - more than one LED (string) can be connected to a single bank, but this is accomplished inside the chip. Logically LEDs configured that way can be treated as a single LED (string) connected to two outputs, and what follows they should be described by a single DT child node.  led-sources will fit very well for this purpose. You could do the following mapping: Then, in the child DT nodes you would use these identifiers to describe the topology:  Following node would describe strings connected to the outputs HVLED1 and HVLED2 controlled by bank A. This is better than my proposal. Thanks!",Pavel Machek,pavel@ucw.cz,1,0,788,1.0,1.0,0.6666666666666666,0.125,0,0.16666666666666666,0.8333333333333334,0.0,0.0
112,368515,368789,civil,"I welcome this feature, been wanting it for some time now. There is simply not enough support in maps or smaps to get this information. This is important to improve code and data layouts.
I would like to see the following changes to your proposal: - call it PERF_SAMPLE_DATA_PAGE_SIZE
That would allow two things:
   1 - not tied to PERF_SAMPLE_ADDR
   2 - Allow PERF_SAMPLE_CODE_PAGE_SIZE to be added
In some measurements, you may just care about the distribution of accesses across page sizes. No need to use double the buffer space to save the address you will not use.
Layout is important for code as well, in fact, that's what most people want first. Having a CODE_PAGE_SIZE is therefore useful. I am happy adding it on top on your proposal. Note that PERF_SAMPLE_CODE_PAGE_SIZE would not have to be tied to PEBS unlike DATA_PAGE_SIZE. Thanks.",368520,technical,Extend sample-parsing test cases to support new sample type.,"Extend sample-parsing test cases to support new sample type. I welcome this feature, been wanting it for some time now. There is simply not enough support in maps or smaps to get this information. This is important to improve code and data layouts.
I would like to see the following changes to your proposal: - call it PERF_SAMPLE_DATA_PAGE_SIZE
That would allow two things:
   1 - not tied to PERF_SAMPLE_ADDR
   2 - Allow PERF_SAMPLE_CODE_PAGE_SIZE to be added
In some measurements, you may just care about the distribution of accesses across page sizes. No need to use double the buffer space to save the address you will not use.
Layout is important for code as well, in fact, that's what most people want first. Having a CODE_PAGE_SIZE is therefore useful. I am happy adding it on top on your proposal. Note that PERF_SAMPLE_CODE_PAGE_SIZE would not have to be tied to PEBS unlike DATA_PAGE_SIZE. Thanks.",Stephane Eranian,eranian@google.com,0,0,909,1.0,1.0,0.08333333333333333,0.08333333333333333,1,0.0,0.0,0.0,0.0
114,374095,374559,civil,Please use your real name. 1st Signed-off-by and patch author should match. Good find! I'll queue this for the next fixes-pull-request.,374095,technical,"Even though we protect on-flash data by CRC checksums, we still don't trust the media. If lnum is not 0 or 1, access exceed array boundary can lead to bad situation.  ","Even though we protect on-flash data by CRC checksums, we still don't trust the media. If lnum is not 0 or 1, access exceed array boundary can lead to bad situation.   Please use your real name. 1st Signed-off-by and patch author should match. Good find! I'll queue this for the next fixes-pull-request.",Richard Weinberger,richard@nod.at,1,0,303,1.0,1.0,0.25,0.25,1,0.0,0.0,0.0,0.0
115,377230,377461,civil,"Interesting - I don't see the grant head reservation code in any of my performance benchmark profiling, even when running at over a million transactions/s on a 2-socket 32-core 64-thread skylake system. I see other places in the transaction subsystem that are hot (e.g the CIL context lock), but not the space reservations. 
My initial suspect is that you have a tiny log on your test filesystem, so it's permanently out of space and so always hitting the slow path. Can you tell us what the storage is and it's configuration? At minimum, I need to see the output of the xfs_info command on your test filesystem. Fixing this may simply be using a larger log on your benchmark systems.
FWIW, can you post the actual profile you are seeing in the commit message? That helps us identify similar problems in the future, and it lets us know what paths are leading to the transaction reservation contention. i.e. this may not even be a problem with the transaction reservation code itself. How does this impact on the strict FIFO queue behaviour the grant queues currently have? The current code only wakes up enough waiters to consume the newly available space and it queues new waiters to the tail of the queue. If there ever is a spurious wakeup then the waiter that was woken from the head remains there until the next wakeup comes in. This is intentional - spurious wakeups are rare enough we can ignore them because a) this is the slow path, and b) correctness is far more important that performance in this path. The fast path is already lockless, and we've already given up peformance if we reach this slow path. hence we only care about correctness in this path, not performance optimisation.
AFAICT the patch changes the spurious wakeup behaviour - it requeues tasks to the tail of the queue if there wasn't space available when they are woken, rather than leaving them as them at the head.  They now have to wait for all the other reservations to make progress. This breaks the guarantees of ordered forward progress the grant queue provides permanent transaction reservations and hence opens us up to log space deadlocks because those transactions can't move their objects forward in the log to free up space in the log... Also, I note that wake_q_add() assumes that the wake queue is a local stack object and so not subject to concurrency - it explicitly states this in the code. That's not the case here - the wake queue is part of the grant head, and so is subject to extreme concurrency that is tempered by a spin lock.  Does the wake_q code work correctly (e.g. have all the necessary memory barriers, etc) when it's not a local stack object and instead protected from concurrency by a spin lock? At minimum, the wake_q infrastructure comments and documentation need updating to accommodate this new use case that wake queues are being used for.

This doesn't generally doesn't happen because the space accounting tends to prevent multiple wakeups. i.e. we only wake the tasks we have reservation space for, and log space being made available tends to arrive in discrete chunks (because IO is slow!) such that that pending wakeups have already been processed before the next chunk of available space comes in....
Yes, but they are very rare and we don't really care about this in the slow path. If you see lots of them, it's typically a sign of an inappropriately configured filesystem for the workload being run. On a correctly configured system, we should almost never use this slow path....

I'm betting that you'll get that and a whole lot more simply by increasing the log size and not running the slow path at all.
Where's the hunk context in your headers? You must be using a non-standard git option here.
Linux kernel specific includes go in fs/xfs/xfs_linux.h, not individual files.
Why do you need to delete the ticket from the queue here? This leads to landmines and incorrect non-FIFO behaviour...
.... here. This is a potential list corruption landmine because this function now has unbalanced list add and removal contexts. IOWs, we can't restart this loop without first having guaranteed the ticket is not already on the ticket queue. You need to document constraints like this in comments and explain what code needs to guarantee those constraints are met. [Because, as I noted at the end, you got this wrong for xlog_grant_head_wake_all()]

To maintian FIFO behaviour, the ticket needs to be left at the head of the grant head wait queue until it has space available to make progress, not get removed and requeued to the tail. Spurious wake ups are irrelevant here - forwards progress (i.e. correctness) requires FIFO ticket ordering behaviour be maintained.
This push is needed to make the necessary space we are waiting on available in the log. Hence leaving it out of the loop you put below will cause the journal to get stuck in the spurious wakeup loop below and be unable to make progress. This will lead to filesystem hangs.
That's a new nested loop. Please implement it as a loop. This is buggy  - i will lead to hangs if the filesystem is shut down and there is a spurious wakeup that triggers this to go back to sleep. The shutdown check needs to break the sleep loop.
That's racy. You can't drop the spin lock between xlog_grant_head_wake() and xlog_grant_head_wait(), because free_bytes is only valid while while the spinlock is held.  Same for the ""wake_all"" variable you added. i..e. while waking up the waiters, we could have run out of space again and had more tasks queued, or had the AIL tail move and now have space available. Either way, we can do the wrong thing because we dropped the lock and free_bytes and wake_all are now stale and potentially incorrect. That's another landmine. Just define the wakeq in the context where it is used rather than use a function wide variable that requires reinitialisation. Ok, what about xlog_grant_head_wake_all()? You didn't convert that to use wake queues, and so that won't remove tickets for the grant head waiter list, and so those tasks will never get out of the new inner loop you added to xlog_grant_head_wait(). That means filesystem shutdowns will just hang the filesystem and leave it unmountable. Did you run this through fstests? ",377229,technical,"Running the AIM7 fserver workload on a 2-socket 24-core 48-thread Broadwell system, it was found that there were severe spinlock contention in the XFS code. In particular, this function consumes 69.7% of cpu time. The check function call and its sub-function calls underneath it consumed 27.2% of the cpu time. This function tried to wake up tasks in the log space wait queue and then put itself into the wait queue if there is not enough log space left.  The process of waking up task can be time consuming and it is not really necessary to hold an XFS lock while doing the wakeups. So the wake function is modified to put the tasks to be waken up into a wake_q to be passed to wake_up_q() without holding the lock.  Corresponding changes are made in xlog_grant_head_wait() to dequeue the tasks from the wait queue after they are put into the wake_q. This avoids multiple wakeups of the same task from different log space waiters. Multiple wakeups seems to be a possibility in the existing code too.  With the use of the wake_q, the cpu time used by this function dropped to 39.6%. However, the performance of the AIM7 fserver workload increased from 91,485.51 jobs/min to 397,290.21 jobs/min which was more than 4X improvement.  ","Running the AIM7 fserver workload on a 2-socket 24-core 48-thread Broadwell system, it was found that there were severe spinlock contention in the XFS code. In particular, this function consumes 69.7% of cpu time. The check function call and its sub-function calls underneath it consumed 27.2% of the cpu time. This function tried to wake up tasks in the log space wait queue and then put itself into the wait queue if there is not enough log space left.  The process of waking up task can be time consuming and it is not really necessary to hold an XFS lock while doing the wakeups. So the wake function is modified to put the tasks to be waken up into a wake_q to be passed to wake_up_q() without holding the lock.  Corresponding changes are made in xlog_grant_head_wait() to dequeue the tasks from the wait queue after they are put into the wake_q. This avoids multiple wakeups of the same task from different log space waiters. Multiple wakeups seems to be a possibility in the existing code too.  With the use of the wake_q, the cpu time used by this function dropped to 39.6%. However, the performance of the AIM7 fserver workload increased from 91,485.51 jobs/min to 397,290.21 jobs/min which was more than 4X improvement.   Interesting - I don't see the grant head reservation code in any of my performance benchmark profiling, even when running at over a million transactions/s on a 2-socket 32-core 64-thread skylake system. I see other places in the transaction subsystem that are hot (e.g the CIL context lock), but not the space reservations. 
My initial suspect is that you have a tiny log on your test filesystem, so it's permanently out of space and so always hitting the slow path. Can you tell us what the storage is and it's configuration? At minimum, I need to see the output of the xfs_info command on your test filesystem. Fixing this may simply be using a larger log on your benchmark systems.
FWIW, can you post the actual profile you are seeing in the commit message? That helps us identify similar problems in the future, and it lets us know what paths are leading to the transaction reservation contention. i.e. this may not even be a problem with the transaction reservation code itself. How does this impact on the strict FIFO queue behaviour the grant queues currently have? The current code only wakes up enough waiters to consume the newly available space and it queues new waiters to the tail of the queue. If there ever is a spurious wakeup then the waiter that was woken from the head remains there until the next wakeup comes in. This is intentional - spurious wakeups are rare enough we can ignore them because a) this is the slow path, and b) correctness is far more important that performance in this path. The fast path is already lockless, and we've already given up peformance if we reach this slow path. hence we only care about correctness in this path, not performance optimisation.
AFAICT the patch changes the spurious wakeup behaviour - it requeues tasks to the tail of the queue if there wasn't space available when they are woken, rather than leaving them as them at the head.  They now have to wait for all the other reservations to make progress. This breaks the guarantees of ordered forward progress the grant queue provides permanent transaction reservations and hence opens us up to log space deadlocks because those transactions can't move their objects forward in the log to free up space in the log... Also, I note that wake_q_add() assumes that the wake queue is a local stack object and so not subject to concurrency - it explicitly states this in the code. That's not the case here - the wake queue is part of the grant head, and so is subject to extreme concurrency that is tempered by a spin lock.  Does the wake_q code work correctly (e.g. have all the necessary memory barriers, etc) when it's not a local stack object and instead protected from concurrency by a spin lock? At minimum, the wake_q infrastructure comments and documentation need updating to accommodate this new use case that wake queues are being used for.

This doesn't generally doesn't happen because the space accounting tends to prevent multiple wakeups. i.e. we only wake the tasks we have reservation space for, and log space being made available tends to arrive in discrete chunks (because IO is slow!) such that that pending wakeups have already been processed before the next chunk of available space comes in....
Yes, but they are very rare and we don't really care about this in the slow path. If you see lots of them, it's typically a sign of an inappropriately configured filesystem for the workload being run. On a correctly configured system, we should almost never use this slow path....

I'm betting that you'll get that and a whole lot more simply by increasing the log size and not running the slow path at all.
Where's the hunk context in your headers? You must be using a non-standard git option here.
Linux kernel specific includes go in this, not individual files.
Why do you need to delete the ticket from the queue here? This leads to landmines and incorrect non-FIFO behaviour...
.... here. This is a potential list corruption landmine because this function now has unbalanced list add and removal contexts. IOWs, we can't restart this loop without first having guaranteed the ticket is not already on the ticket queue. You need to document constraints like this in comments and explain what code needs to guarantee those constraints are met. [Because, as I noted at the end, you got this wrong for xlog_grant_head_wake_all()]

To maintian FIFO behaviour, the ticket needs to be left at the head of the grant head wait queue until it has space available to make progress, not get removed and requeued to the tail. Spurious wake ups are irrelevant here - forwards progress (i.e. correctness) requires FIFO ticket ordering behaviour be maintained.
This push is needed to make the necessary space we are waiting on available in the log. Hence leaving it out of the loop you put below will cause the journal to get stuck in the spurious wakeup loop below and be unable to make progress. This will lead to filesystem hangs.
That's a new nested loop. Please implement it as a loop. This is buggy  - i will lead to hangs if the filesystem is shut down and there is a spurious wakeup that triggers this to go back to sleep. The shutdown check needs to break the sleep loop.
That's racy. You can't drop the spin lock between xlog_grant_head_wake() and xlog_grant_head_wait(), because free_bytes is only valid while while the spinlock is held.  Same for the ""wake_all"" variable you added. i..e. while waking up the waiters, we could have run out of space again and had more tasks queued, or had the AIL tail move and now have space available. Either way, we can do the wrong thing because we dropped the lock and free_bytes and wake_all are now stale and potentially incorrect. That's another landmine. Just define the wakeq in the context where it is used rather than use a function wide variable that requires reinitialisation. Ok, what about xlog_grant_head_wake_all()? You didn't convert that to use wake queues, and so that won't remove tickets for the grant head waiter list, and so those tasks will never get out of the new inner loop you added to xlog_grant_head_wait(). That means filesystem shutdowns will just hang the filesystem and leave it unmountable. Did you run this through fstests? ",Dave Chinner,david@fromorbit.com,0,0,7450,1.0,1.0,0.014492753623188406,0.013888888888888888,0,0.0,0.6666666666666666,0.0,0.0
116,377230,378511,civil,"Thanks for your detailed review of the patch. I now have a better understanding of what should and shouldn't be done. I have sent out a more conservative v2 patchset which, hopefully, can address the concerns that you raised.",378176,technical,"You are right. The XFS filesystem was created on a small ramfs device and so the disk space was tiny. The microbenchmark that I used exposes some extreme cases that may not be normally observed.   Those were part of the perf trace that I marked down:   A spurious wakeup shouldn't change the behavior as the waiter should find that it is still being queued (list not empty) and so will sleep again. However, if the waiter is rightfully waken but find that there is not enough log space somehow, it will put itself back to the end of the queue. That is a change in behavior that I think could be an issue.  I am just wondering why the code doesn't reserve the actual log space at the time a task is being waken. Instead, it has to try to get it itself after being waken.  Also I think the current code allows consecutive waiters to come in and wake up the same set of tasks again and again. That may be where a part of the performance slowdown come from.   As I said above, spurious wakeup shouldn't cause problem. However, consecutive waiters will probably wake up more tasks than there is log space available. In this case, some of the tasks will be put back to the queue. Maybe a counter to record the log space temporarily reserved for the waken-up task can help to prevent over-subscription.    The wake_q should work correctly as it is used by mutexes and rwsems. We will see a lot of problem reports if that is not the case.   That is probably true.   I am using a old git (1.8). I should probably upgrade to a newer one.   OK   It is because the wake_q uses a field in the task structure for queuing. So a task can only be in one wake_q at a time. Leaving the ticket in the queue may cause the task to be put into multiple wake_q causing missed wakeup, perhaps.    Yes, you are right. The wake function need to be modified as well.   OK, I need more time to think about some of the questions that you raise.  Thanks for reviewing the patch.","You are right. The XFS filesystem was created on a small ramfs device and so the disk space was tiny. The microbenchmark that I used exposes some extreme cases that may not be normally observed.   Those were part of the perf trace that I marked down:   A spurious wakeup shouldn't change the behavior as the waiter should find that it is still being queued (list not empty) and so will sleep again. However, if the waiter is rightfully waken but find that there is not enough log space somehow, it will put itself back to the end of the queue. That is a change in behavior that I think could be an issue.  I am just wondering why the code doesn't reserve the actual log space at the time a task is being waken. Instead, it has to try to get it itself after being waken.  Also I think the current code allows consecutive waiters to come in and wake up the same set of tasks again and again. That may be where a part of the performance slowdown come from.   As I said above, spurious wakeup shouldn't cause problem. However, consecutive waiters will probably wake up more tasks than there is log space available. In this case, some of the tasks will be put back to the queue. Maybe a counter to record the log space temporarily reserved for the waken-up task can help to prevent over-subscription.    The wake_q should work correctly as it is used by mutexes and rwsems. We will see a lot of problem reports if that is not the case.   That is probably true.   I am using a old git (1.8). I should probably upgrade to a newer one.   OK   It is because the wake_q uses a field in the task structure for queuing. So a task can only be in one wake_q at a time. Leaving the ticket in the queue may cause the task to be put into multiple wake_q causing missed wakeup, perhaps.    Yes, you are right. The wake function need to be modified as well.   OK, I need more time to think about some of the questions that you raise.  Thanks for reviewing the patch. Thanks for your detailed review of the patch. I now have a better understanding of what should and shouldn't be done. I have sent out a more conservative v2 patchset which, hopefully, can address the concerns that you raised.",Waiman Long,longman@redhat.com,1,1,2173,0.3117241379310345,1.0,0.3333333333333333,0.9722222222222222,1,1.0,0.0,0.3333333333333333,0.0
118,378505,379417,civil,"Can you please re-run and report the results for each patch on the ramdisk setup? And, please, include the mkfs.xfs or xfs_info output for the ramdisk filesystem so I can see /exactly/ how much concurrency the filesystems are providing to the benchmark you are running. 50GB is tiny for XFS. Personally, I've been using ~1PB filesystems(*) for the performance testing I've been doing
recently... Yes, petabytes. Sparse image files on really fast SSDs are a wonderful thing.",379318,technical,"Yes, I realise that.  I am expecting that when it comes to optimising for pmem, we'll actually rewrite the journal to map pmem and memcpy() directly rather than go through the buffering and IO layers we currently do so we can minimise write latency and control concurrency ourselves. Hence I'm not really concerned by performance issues with pmem at this point - most of our still users have traditional storage and will for a long time to come....","Yes, I realise that.  I am expecting that when it comes to optimising for pmem, we'll actually rewrite the journal to map pmem and memcpy() directly rather than go through the buffering and IO layers we currently do so we can minimise write latency and control concurrency ourselves. Hence I'm not really concerned by performance issues with pmem at this point - most of our still users have traditional storage and will for a long time to come.... Can you please re-run and report the results for each patch on the ramdisk setup? And, please, include the mkfs.xfs or xfs_info output for the ramdisk filesystem so I can see /exactly/ how much concurrency the filesystems are providing to the benchmark you are running. 50GB is tiny for XFS. Personally, I've been using ~1PB filesystems(*) for the performance testing I've been doing recently... Yes, petabytes. Sparse image files on really fast SSDs are a wonderful thing.",Dave Chinner,david@fromorbit.com,0,0,922,1.0,1.0,0.2,0.1,1,1.0,0.0,0.0,0.0
119,379138,379657,civil,"I like the idea and I think it's good direction to go, but could you please share some from perf stat or whatever you used to meassure the new performance?",379138,technical,"Currently in record mode the tool implements trace writing serially.  The algorithm loops over mapped per-cpu data buffers and stores ready  data chunks into a trace file using write() system call.  At some circumstances the kernel may lack free space in a buffer  because the other buffer's half is not yet written to disk due to  some other buffer's data writing by the tool at the moment.  Thus serial trace writing implementation may cause the kernel  to loose profiling data and that is what observed when profiling  highly parallel CPU bound workloads on machines with big number  of cores.  Experiment with G123 profiling matrix multiplication code executing 128  threads on Intel Xeon Phi (KNM) with 272 cores, like below, demonstrates data loss metrics value of 98%: Data loss metrics is the ratio lost_time/elapsed_time where  lost_time is the sum of time intervals containing lost records and elapsed_time is the elapsed application run time  under profiling.  Applying asynchronous trace streaming thru Posix AIO API  lowers data loss  metrics value providing ~25% improvement in average.  ","Currently in record mode the tool implements trace writing serially.  The algorithm loops over mapped per-cpu data buffers and stores ready  data chunks into a trace file using write() system call.  At some circumstances the kernel may lack free space in a buffer  because the other buffer's half is not yet written to disk due to  some other buffer's data writing by the tool at the moment.  Thus serial trace writing implementation may cause the kernel  to loose profiling data and that is what observed when profiling  highly parallel CPU bound workloads on machines with big number  of cores.  Experiment with G123 profiling matrix multiplication code executing 128  threads on Intel Xeon Phi (KNM) with 272 cores, like below, demonstrates data loss metrics value of 98%: Data loss metrics is the ratio lost_time/elapsed_time where  lost_time is the sum of time intervals containing lost records and elapsed_time is the elapsed application run time  under profiling.  Applying asynchronous trace streaming thru Posix AIO API  lowers data loss  metrics value providing ~25% improvement in average.   I like the idea and I think it's good direction to go, but could you please share some from perf stat or whatever you used to meassure the new performance?",Jiri Olsa,jolsa@redhat.com,1,0,1258,1.0,1.0,1.0,1.0,0,0.0,0.0,0.0,0.0
121,390394,390741,civil,"Sorry but I don't like imposing a run-time check on everybody when stack-based requests are the odd ones out.  If we're going to make this a run-time check (I'd much prefer a compile-time check, but I understand that this may involve too much churn), then please do it for stack-based request users only.",390396,technical,"Since the size is now fixed, there is no need to include the tfm argument. This removes it from the definition and callers.   --","Since the size is now fixed, there is no need to include the tfm argument. This removes it from the definition and callers.   -- Sorry but I don't like imposing a run-time check on everybody when stack-based requests are the odd ones out.  If we're going to make this a run-time check (I'd much prefer a compile-time check, but I understand that this may involve too much churn), then please do it for stack-based request users only.",Herbert Xu,herbert@gondor.apana.org.au,1,0,433,1.0,1.0,0.5,0.5,0,0.0,1.0,0.0,0.0
122,391895,394633,civil,"[ I am not subscribed to LKML, please keep me CC'd on replies ] I tried a simple test with several VMs (in my initial test, I have 48
idle 1-cpu 512-mb VMs and 2 idle 2-cpu, 2-gb VMs) using libvirt, none pinned to any CPUs. When I tried to set all of the top-level libvirt cpu cgroups' to be co-scheduled. There are several moving parts there, so I tried narrowing it down, by only coscheduling one VM, and thing seemed fine. One thing that is not entirely obvious to me (but might be completely intentional) is that since by default the top-level libvirt cpu cgroups are empty. the result of this should be a no-op, right? [This becomes relevant below] Specifically, all of the threads of qemu are in sub-cgroups, which do not indicate they are co-scheduling. When I then try to coschedule the second VM, the machine hangs. On the console, I see the same backtraces I see when I try to set all of the VMs to be coscheduled. I am happy to do any further debugging I can do, or try patches on top of those posted on the mailing list.",392481,technical,"Hi, Please document both of these kernel parameters in Documentation.","Hi, Please document both of these kernel parameters in Documentation. [ I am not subscribed to LKML, please keep me CC'd on replies ] I tried a simple test with several VMs (in my initial test, I have 48
idle 1-cpu 512-mb VMs and 2 idle 2-cpu, 2-gb VMs) using libvirt, none pinned to any CPUs. When I tried to set all of the top-level libvirt cpu cgroups' to be co-scheduled. There are several moving parts there, so I tried narrowing it down, by only coscheduling one VM, and thing seemed fine. One thing that is not entirely obvious to me (but might be completely intentional) is that since by default the top-level libvirt cpu cgroups are empty. the result of this should be a no-op, right? [This becomes relevant below] Specifically, all of the threads of qemu are in sub-cgroups, which do not indicate they are co-scheduling. When I then try to coschedule the second VM, the machine hangs. On the console, I see the same backtraces I see when I try to set all of the VMs to be coscheduled. I am happy to do any further debugging I can do, or try patches on top of those posted on the mailing list.",Nishanth Aravamudan,naravamudan@digitalocean.com,0,0,1102,1.0,1.0,0.25,0.014705882352941176,0,0.04597701149425287,0.9540229885057471,0.011494252873563218,0.0
146,498594,574206,civil,"I would really like to get an ack from the people who have been deep into this first.  If you can get that, and preferably resubmit with a less condescending changelog, I can pick it up.",573990,uncivil,"No problem here, no performance issues, nothing to be seen unless you are running VM.""   Take a care to look at the patch I submitted?  Lie: A system with an up to date kernel is protected against attacks from malicious user space applications.  3GB system running 32bit kernel is not protected. Same is true for for really big 64bit systems.  If I do what he suggests, this becomes untrue: The Linux kernel contains a mitigation for this attack vector, PTE inversion, which is permanently enabled and has no performance # impact.  Limiting memory to 2GB _is_ going to have severe perfomance impact. ","No problem here, no performance issues, nothing to be seen unless you are running VM.""   Take a care to look at the patch I submitted?  Lie: A system with an up to date kernel is protected against attacks from malicious user space applications.  3GB system running 32bit kernel is not protected. Same is true for for really big 64bit systems.  If I do what he suggests, this becomes untrue: The Linux kernel contains a mitigation for this attack vector, PTE inversion, which is permanently enabled and has no performance # impact.  Limiting memory to 2GB _is_ going to have severe perfomance impact.  I would really like to get an ack from the people who have been deep into this first.  If you can get that, and preferably resubmit with a less condescending changelog, I can pick it up.",Jonathan Corbet,corbet@lwn.net,1,0,787,1.0,1.0,0.5,0.0125,0,0.32270916334661354,0.6772908366533864,0.0,0.0
152,521470,533953,civil,"Is this patchset still an RFC or you really want to see this merged ASAP? If I am not mistaken there is still some work in progress trying to push all the SCP stuff? personally I have some concerns. Looks like the cros_* family is increasing quickly lately and I am wondering if we are really doing well all this. To be honest, I'd like to take a deeper look before merge this, btw I thought there was no hurry because of the RFC and I guess there are still some scp things that are missing. I might be wrong, and if that's not the case I can take a look deeper and the end of the week.",533830,technical,"Just to clarify to the new Cc'ed list, I'm waiting on one of the Chromium guys to review before I put my mucky paws over it. ","Just to clarify to the new Cc'ed list, I'm waiting on one of the Chromium guys to review before I put my mucky paws over it.  Is this patchset still an RFC or you really want to see this merged ASAP? If I am not mistaken there is still some work in progress trying to push all the SCP stuff? personally I have some concerns. Looks like the cros_* family is increasing quickly lately and I am wondering if we are really doing well all this. To be honest, I'd like to take a deeper look before merge this, btw I thought there was no hurry because of the RFC and I guess there are still some scp things that are missing. I might be wrong, and if that's not the case I can take a look deeper and the end of the week.",Enric Balletbo Serra,eballetbo@gmail.com,1,0,712,1.0,1.0,0.16666666666666666,0.16666666666666666,0,1.0,0.0,0.0,0.0
154,539613,546296,civil,"You are missing a cover letter from this patch set. Please have it in v2. Also use tag ""selftests/tpm2"" instead of having two tags in the short summaries. Now they look a bit weird. Remove.",539614,technical,"Three new tests added: 1. Send get random cmd, read header in 1st read, read the rest in second    read - expect success 2. Send get random cmd, read only part of the response, send another    get random command, read the response - expect success 3. Send get random cmd followed by another get random cmd, without    reading the first response - expect the second cmd to fail with -EBUSY ","Three new tests added: 1. Send get random cmd, read header in 1st read, read the rest in second    read - expect success 2. Send get random cmd, read only part of the response, send another    get random command, read the response - expect success 3. Send get random cmd followed by another get random cmd, without    reading the first response - expect the second cmd to fail with -EBUSY  You are missing a cover letter from this patch set. Please have it in v2. Also use tag ""selftests/tpm2"" instead of having two tags in the short summaries. Now they look a bit weird. Remove.",Jarkko Sakkinen,jarkko.sakkinen@linux.intel.com,1,0,579,1.0,1.0,0.25,0.1111111111111111,0,0.7142857142857143,0.14285714285714285,0.7142857142857143,0.0
162,571417,571702,civil,This is phenomenal. Thank you so much for digging into this. I'm hoping this will greatly reduce the risk of future leakage.,571698,technical,Agreed... it seems fishy at least.  ,Agreed... it seems fishy at least.   This is phenomenal. Thank you so much for digging into this. I'm hoping this will greatly reduce the risk of future leakage.,Unkown Name,hpa@zytor.com,0,0,161,1.0,1.0,0.3333333333333333,0.3333333333333333,0,0.0,0.9767441860465116,0.0,0.0
