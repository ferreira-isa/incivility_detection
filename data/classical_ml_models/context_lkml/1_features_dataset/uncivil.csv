Unnamed: 0,thread_id,email_id,email_code,email_body,previous_email_id,previous_email_code,previous_email_body,concat_body,author_name,author_email,author_role,is_first_author_thread,nr_characters,ratio_words_email_thread,ratio_words_email_comment,position_sentence_comment,position_sentence_thread,is_last_comment,time_start_to_email,time_email_to_end,time_previous_to_email,time_email_to_next
0,152625,156564,uncivil,"How do you plan to handle the external references? For example, the following LWN articles has a link this file. And changing the name and/or location will break that link, AFAIK.",156500,uncivil,"So I hate this rst crap with a passion, so NAK from me.","So I hate this rst crap with a passion, so NAK from me. How do you plan to handle the external references? For example, the following LWN articles has a link this file. And changing the name and/or location will break that link, AFAIK.",Boqun Feng,boqun.feng@gmail.com,1,0,235,0.18085106382978725,1.0,0.5,0.5454545454545454,0,0.0,0.5,0.0,0.0
1,152625,156500,uncivil,"So I hate this rst crap with a passion, so NAK from me.",152625,technical,"Let PDF & HTML's be created out of memory-barriers Text by reStructuring.  reStructuring done were, 1. Section headers modification, lower header case except start 2. Removal of manual index(contents section), since it now gets created    automatically for html/pdf 3. Internal cross reference for easy navigation 4. Alignment adjustments 5. Strong emphasis made wherever there was emphasis earlier (through    other ways), strong was chosen as normal emphasis showed in italics,    which was felt to be not enough & strong showed it in bold 6. ASCII text & code snippets in literal blocks 7. Backquotes for inline instances in the paragraph's where they are    expressed not in English, but in C, pseudo-code, file path etc. 8. Notes section created out of the earlier notes 9. Manual numbering replaced by auto-numbering 10.Bibliography (References section) made such that it can be cross-linked.   Hi,  With this change, pdf & html could be generated. There certainly are improvements to be made, but thought of first knowing whether migrating memory-barriers from txt to rst is welcome.  The location chosen is Documentation/kernel-hacking"", i was unsure where this should reside & there was no .rst file in top-level directory ""Documentation"", so put it into one of the existing folder that seemed to me as not that unsuitable.  Other files refer to memory-barrier.txt, those also needs to be adjusted based on where .rst can reside.   ","Let PDF & HTML's be created out of memory-barriers Text by reStructuring.  reStructuring done were, 1. Section headers modification, lower header case except start 2. Removal of manual index(contents section), since it now gets created    automatically for html/pdf 3. Internal cross reference for easy navigation 4. Alignment adjustments 5. Strong emphasis made wherever there was emphasis earlier (through    other ways), strong was chosen as normal emphasis showed in italics,    which was felt to be not enough & strong showed it in bold 6. ASCII text & code snippets in literal blocks 7. Backquotes for inline instances in the paragraph's where they are    expressed not in English, but in C, pseudo-code, file path etc. 8. Notes section created out of the earlier notes 9. Manual numbering replaced by auto-numbering 10.Bibliography (References section) made such that it can be cross-linked.   Hi,  With this change, pdf & html could be generated. There certainly are improvements to be made, but thought of first knowing whether migrating memory-barriers from txt to rst is welcome.  The location chosen is Documentation/kernel-hacking"", i was unsure where this should reside & there was no .rst file in top-level directory ""Documentation"", so put it into one of the existing folder that seemed to me as not that unsuitable.  Other files refer to memory-barrier.txt, those also needs to be adjusted based on where .rst can reside.    So I hate this rst crap with a passion, so NAK from me.",Peter Zijlstra,peterz@infradead.org,1,0,1497,1.0,1.0,1.0,1.0,0,0.0,0.5,0.0,0.0
2,152625,156871,uncivil,"IMO symlinks are mostly ending in a mess, URLs are never stable. There is a link to handle such requirements. Take a look at intersphinx to see how it works:  Each Sphinx HTML build creates a file named objects.inv that contains a mapping from object names to URIs relative to the HTML set's root. This means articles from external (like lwn articles) has to be recompiled. Not perfect, but a first solution. I really like them, factually valuable comments .. please express your concern so that we have a chance to move on. I think that's a pity.",156614,technical,"If necessary to handle these, symlink might help here i believe.  Upon trying to understand memory-barriers.txt, i felt that it might be better to have it in PDF/HTML format, thus attempted to convert it to rst. And i see it not being welcomed, hence shelving the conversion.","If necessary to handle these, symlink might help here i believe.  Upon trying to understand memory-barriers.txt, i felt that it might be better to have it in PDF/HTML format, thus attempted to convert it to rst. And i see it not being welcomed, hence shelving the conversion. IMO symlinks are mostly ending in a mess, URLs are never stable. There is a link to handle such requirements. Take a look at intersphinx to see how it works:  Each Sphinx HTML build creates a file named objects.inv that contains a mapping from object names to URIs relative to the HTML set's root. This means articles from external (like lwn articles) has to be recompiled. Not perfect, but a first solution. I really like them, factually valuable comments .. please express your concern so that we have a chance to move on. I think that's a pity.",Markus Heiser,markus.heiser@darmarit.de,0,0,823,0.5921985815602837,1.0,0.1111111111111111,0.5909090909090909,0,0.5,0.0,0.0,0.0
4,159308,177720,uncivil,"A version of this patch has been queued by Catalin. Now that the cpufeature bits are queued, I think this can be split up into two separate series for v4.16-rc1, one to tackle NOTIFY_SEI and the associated plumbing. The second for the KVM 'make SError pending' API. I didn't sign-off this patch. If you pick some bits from another version and want to credit someone else you can 'CC:' them or just mention it in the commit-message. Irrelevant-Nit: sys-regs usually have a 'SYS_' prefix, and are in instruction encoding order lower down the file. (These PSTATE PAN things are a bit odd as they were used to generate and instruction before the fancy {read,write}_sysreg() helpers were added). Bits of this are spread between patches 5 and 6. If you put them in the other order this wouldn't happen. (but after a rebase most of this patch should disappear) So this writes an impdef ESR, because its the existing code-path in KVM. And then you overwrite it. Which is a bit odd as there is a helper to do both in one go. How come you don't use this in kvm_arm_set_sei_esr()?",177719,technical,"After this patch user-space can trigger an SError in the guest. If it wants to migrate the guest, how does the pending SError get migrated?  I think we need to fix migration first. Andrew Jones suggested using this:  Given KVM uses kvm_inject_vabt() on v8.0 hardware too, we should cover systems without the v8.2 RAS Extensions with the same API. I think this means a bit to read/write whether SError is pending, and another to indicate the ESR should be set/read. CPUs without the v8.2 RAS Extensions can reject pending-SError that had an ESR.  user-space can then use the 'for migration' calls to make a 'new' SError pending.  Now that the cpufeature bits are queued, I think this can be split up into two separate series for v4.16-rc1, one to tackle NOTIFY_SEI and the associated plumbing. The second for the KVM 'make SError pending' API.    Does nothing in the patch that adds the support? This is a bit odd. (oh, its hiding in patch 6...)","After this patch user-space can trigger an SError in the guest. If it wants to migrate the guest, how does the pending SError get migrated?  I think we need to fix migration first. Andrew Jones suggested using this:  Given KVM this function on v8.0 hardware too, we should cover systems without the v8.2 RAS Extensions with the same API. I think this means a bit to read/write whether SError is pending, and another to indicate the ESR should be set/read. CPUs without the v8.2 RAS Extensions can reject pending-SError that had an ESR.  user-space can then use the 'for migration' calls to make a 'new' SError pending.  Now that the cpufeature bits are queued, I think this can be split up into two separate series for this version, one to tackle NOTIFY_SEI and the associated plumbing. The second for the KVM 'make SError pending' API.    Does nothing in the patch that adds the support? This is a bit odd. (oh, its hiding in patch 6...) A version of this patch has been queued by Catalin. Now that the cpufeature bits are queued, I think this can be split up into two separate series for this version, one to tackle NOTIFY_SEI and the associated plumbing. The second for the KVM 'make SError pending' API. I didn't sign-off this patch. If you pick some bits from another version and want to credit someone else you can 'CC:' them or just mention it in the commit-message. Irrelevant-Nit: sys-regs usually have a 'SYS_' prefix, and are in instruction encoding order lower down the file. (These PSTATE PAN things are a bit odd as they were used to generate and instruction before the fancy helpers were added). Bits of this are spread between patches 5 and 6. If you put them in the other order this wouldn't happen. (but after a rebase most of this patch should disappear) So this writes an impdef ESR, because its the existing code-path in KVM. And then you overwrite it. Which is a bit odd as there is a helper to do both in one go. How come you don't use this in this function?",James Morse,james.morse@arm.com,1,0,1981,1.0,1.0,0.07692307692307693,0.07692307692307693,0,0.17708333333333334,0.8229166666666666,0.0,0.010416666666666666
5,161354,161783,uncivil,"For 2500Base-X, do you report a speed of 2500Mbps through ethtool, or are you reporting 1000Mbps?  I don't see any code in this patch that deals with that.",161722,technical,Thanks for adding the comment. ,"Thanks for adding the comment.  For 2500Base-X, do you report a speed of 2500Mbps through ethtool, or are you reporting 1000Mbps?  I don't see any code in this patch that deals with that.",Russell King - ARM Linux,linux@armlinux.org.uk,1,0,187,1.0,1.0,0.16666666666666666,0.16666666666666666,0,0.0,0.0,0.0,0.0
7,165657,169349,uncivil,"Can you please use a consistent name space? retpoline_ ... or such? I really don't like fiddling with that variable. That's just hackery. The variable reflects the actual enabled mitigation state of the kernel proper. That'll break once we get other mitigation variants. These newlines are there to separate stuff for readability sake. This really can be done in a cleaner way. That only needs one function and that one can take care of setting a
variable in the spectre code which then influences the sysfs output. And that output should not be ""Vulnerable"" like you force with the hack above. It actually should tell WHY it is vulnerable despite having had protection in place before the module was loaded.",165657,technical," There's a risk that a kernel that has full retpoline mitigations becomes vulnerable when a module gets loaded that hasn't been compiled with the right compiler or the right option.  We cannot fix it, but should at least warn the user when that happens.  When the a module hasn't been compiled with a retpoline aware compiler, print a warning and change the SPECTRE_V2 mitigation mode to show the system is vulnerable now.  For modules it is checked at compile time, however it cannot check assembler or other non compiled objects used in the module link.  v2: Change warning message v3.","There's a risk that a kernel that has full retpoline mitigations becomes vulnerable when a module gets loaded that hasn't been compiled with the right compiler or the right option.  We cannot fix it, but should at least warn the user when that happens.  When the a module hasn't been compiled with a retpoline aware compiler, print a warning and change the SPECTRE_V2 mitigation mode to show the system is vulnerable now.  For modules it is checked at compile time, however it cannot check assembler or other non compiled objects used in the module link.  v2: Change warning message v3. Can you please use a consistent name space? retpoline ... or such? I really don't like fiddling with that variable. That's just hackery. The variable reflects the actual enabled mitigation state of the kernel proper. That'll break once we get other mitigation variants. These newlines are there to separate stuff for readability sake. This really can be done in a cleaner way. That only needs one function and that one can take care of setting a
variable in the spectre code which then influences the sysfs output. And that output should not be ""Vulnerable"" like you force with the hack above. It actually should tell WHY it is vulnerable despite having had protection in place before the module was loaded.",Thomas Gleixner,tglx@linutronix.de,1,0,1294,1.0,1.0,0.08333333333333333,0.08333333333333333,0,1.0,0.0,1.0,0.0
8,166193,168161,uncivil,I didn't get any response to a comment I've written about the point above during the previous patch iteration.,168038,technical,tested v3... ,tested v3...  I didn't get any response to a comment I've written about the point above during the previous patch iteration.,Maciej S. Szmigiero,mail@maciej.szmigiero.name,0,0,124,1.0,1.0,0.5,0.5,0,0.0,0.0,0.0,0.0
10,168060,169219,uncivil,This does not make sense vs. the documentation. This should say: And I really have to ask whether this should be named GLOBAL instead of SHARED. Hmm?,168063,technical,Test the new MEMBARRIER_CMD_PRIVATE_EXPEDITED_SYNC_CORE and MEMBARRIER_CMD_REGISTER_PRIVATE_EXPEDITED_SYNC_CORE commands.,Test the new commands. This does not make sense vs. the documentation. This should say: And I really have to ask whether this should be named GLOBAL instead of SHARED. Hmm?,Thomas Gleixner,tglx@linutronix.de,1,0,172,1.0,1.0,0.3333333333333333,0.3333333333333333,0,0.0,0.0,0.0,0.0
12,168668,168727,uncivil,"Again, 'boutside' protection  Other than that. Reviewed.",168726,technical,"boutside protection'?  In general I'd rather have the tracepoints when actually submitting the request, with this tracepoint we might be getting a trace which doesn't really indicate if the command was submitted at all.","boutside protection'?  In general I'd rather have the tracepoints when actually submitting the request, with this tracepoint we might be getting a trace which doesn't really indicate if the command was submitted at all. Again, 'boutside' protection. Other than that. Reviewed.",Hannes Reinecke,hare@suse.de,1,0,276,1.0,1.0,0.5,0.5,0,0.0,0.0,0.0,0.0
13,169133,177084,uncivil,"The timer is supposed to restart the protocol again, that's how this whole thing is designed to work. I think you are making changes to the symptom rather than the true because of the problems you are seeing. Sorry, I will not apply this until the exact issue is better understood.",169133,technical,"In drivers/net/wan/hdlc_ppp.c, some noise on physical line can cause the carrier detect still ok, but the protocol will fail. So if carrier detect ok, don't turn off protocol negotiation  This patch is against the kernel version Linux 4.15-rc8","In this file, some noise on physical line can cause the carrier detect still ok, but the protocol will fail. So if carrier detect ok, don't turn off protocol negotiation  This patch is against the kernel version Linux 4.15-rc8 The timer is supposed to restart the protocol again, that's how this whole thing is designed to work. I think you are making changes to the symptom rather than the true because of the problems you are seeing. Sorry, I will not apply this until the exact issue is better understood.",David Miller,davem@davemloft.net,1,0,508,0.38697318007662834,1.0,0.25,0.6428571428571429,0,0.16216216216216217,0.8108108108108109,0.16216216216216217,0.0
14,169133,177642,uncivil,"Ok, I check the source code again. It have nothing to do with the interrupts, it is related how the hdlc.c is implemented. My case is the carrier always good, but protocol will fail due to perfect noise, and this issue was found and complained by our customers. So it is not my theory guessing, it is a real problem.",177133,technical,"The timer is supposed to be triggered by carrier detect interrupt. After remove the line noise, the carrier detect interrupt is never triggered again, because the carrier is always ok and it only trigger the timer once, Since the protocol was terminated and no new interrupts happen, the link will never be back. So the case here is that the line noise is good and just good to make the carrier detect still good  but the protocol fail, the timer will be never triggered again.  Of course, if you increase the noise and make even the carrier detect fail, then remove the noise, the link will be up, Because the carrier down and up again and then trigger the timer to restart. The timer is supposed to restart the protocol again, that's how this whole thing is designed to work.  I think you are making changes to the symptom rather than the true cause of the problems you are seeing.  Sorry, I will not apply this until the exact issue is better understood.","The timer is supposed to be triggered by carrier detect interrupt. After remove the line noise, the carrier detect interrupt is never triggered again, because the carrier is always ok and it only trigger the timer once, Since the protocol was terminated and no new interrupts happen, the link will never be back. So the case here is that the line noise is good and just good to make the carrier detect still good  but the protocol fail, the timer will be never triggered again.  Of course, if you increase the noise and make even the carrier detect fail, then remove the noise, the link will be up, Because the carrier down and up again and then trigger the timer to restart. The timer is supposed to restart the protocol again, that's how this whole thing is designed to work.  I think you are making changes to the symptom rather than the true cause of the problems you are seeing.  Sorry, I will not apply this until the exact issue is better understood. Ok, I check the source code again. It have nothing to do with the interrupts, it is related how the hdlc.c is implemented. My case is the carrier always good, but protocol will fail due to perfect noise, and this issue was found and complained by our customers. So it is not my theory guessing, it is a real problem.",Denis Du,dudenis2000@yahoo.ca,0,1,1274,1.0,1.0,0.16666666666666666,0.8809523809523809,0,0.1891891891891892,0.8108108108108109,0.0,0.10810810810810811
17,169133,204633,uncivil,"I cannot apply a patch which has been corrupted by your email client like
this.

Please send it properly again, plain ASCII text, and no trasnformations
by your email client.
You should send the patch to yourself and try to apply the patch you receive, do not send to the list until you can pass the test properly. Do not use attachments to fix this problem, the patch must be inline after your commit message and signoffs. Please read these for more information.",203117,technical,"How  is your thinking about this patch? Subject: netdev: carrier detect ok, don't turn off negotiation   Sometimes when physical lines have a just good noise to make the protocol  handshaking fail, but the carrier detect still good. Then after remove of  the noise, nobody will trigger this protocol to be start again to cause  the link to never come back. The fix is when the carrier is still on, not  terminate the protocol handshaking.  Ok, I submit it  again.   In drivers/net/wan/hdlc_ppp.c, some noise on physical line can cause the carrier detect still ok, but the protocol will fail. So if carrier detect ok, don't turn off protocol negotiation  This patch is against the kernel version Linux 4.15-rc8 Please resubmit it and I'll think about it again, thank you.","How  is your thinking about this patch? Subject: netdev: carrier detect ok, don't turn off negotiation   Sometimes when physical lines have a just good noise to make the protocol  handshaking fail, but the carrier detect still good. Then after remove of  the noise, nobody will trigger this protocol to be start again to cause  the link to never come back. The fix is when the carrier is still on, not  terminate the protocol handshaking.  Ok, I submit it  again.   In this file, some noise on physical line can cause the carrier detect still ok, but the protocol will fail. So if carrier detect ok, don't turn off protocol negotiation  This patch is against the kernel version Linux 4.15-rc8 Please resubmit it and I'll think about it again, thank you. I cannot apply a patch which has been corrupted by your email client like this. Please send it properly again, plain ASCII text, and no transformations by your email client.
You should send the patch to yourself and try to apply the patch you receive, do not send to the list until you can pass the test properly. Do not use attachments to fix this problem, the patch must be inline after your commit message and signoffs. Please read these for more information.",David Miller,davem@davemloft.net,1,0,1216,0.9310344827586207,1.0,0.16666666666666666,0.7380952380952381,1,1.0,0.0,0.02702702702702703,0.0
18,170193,170197,uncivil,"Please don't put plain-text files into core-api - that's a directory full
of RST documents.  Your document is 99.9% RST already, better to just
finish the job and tie it into the rest of the kernel docs.


We might as well put the SPDX tag here, it's a new file.


This is all good information, but I'd suggest it belongs more in the 0/n
patch posting than here.  The introduction of *this* document should say what it actually covers. This seems like a relevant and important aspect of the API that shouldn't be buried in the middle of a section talking about random things. So one gets this far, but has no actual idea of how to do these things. Which leads me to wonder: what is this document for?  Who are you expecting to read it? You could improve things a lot by (once again) going to RST and using directives to bring in the kerneldoc comments from the source (which, I note, do exist).  But I'd suggest rethinking this document and its audience.  Most of the people reading it are likely wanting to learn how to *use* this API; I think it would be best to not leave them frustrated.",170198,technical,Add basic self-test functionality for pmalloc.,"Add basic self-test functionality for pmalloc. Please don't put plain-text files into core-api - that's a directory full of RST documents.  Your document is 99.9% RST already, better to just finish the job and tie it into the rest of the kernel docs. We might as well put the SPDX tag here, it's a new file.

This is all good information, but I'd suggest it belongs more in the 0/n patch posting than here.  The introduction of *this* document should say what it actually covers. This seems like a relevant and important aspect of the API that shouldn't be buried in the middle of a section talking about random things. So one gets this far, but has no actual idea of how to do these things. Which leads me to wonder: what is this document for?  Who are you expecting to read it? You could improve things a lot by (once again) going to RST and using directives to bring in the kerneldoc comments from the source (which, I note, do exist).  But I'd suggest rethinking this document and its audience.  Most of the people reading it are likely wanting to learn how to *use* this API; I think it would be best to not leave them frustrated.",Jonathan Corbet,corbet@lwn.net,1,0,1135,0.9420849420849421,1.0,0.07692307692307693,0.4411764705882353,0,0.0,1.0,0.0,0.07692307692307693
19,170193,188751,uncivil,"Relatively significant? I do not object to your comment, but in practice i see that:
- vmalloc is used relatively little
- allocations do not seem to be huge
- there seem to be way larger overheads in the handling of virtual pages (see my proposal for the LFS/m summit, about collapsing struct vm_struct and struct vmap_area)
Can you please point me to this function/macro? I don't seem to be able to find it, at least not in 4.15. During hardened user copy permission check, I need to confirm if the memory range that would be exposed to userspace is a legitimate sub-range of a pmalloc allocation. So, I start with the pair (address, size) and I must end up to something I can compare it against. The idea here is to pass through struct_page and then the related vmap area, which already has the information about the specific chunk of virtual memory. I cannot comment on your proposal because I do not know where to find the reference you made, or maybe I do not understand what you mean :sad:",170195,technical,Well this introduces significant overhead for large sized allocation. Does this not matter because the areas are small?  Would it not be better to use compound page allocations here? page_head(whatever) gets you the head page where you can store all sorts of information about the chunk of memory.,"Well this introduces significant overhead for large sized allocation. Does this not matter because the areas are small?  Would it not be better to use compound page allocations here? page_head(whatever) gets you the head page where you can store all sorts of information about the chunk of memory. Relatively significant? I do not object to your comment, but in practice i see that:
- vmalloc is used relatively little
- allocations do not seem to be huge
- there seem to be way larger overheads in the handling of virtual pages (see my proposal for the LFS/m summit, about collapsing struct vm_struct and struct vmap_area)
Can you please point me to this function/macro? I don't seem to be able to find it, at least not in 4.15. During hardened user copy permission check, I need to confirm if the memory range that would be exposed to userspace is a legitimate sub-range of a pmalloc allocation. So, I start with the pair (address, size) and I must end up to something I can compare it against. The idea here is to pass through struct_page and then the related vmap area, which already has the information about the specific chunk of virtual memory. I cannot comment on your proposal because I do not know where to find the reference you made, or maybe I do not understand what you mean :sad:",Igor Stoppa,igor.stoppa@huawei.com,0,1,1294,1.0,1.0,0.14285714285714285,0.8235294117647058,0,0.07692307692307693,0.8461538461538461,0.0,0.0
21,173287,173288,uncivil,You can't do it this simply as it will cause deadlock due to nested locking of the buf_lock. To share the lock you will need to provide unlocked versions of the read and write functions and use those if the lock has already been taken.,173287,technical,This is to be used only by the IIO core for protecting device mode changes between INDIO_DIRECT and INDIO_BUFFER.  This patch replaces the use of mlock with the already established buf_lock mutex. ,This is to be used only by the IIO core for protecting device mode changes between INDIO_DIRECT and INDIO_BUFFER.  This patch replaces the use of mlock with the already established buf_lock mutex.  You can't do it this simply as it will cause deadlock due to nested locking of the buf_lock. To share the lock you will need to provide unlocked versions of the read and write functions and use those if the lock has already been taken.,Jonathan Cameron,jic23@kernel.org,1,0,433,1.0,1.0,0.5,0.5,1,0.0,0.0,0.0,0.0
22,174463,174508,uncivil,Ok. I've looked at your patch for way too long now and still don't see how you've shown it to be correct. Shouldn't there be a at least a comment to explain why zero is an appropriate initialization value in that case?,174487,technical, I already sent a fix for this., I already sent a fix for this. Ok. I've looked at your patch for way too long now and still don't see how you've shown it to be correct. Shouldn't there be a at least a comment to explain why zero is an appropriate initialization value in that case?,Arnd Bergmann,arnd@arndb.de,1,1,250,1.0,1.0,0.3333333333333333,0.3333333333333333,0,0.0,0.0,0.0,0.0
23,174735,174850,uncivil,Are you moving checks from the core subsystem to drivers ? This looks really nonsensical and the commit message doesn't explain the rationale for that at all.,174736,technical,"Export and import are mandatory in async hash. As drivers were rewritten, drop empty wrappers and correct init of ahash transformation. ","Export and import are mandatory in async hash. As drivers were rewritten, drop empty wrappers and correct init of ahash transformation.  Are you moving checks from the core subsystem to drivers ? This looks really nonsensical and the commit message doesn't explain the rationale for that at all.",Marek Vasut,marex@denx.de,1,0,295,0.33125,1.0,0.5,0.037037037037037035,0,0.0,1.0,0.0,0.0
24,174735,199553,uncivil,"This makes no sense, cfr my comment on 5/5. Seems like if the driver doesn't implement those, the core can easily detect that and perform the necessary action. Moving the checks out of core seems like the wrong thing to do, rather you should enhance the checks in core if they're insufficient in my opinion.",199556,technical,All applied.  Thanks. ,"All applied.  Thanks.  This makes no sense, cfr my comment on 5/5. Seems like if the driver doesn't implement those, the core can easily detect that and perform the necessary action. Moving the checks out of core seems like the wrong thing to do, rather you should enhance the checks in core if they're insufficient in my opinion.",Marek Vasut,marex@denx.de,1,0,330,0.425,1.0,0.3333333333333333,0.1111111111111111,0,0.9642857142857143,0.0,0.0,0.0
25,174735,199600,uncivil,"The core can very well check if these functions are not populated and
return ENOSYS. So you remove all NULL pointer checks ? Esp. in security-sensitive code? What is the impact of this non-critical path code on performance? Come on ... You can very well impose that in the core, except you don't duplicate the code.",199597,technical,"The bug can only be in driver which will not implement those two functions, but we already had all drivers with those due to patches 1..4 All other drivers do have them.  Additionally, with crypto we want minimize code and run as fast as possible.  Moving checks out of core will impose on driver author need for implement those functions, or declare them empty, but in case of empty ones  crypto will not work properly with such driver. ","The bug can only be in driver which will not implement those two functions, but we already had all drivers with those due to patches 1..4 All other drivers do have them.  Additionally, with crypto we want minimize code and run as fast as possible.  Moving checks out of core will impose on driver author need for implement those functions, or declare them empty, but in case of empty ones  crypto will not work properly with such driver.  The core can very well check if these functions are not populated and return ENOSYS. So you remove all NULL pointer checks ? Esp. in security-sensitive code? What is the impact of this non-critical path code on performance? Come on ... You can very well impose that in the core, except you don't duplicate the code.",Marek Vasut,marex@denx.de,1,0,754,0.9375,1.0,0.16666666666666666,0.2222222222222222,0,0.9642857142857143,0.0,0.0,0.0
26,174735,199673,uncivil,"Why you want checks for something that not exist ? Those without them will not work and will do Oops in crypto testmgr, so such drivers should not be used nor accepted in drivers/crypto. Ask yourself why crypto do not check for NULL in ahash digest or other required ahash functions. Now size of crypto core is reduced.",199600,uncivil,"The core can very well check if these functions are not populated and return ENOSYS. So you remove all NULL pointer checks ? Esp. in security-sensitive code? What is the impact of this non-critical path code on performance?  Come on ...   You can very well impose that in the core, except you don't duplicate the code. ","The core can very well check if these functions are not populated and return ENOSYS. So you remove all NULL pointer checks ? Esp. in security-sensitive code? What is the impact of this non-critical path code on performance?  Come on ...   You can very well impose that in the core, except you don't duplicate the code.  Why you want checks for something that not exist ? Those without them will not work and will do Oops in crypto testmgr, so such drivers should not be used nor accepted in drivers/crypto. Ask yourself why crypto do not check for NULL in ahash digest or other required ahash functions. Now size of crypto core is reduced.",Kamil Konieczny,k.konieczny@partner.samsung.com,0,1,639,0.78125,1.0,0.3333333333333333,0.4444444444444444,0,0.9642857142857143,0.0,0.0,0.0
27,174735,199701,uncivil,"Are you suggesting that the kernel code should NOT perform NULL pointer checks? Are you suggesting each driver should implement every single callback available and if it is not implemented, return -ENOSYS ? This looks like a MASSIVE code duplication. You implemented the same code thrice, it surely is not reduced.",199673,uncivil,"Why you want checks for something that not exist ? Those without them will not work and will do Oops in crypto testmgr, so such drivers should not be used nor accepted in drivers/crypto  Ask yourself why crypto do not check for NULL in ahash digest or other required ahash functions.   Now size of crypto core is reduced. ","Why you want checks for something that not exist ? Those without them will not work and will do Oops in crypto testmgr, so such drivers should not be used nor accepted in drivers/crypto  Ask yourself why crypto do not check for NULL in ahash digest or other required ahash functions.   Now size of crypto core is reduced.  Are you suggesting that the kernel code should NOT perform NULL pointer checks? Are you suggesting each driver should implement every single callback available and if it is not implemented, return -ENOSYS ? This looks like a MASSIVE code duplication. You implemented the same code thrice, it surely is not reduced.",Marek Vasut,marex@denx.de,1,0,637,0.73125,1.0,0.25,0.5555555555555556,0,0.9642857142857143,0.0,0.0,0.0
28,174735,200015,uncivil,"You can compile kernel with generic config and at that point you have all the duplicated code stored on your machine. But this discussion is moving away from the point I was concerned about -- that this patchset _increases_ code duplication and I find this wrong. It does NOT reduce the binary size, just try compiling all the drivers in and it will make the kernel bigger.",199976,uncivil,"It is source code duplication. One do not load all crypto drivers at once, simple because one board has only one crypto HW (or few closely related), and if one even try, almost none of them will initialize on given hardware. E.g. on Exynos board only exynos drivers will load, on board with omap crypto only omap crypto will load. As I said above, it reduces binary size at cost of more source code in few drivers. ","It is source code duplication. One do not load all crypto drivers at once, simple because one board has only one crypto HW (or few closely related), and if one even try, almost none of them will initialize on given hardware. E.g. on Exynos board only exynos drivers will load, on board with omap crypto only omap crypto will load. As I said above, it reduces binary size at cost of more source code in few drivers.  You can compile kernel with generic config and at that point you have all the duplicated code stored on your machine. But this discussion is moving away from the point I was concerned about -- that this patchset _increases_ code duplication and I find this wrong. It does NOT reduce the binary size, just try compiling all the drivers in and it will make the kernel bigger.",Marek Vasut,marex@denx.de,1,0,789,1.0,1.0,0.3333333333333333,0.7037037037037037,1,1.0,0.0,0.0,0.0
29,174735,199976,uncivil,"It is source code duplication. One do not load all crypto drivers at once, simple because one board has only one crypto HW (or few closely related), and if one even try, almost none of them will initialize on given hardware. E.g. on Exynos board only exynos drivers will load, on board with omap crypto only omap crypto will load. As I said above, it reduces binary size at cost of more source code in few drive",199701,uncivil,"Are you suggesting that the kernel code should NOT perform NULL pointer checks ?  Are you suggesting each driver should implement every single callback available and if it is not implemented, return -ENOSYS ? This looks like a MASSIVE code duplication.   You implemented the same code thrice, it surely is not reduced. ","Are you suggesting that the kernel code should NOT perform NULL pointer checks ?  Are you suggesting each driver should implement every single callback available and if it is not implemented, return -ENOSYS ? This looks like a MASSIVE code duplication.   You implemented the same code thrice, it surely is not reduced.  It is source code duplication. One do not load all crypto drivers at once, simple because one board has only one crypto HW (or few closely related), and if one even try, almost none of them will initialize on given hardware. E.g. on Exynos board only exynos drivers will load, on board with omap crypto only omap crypto will load. As I said above, it reduces binary size at cost of more source code in few drive",Kamil Konieczny,k.konieczny@partner.samsung.com,0,1,731,0.9,1.0,0.16666666666666666,0.8148148148148148,0,1.0,0.0,0.0,0.0
32,202437,202446,uncivil,"Use normal patch styles.
Fix your tools before you send any more patches.",202444,technical,"The variables dssdev"" and ""vid_dev"" will eventually be set to appropriate pointers a bit later. Thus omit the explicit initialisations at the beginning.  ","The variables dssdev"" and ""vid_dev"" will eventually be set to appropriate pointers a bit later. Thus omit the explicit initialisations at the beginning.   Use normal patch styles.
Fix your tools before you send any more patches.",Joe Perches,joe@perches.com,1,0,228,0.16475095785440613,1.0,0.5,0.018867924528301886,0,0.0,1.0,0.0,0.2536231884057971
33,202437,505099,uncivil,"While we do not mind cleanup patches, the way you post them (one fix per file) is really annoying and takes us too much time to review. I'll take the ""Fix a possible null pointer"" patch since it is an actual bug fix, but will reject the others, not just this driver but all of them that are currently pending in our patchwork (https://patchwork.linuxtv.org). Feel free to repost, but only if you organize the patch as either fixing the same type of issue for a whole subdirectory (media/usb, media/pci, etc) or fixing all issues for a single driver. Actual bug fixes (like the null pointer patch in this series) can still be posted as separate patches, but cleanups shouldn't. So in this particular case I would expect two omap_vout patches: one for the bug fix, one for the cleanups. Just so you know, I'll reject any future patch series that do not follow these rules. Just use common sense when posting these things in the future. I would also suggest that your time might be spent more productively if you would work on some more useful projects. There is more than enough to do. However, that's up to you.",202446,uncivil,Use normal patch styles. Fix your tools before you send any more patches.,"Use normal patch styles. Fix your tools before you send any more patches. While we do not mind cleanup patches, the way you post them (one fix per file) is really annoying and takes us too much time to review. I'll take the ""Fix a possible null pointer"" patch since it is an actual bug fix, but will reject the others, not just this driver but all of them that are currently pending in our patchwork. Feel free to repost, but only if you organize the patch as either fixing the same type of issue for a whole subdirectory (media/usb, media/pci, etc) or fixing all issues for a single driver. Actual bug fixes (like the null pointer patch in this series) can still be posted as separate patches, but cleanups shouldn't. So in this particular case I would expect two omap_vout patches: one for the bug fix, one for the cleanups. Just so you know, I'll reject any future patch series that do not follow these rules. Just use common sense when posting these things in the future. I would also suggest that your time might be spent more productively if you would work on some more useful projects. There is more than enough to do. However, that's up to you.",Hans Verkuil,hverkuil@xs4all.nl,1,0,1152,0.9425287356321839,1.0,0.1,0.05660377358490566,0,0.2536231884057971,0.7463768115942029,0.2536231884057971,0.0
34,202437,505195,uncivil,"??? I did that: either one patch per directory with the same type of change,
or one patch per driver combining all the changes for that driver. Yes, and you were told not to do it like that again.",505193,uncivil,"Interesting... Would you like to share any more information from this meeting?    I would appreciate further indications for a corresponding change acceptance.  I found a feedback by Mauro Carvalho Chehab more constructive. Cleanup fixes. This time, I was nice and I took some time doing this.","Interesting... Would you like to share any more information from this meeting? I would appreciate further indications for a corresponding change acceptance.  I found a feedback by Mauro Carvalho Chehab more constructive. Cleanup fixes. This time, I was nice and I took some time doing this. ??? I did that: either one patch per directory with the same type of change, or one patch per driver combining all the changes for that driver. Yes, and you were told not to do it like that again.",Hans Verkuil,hverkuil@xs4all.nl,1,0,487,0.3793103448275862,1.0,0.5,0.2641509433962264,0,0.2608695652173913,0.7391304347826086,0.0,0.0
35,202437,505193,uncivil,Interesting  Would you like to share any more information from this meeting? I would appreciate further indications for a corresponding change acceptance. I found a feedback by Mauro Carvalho Chehab more constructive.,505158,technical,For the record: this only applies to drivers/media. We discussed what do to with series like this during our media summit last Friday and this was the conclusion of that. Obviously I can't talk about other subsystems.,For the record: this only applies to drivers/media. We discussed what do to with series like this during our media summit last Friday and this was the conclusion of that. Obviously I can't talk about other subsystems. Interesting  Would you like to share any more information from this meeting? I would appreciate further indications for a corresponding change acceptance. I found a feedback by Mauro Carvalho Chehab more constructive.,SF Markus Elfring,elfring@users.sourceforge.net,0,1,435,0.2950191570881226,1.0,0.3333333333333333,0.6981132075471698,0,0.2608695652173913,0.7391304347826086,0.0,0.0
36,202437,513970,uncivil,"I find it very surprising that you rejected 146 useful update suggestions
so easily. What does this software area make it so special in comparison to
other Linux subsystems? Have you taken any other solution approaches into account than a quick rejection? Could your reaction have been different if the remarkable number of change possibilities were sent by different authors (and not only me)? How should possibly remaining disagreements about affected implementation details be resolved now? Are you looking for further improvements around development tools like patchwork and quilt? Will you accept increasing risks because of bigger patch sizes? Can such an information lead to differences in the preferred patch granularity? How do you think about this detail?
How would you ever like to clean up stuff in affected source files which was accumulated (or preserved somehow) over years? I guess that this handling will trigger more communication challenges. Our common sense seems to be occasionally different in significant ways. I distribute my software development capacity over several areas. Does your wording indicate a questionable signal for further contributions?",505225,technical,I have got an other impression.    I continued with the presentation of suggestions from my selection of change possibilities. It seems that there are very different expectations for the preferred patch granularity.  Can it happen again that you are going to use a development tool like quilt (as a maintainer) for the desired recombination of possible update steps?,"I have got an other impression.    I continued with the presentation of suggestions from my selection of change possibilities. It seems that there are very different expectations for the preferred patch granularity.  Can it happen again that you are going to use a development tool like quilt (as a maintainer) for the desired recombination of possible update steps? I find it very surprising that you rejected 146 useful update suggestions
so easily. What does this software area make it so special in comparison to other Linux subsystems? Have you taken any other solution approaches into account than a quick rejection? Could your reaction have been different if the remarkable number of change possibilities were sent by different authors (and not only me)? How should possibly remaining disagreements about affected implementation details be resolved now? Are you looking for further improvements around development tools like patchwork and quilt? Will you accept increasing risks because of bigger patch sizes? Can such an information lead to differences in the preferred patch granularity? How do you think about this detail?
How would you ever like to clean up stuff in affected source files which was accumulated (or preserved somehow) over years? I guess that this handling will trigger more communication challenges. Our common sense seems to be occasionally different in significant ways. I distribute my software development capacity over several areas. Does your wording indicate a questionable signal for further contributions?",SF Markus Elfring,elfring@users.sourceforge.net,0,1,1547,1.0,1.0,0.07142857142857142,0.7547169811320755,0,0.2608695652173913,0.7391304347826086,0.0,0.18840579710144928
37,202437,745390,uncivil,Would you like to answer my still remaining questions in any more constructive ways?,513970,uncivil,I find it very surprising that you rejected 146 useful update suggestions so easily. What does this software area make it so special in comparison to other Linux subsystems? Have you taken any other solution approaches into account than a quick rejection? Could your reaction have been different if the remarkable number of  change possibilities were sent by different authors (and not only me)? How should possibly remaining disagreements about affected implementation   details be resolved now? Are you looking for further improvements around development tools   like patchwork and quilt?  Will you accept increasing risks because of bigger patch sizes?    Can such an information lead to differences in the preferred patch granularity? How do you think about this detail? How would you ever like to clean up stuff in affected source files which was accumulated (or preserved somehow) over years? I guess that this handling will trigger more communication challenges. Our common sense seems to be occasionally different in significant ways.  I distribute my software development capacity over several areas. Does your wording indicate a questionable signal for further contributions?,I find it very surprising that you rejected 146 useful update suggestions so easily. What does this software area make it so special in comparison to other Linux subsystems? Have you taken any other solution approaches into account than a quick rejection? Could your reaction have been different if the remarkable number of  change possibilities were sent by different authors (and not only me)? How should possibly remaining disagreements about affected implementation   details be resolved now? Are you looking for further improvements around development tools   like patchwork and quilt?  Will you accept increasing risks because of bigger patch sizes?    Can such an information lead to differences in the preferred patch granularity? How do you think about this detail? How would you ever like to clean up stuff in affected source files which was accumulated (or preserved somehow) over years? I guess that this handling will trigger more communication challenges. Our common sense seems to be occasionally different in significant ways.  I distribute my software development capacity over several areas. Does your wording indicate a questionable signal for further contributions? Would you like to answer my still remaining questions in any more constructive ways?,SF Markus Elfring,elfring@users.sourceforge.net,0,1,1272,0.8122605363984674,1.0,1.0,0.24528301886792453,0,0.45652173913043476,0.5434782608695652,0.18840579710144928,0.30434782608695654
38,202437,160227,uncivil,Are you going to answer any of my remaining questions in a more constructive way?,745390,uncivil,Would you like to answer my still remaining questions in any more constructive ways?,Would you like to answer my still remaining questions in any more constructive ways? Are you going to answer any of my remaining questions in a more constructive way?,SF Markus Elfring,elfring@users.sourceforge.net,0,1,166,0.11877394636015326,1.0,1.0,0.3018867924528302,0,0.7681159420289855,0.2318840579710145,0.30434782608695654,0.17391304347826086
39,202437,191235,uncivil,Do any contributors get into the mood to take another look at software updates from my selection of change possibilities in a more constructive way? Do you need any additional development resources?,160227,uncivil,Are you going to answer any of my remaining questions in a more constructive way?,Are you going to answer any of my remaining questions in a more constructive way? Do any contributors get into the mood to take another look at software updates from my selection of change possibilities in a more constructive way? Do you need any additional development resources?,SF Markus Elfring,elfring@users.sourceforge.net,0,1,280,0.19157088122605365,1.0,0.5,0.32075471698113206,0,0.9420289855072463,0.050724637681159424,0.17391304347826086,0.0
40,202437,191241,uncivil,"One last time: either post per-driver patches with all the cleanups for a driver in a single patch, or a per-directory patch (drivers/media/pci, usb, etc) doing the same cleanup for all drivers in that directory. I prefer the first approach, but it's up to you. We don't have the time to wade through dozens of one-liner cleanup patches. I don't understand what is so difficult about this.",191235,uncivil,Do any contributors get into the mood to take another look at software updates from my selection of change possibilities in a more constructive way?  Do you need any additional development resources?,"Do any contributors get into the mood to take another look at software updates from my selection of change possibilities in a more constructive way?  Do you need any additional development resources? One last time: either post per-driver patches with all the cleanups for a driver in a single patch, or a per-directory patch (drivers/media/pci, usb, etc) doing the same cleanup for all drivers in that directory. I prefer the first approach, but it's up to you. We don't have the time to wade through dozens of one-liner cleanup patches. I don't understand what is so difficult about this.",Hans Verkuil,hverkuil@xs4all.nl,1,0,589,0.44061302681992337,1.0,0.25,0.3584905660377358,0,0.9492753623188406,0.050724637681159424,0.0,0.0
41,202437,191275,uncivil,"I preferred to offer source code adjustments according to specific transformation patterns mostly for each software module separately (also in small patch series). I am curious if bigger patch packages would be easier to get accepted. Or would you get frightened still by any other change combination? We have got different preferences for a safe patch granularity. I imagine that there are more development factors involved. It is usual that integration of update suggestions will take some time. How would the situation change if I would dare to regroup possible update steps? There are communication difficulties to consider since your terse information from your conference meeting. If you would insist on patch squashing, would you dare to use a development tool like quilt fold also on your own once more?",191241,uncivil,"One last time: either post per-driver patches with all the cleanups for a driver in a single patch, or a per-directory patch (drivers/media/pci, usb, etc) doing the same cleanup for all drivers in that directory.  I prefer the first approach, but it's up to you.  We don't have the time to wade through dozens of one-liner cleanup patches.  I don't understand what is so difficult about this.","One last time: either post per-driver patches with all the cleanups for a driver in a single patch, or a per-directory patch (drivers/media/pci, usb, etc) doing the same cleanup for all drivers in that directory.  I prefer the first approach, but it's up to you.  We don't have the time to wade through dozens of one-liner cleanup patches.  I don't understand what is so difficult about this. I preferred to offer source code adjustments according to specific transformation patterns mostly for each software module separately (also in small patch series). I am curious if bigger patch packages would be easier to get accepted. Or would you get frightened still by any other change combination? We have got different preferences for a safe patch granularity. I imagine that there are more development factors involved. It is usual that integration of update suggestions will take some time. How would the situation change if I would dare to regroup possible update steps? There are communication difficulties to consider since your terse information from your conference meeting. If you would insist on patch squashing, would you dare to use a development tool like quilt fold also on your own once more?",SF Markus Elfring,elfring@users.sourceforge.net,0,1,1205,0.8544061302681992,1.0,0.1111111111111111,0.4339622641509434,0,0.9492753623188406,0.050724637681159424,0.0,0.050724637681159424
42,202437,196318,uncivil,I find such a change combination unsafe. Would you dare to apply any (of my) scripts for the semantic patch language directly on the whole directory for multi-media software? Can you handle bigger patches really better than similar patch series? Are there any further possibilities to consider around consequences from a general change resistance? Will any development (or management) tools like quilt fold make the regrouping of possible update steps more convenient and safer? ,191275,uncivil,"I preferred to offer source code adjustments according to specific transformation patterns mostly for each software module separately (also in small patch series).    I am curious if bigger patch packages would be easier to get accepted.  Or would you get frightened still by any other change combination?     We have got different preferences for a safe patch granularity.    I imagine that there are more development factors involved.    It is usual that integration of update suggestions will take some time. How would the situation change if I would dare to regroup possible update steps?    There are communication difficulties to consider since your terse information from your conference meeting.  If you would insist on patch squashing, would you dare to use a development tool like quilt fold also on your own once more?","I preferred to offer source code adjustments according to specific transformation patterns mostly for each software module separately (also in small patch series). I am curious if bigger patch packages would be easier to get accepted.  Or would you get frightened still by any other change combination? We have got different preferences for a safe patch granularity. I imagine that there are more development factors involved. It is usual that integration of update suggestions will take some time. How would the situation change if I would dare to regroup possible update steps? There are communication difficulties to consider since your terse information from your conference meeting.  If you would insist on patch squashing, would you dare to use a development tool like quilt fold also on your own once more? I find such a change combination unsafe. Would you dare to apply any (of my) scripts for the semantic patch language directly on the whole directory for multi-media software? Can you handle bigger patches really better than similar patch series? Are there any further possibilities to consider around consequences from a general change resistance? Will any development (or management) tools like quilt fold make the regrouping of possible update steps more convenient and safer? ",SF Markus Elfring,elfring@users.sourceforge.net,0,1,1295,0.8620689655172413,1.0,0.2,0.6037735849056604,1,1.0,0.0,0.050724637681159424,0.0
47,210458,210459,uncivil,"Wait, what?  Why would it do that, because it thinks dereferencing NULL is undefined behaviour and it can just do whatever it wants to? That feels crazy, as for these calls we ""know"" it will never be NULL because the previous call to debugfs_file_get() will always ensure it will be correct. So this is a case of the compiler trying to be smarter than it really is, and getting things totally wrong :sad:. Has anyone reported this to the clang developers? Papering over compiler foolishness is not something I like to do in kernel code if at all possible...",210458,technical,"debugfs_real_fops() returns a NULL pointer when it is invoked without a prior call to debugfs_file_get(). In code paths including this call it is not strictly necessary to check the return value of debugfs_real_fops(). However clang inlines debugfs_real_fops(), detects the invalid dereferencing of the NULL pointer and drops the code path. This leads to a bunch of objtool warnings when building with clang,  Check the pointer returned by debugfs_real_fops() in all code paths to make clang and objtool happy.  ","This function returns a NULL pointer when it is invoked without a prior call to the get function. In code paths including this call it is not strictly necessary to check the return value of the function. However clang inlines the function, detects the invalid dereferencing of the NULL pointer and drops the code path. This leads to a bunch of objtool warnings when building with clang,  Check the pointer returned by debugfs_real_fops() in all code paths to make clang and objtool happy.   Wait, what?  Why would it do that, because it thinks dereferencing NULL is undefined behaviour and it can just do whatever it wants to? That feels crazy, as for these calls we ""know"" it will never be NULL because the previous call to debugfs_file_get() will always ensure it will be correct. So this is a case of the compiler trying to be smarter than it really is, and getting things totally wrong :sad:. Has anyone reported this to the clang developers? Papering over compiler foolishness is not something I like to do in kernel code if at all possible...",Greg Kroah-Hartman,gregkh@linuxfoundation.org,1,0,1048,1.0,1.0,0.2,0.07142857142857142,0,0.0,0.0,0.0,0.0
48,210458,210461,uncivil,"Why is top-posting such a bad thing? Because it messes up the order in which people normally read text. What is the most annoying thing in e-mail? Top-posting. Should I include quotations after my reply? No. Then fix the tool, the C code is correct :) Then tell clang not to do that, like we tell gcc not to do that as that is a foolish thing for a compiler to do when building the kernel.",210467,technical,"Or, as the case may be, oopsing at the point of failure.    --","Or, as the case may be, oopsing at the point of failure.    -- Why is top-posting such a bad thing? Because it messes up the order in which people normally read text. What is the most annoying thing in e-mail? Top-posting. Should I include quotations after my reply? No. Then fix the tool, the C code is correct :smile: Then tell clang not to do that, like we tell gcc not to do that as that is a foolish thing for a compiler to do when building the kernel.",Greg Kroah-Hartman,gregkh@linuxfoundation.org,1,0,457,0.5,1.0,0.2857142857142857,0.5,0,0.0,0.0,0.0,0.0
49,210458,210463,uncivil,"Wait, clang does not have that?  That's crazy, how has this not been hit yet when building the kernel? Confused.",210462,technical," Thanks all for your input, we'll try to get -fno-delete-null-pointer-checks or a similar flag to be added to clang."," Thanks all for your input, we'll try to get -fno-delete-null-pointer-checks or a similar flag to be added to clang. Wait, clang does not have that?  That's crazy, how has this not been hit yet when building the kernel? Confused.",Greg Kroah-Hartman,gregkh@linuxfoundation.org,1,0,229,0.23300970873786409,1.0,0.5,0.9285714285714286,0,0.0,0.0,0.0,0.0
52,221804,221853,uncivil,Choose one of those two. Better to keep in order. Ditto. What's wrong with dev_info()? Hmm... Can't you use devm_ioremap_resources() to get the virtual address for I/O ? When you use explicit casting in printf() you are doing in 99.9% cases something wrong. Noise.,221804,technical,Add Amiga Gayle PATA controller driver. It enables libata support for the on-board IDE interfaces on some Amiga models and also for IDE interfaces on the Zorro expansion bus (M-Tech E-Matrix 530 expansion card).  Thanks to John Paul Adrian Glaubitz and Michael Schmitz for help with testing the driver. ,Add Amiga Gayle PATA controller driver. It enables libata support for the on-board IDE interfaces on some Amiga models and also for IDE interfaces on the Zorro expansion bus (M-Tech E-Matrix 530 expansion card).  Thanks to John Paul Adrian Glaubitz and Michael Schmitz for help with testing the driver.  Choose one of those two. Better to keep in order. Ditto. What's wrong with dev_info? Hmm... Can't you use the resources function to get the virtual address for I/O ? When you use explicit casting in printf() you are doing in 99.9% cases something wrong. Noise.,Andy Shevchenko,andy.shevchenko@gmail.com,1,0,564,1.0,1.0,0.1111111111111111,0.1111111111111111,0,0.0,0.0,0.0,0.0
53,222860,223021,uncivil,"...wait a second...this looks like it's a u-boot driver. There's a surprising amount of similarity between U-boot and Linux drivers (no coincidence I'm sure), including <linux/...> headers. Since when do U-Boot patches go to LKML and dri-devel? Anyway, I'll try my best to ignore this series.",223039,uncivil,"Hi,    How many times are we going to allow copy-and-pasting the same driver? Last time we wanted to modify the Rockchip driver, we were told consolidate"", because ST had already forked our driver. This nearly halted all progress. I'm going to be real disappointed if we see another fork get merged.  (IOW, I would say ""over my dead body,"" but I have no power here.)  And why can't you use DRM?""","How many times are we going to allow copy-and-pasting the same driver? Last time we wanted to modify the Rockchip driver, we were told consolidate"", because ST had already forked our driver. This nearly halted all progress. I'm going to be real disappointed if we see another fork get merged.  (IOW, I would say ""over my dead body,"" but I have no power here.)  And why can't you use DRM?"" ...wait a second...this looks like it's a u-boot driver. There's a surprising amount of similarity between U-boot and Linux drivers (no coincidence I'm sure), including headers. Since when do U-Boot patches go to LKML and dri-devel? Anyway, I'll try my best to ignore this series.",Brian Norris,briannorris@chromium.org,1,0,669,1.0,1.0,0.2,0.7333333333333333,0,0.0,1.0,0.0,0.3
57,232313,234089,uncivil,"meta comment (i.e., not about the merits of the patch itself). You'll need to send the patch to someone if you want it to be merged. Maintainers don't mine mailing lists for patches to apply.",232313,technical,"there are 2 reasons for no need to wait device probe  reason 1: mount root device is very late in kernel initial stage. all initcalls are finished. that means most of probe functions are returned.  and deferred probe are also finished by late_initcall. only async probe driver are possible in  probing.  no block devices, device-mapper or nfs are use async probe. so no need to wait device probe.  reason 2: let's check dd.c, probe_count is increased and decreased only in really_probe, and when really_probe returns, probe_count always be 0.  when someone really wants to wait device-B probe. but code looks like this.","there are 2 reasons for no need to wait device probe  reason 1: mount root device is very late in kernel initial stage. all initcalls are finished. that means most of probe functions are returned.  and deferred probe are also finished by late_initcall. only async probe driver are possible in  probing.  no block devices, device-mapper or nfs are use async probe. so no need to wait device probe.  reason 2: let's check this file, probe_count is increased and decreased only in really_probe, and when really_probe returns, probe_count always be 0.  when someone really wants to wait device-B probe. but code looks like this. meta comment (i.e., not about the merits of the patch itself). You'll need to send the patch to someone if you want it to be merged. Maintainers don't mine mailing lists for patches to apply.",Randy Dunlap,rdunlap@infradead.org,0,0,816,1.0,1.0,0.25,0.25,0,0.6666666666666666,0.3333333333333333,0.6666666666666666,0.3333333333333333
58,239101,240255,uncivil,"
They've been dropped.  BUT please do note that the patches I pushed to
linux-dm.git were rebased ontop of the 'check_at_most_once' patch.
I never did get an answer about how the sg array is free'd in certain
error paths (see ""FIXME:"" in the 2nd patch). Also, I fixed some issues I saw in error paths, and lots of formatting. I'll be pretty frustrated if you submit v2 that is blind to the kinds of
changes I made. I'll send you a private copy of the patches just so you have them for
your reference.",240077,technical,I will run veritysetup test on next version of these patches and contact you about verity-compat-test testsuits.,"I will run veritysetup test on next version of these patches and contact you about verity-compat-test testsuits. 
They've been dropped.  BUT please do note that the patches I pushed were rebased ontop of the 'check_at_most_once' patch.
I never did get an answer about how the sg array is free'd in certain error paths (see ""FIXME:"" in the 2nd patch). Also, I fixed some issues I saw in error paths, and lots of formatting. I'll be pretty frustrated if you submit v2 that is blind to the kinds of changes I made. I'll send you a private copy of the patches just so you have them for your reference.",Mike Snitzer,snitzer@redhat.com,1,0,597,1.0,1.0,0.14285714285714285,0.5384615384615384,0,0.03333333333333333,0.9666666666666667,0.0,0.0
60,245912,245922,uncivil,"Is this include needed ? Please use bool. I am quite completely missing how the two functions above are different. There is a lot of duplication in those functions. Would it be possible to find common code and use functions for it instead of duplicating everything several times? 
What if nothing is found? FWIW, it might be better to pass channel as parameter. What if it didn't find a core? This attribute should not exist. It is this, and this above is tjmax - tcontrol ? How does this make sense? Am I missing something, or is the same temperature reported several time?
tjmax is also reported as temp_crit cputemp_read_die(), for example. There is again a lot of duplication in those functions. Can this be made less magic with some defines ? Does this mean there will be an error message for each non-supported CPU? Why ? This is not an error, and should not result in an error message. Besides, the error can also be propagated from peci core code, and may well be something else. Then what ? Shouldn't this result in probe deferral or something more useful instead of just being ignored ? FWIW, this should be two separate patches. Needed ? It might make sense to provide the duplicate functions in a core file. This again looks like duplicate code. Please handle error cases first. More duplicate code. One set of brackets is unnecessary on each side of the expression. Why is this ""invalid"", and why does it warrant an error message? Is this guaranteed to be this? Or the peci command failed?",245963,technical,This commit adds a maintainer information for the PECI subsystem.,"This commit adds a maintainer information for the PECI subsystem. Is this include needed ? Please use bool. I am quite completely missing how the two functions above are different. There is a lot of duplication in those functions. Would it be possible to find common code and use functions for it instead of duplicating everything several times? 
What if nothing is found? FWIW, it might be better to pass channel as parameter. What if it didn't find a core? This attribute should not exist. It is this, and this above is control ? How does this make sense? Am I missing something, or is the same temperature reported several time?
tjmax is also reported as this function, for example. There is again a lot of duplication in those functions. Can this be made less magic with some defines ? Does this mean there will be an error message for each non-supported CPU? Why ? This is not an error, and should not result in an error message. Besides, the error can also be propagated from peci core code, and may well be something else. Then what ? Shouldn't this result in probe deferral or something more useful instead of just being ignored ? FWIW, this should be two separate patches. Needed ? It might make sense to provide the duplicate functions in a core file. This again looks like duplicate code. Please handle error cases first. More duplicate code. One set of brackets is unnecessary on each side of the expression. Why is this ""invalid"", and why does it warrant an error message? Is this guaranteed to be this? Or the peci command failed?",Guenter Roeck,linux@roeck-us.net,1,0,1544,1.0,1.0,0.03225806451612903,0.5135135135135135,0,0.0,1.0,0.0,0.0
62,245912,245916,uncivil,"As per the in-kernel documentation, I am now allowed to make fun of you. You are trying to ""out smart"" the kernel by getting rid of a warning message that was explicitly put there for you to do something.  To think that by just providing an ""empty"" function you are somehow fulfilling the API requirement is quite bold, don't you think? This has to be fixed.  I didn't put that warning in there for no good reason.  Please go read the documentation again...",245939,technical,"Additionally, I need to explain that there is one and only bus host (adapter) and multiple clients on a PECI bus, and PECI spec doesn't allow multiple originators so only the host device can originate message. In this implementation, all message transactions on a bus from client driver modules and user space will be serialized well in the PECI core bus driver so bus occupation and traffic arbitration will be managed well in the PECI core bus driver even in case of a bus has 2  client drivers at the same address. I'm sure that this implementation  doesn't make that kind of problem to OS.","Additionally, I need to explain that there is one and only bus host (adapter) and multiple clients on a PECI bus, and PECI spec doesn't allow multiple originators so only the host device can originate message. In this implementation, all message transactions on a bus from client driver modules and user space will be serialized well in the PECI core bus driver so bus occupation and traffic arbitration will be managed well in the PECI core bus driver even in case of a bus has 2  client drivers at the same address. I'm sure that this implementation  doesn't make that kind of problem to OS. As per the in-kernel documentation, I am now allowed to make fun of you. You are trying to ""out smart"" the kernel by getting rid of a warning message that was explicitly put there for you to do something.  To think that by just providing an ""empty"" function you are somehow fulfilling the API requirement is quite bold, don't you think? This has to be fixed.  I didn't put that warning in there for no good reason.  Please go read the documentation again...",Greg KH,gregkh@linuxfoundation.org,1,0,1051,0.6805111821086262,1.0,0.16666666666666666,0.9324324324324325,0,0.9230769230769231,0.07692307692307693,0.23076923076923078,0.0
63,254985,255085,uncivil,"Please do not repost with such a small changes. It is much more important to sort out the big picture first and only then deal with minor implementation details. The more versions you post the more fragmented and messy the discussion will become.
You will have to be patient because this is a rather big change and it will take _quite_ some time to get sorted.",254985,technical,"Page replacement is handled in the Linux Kernel in one of two ways:  1) Asynchronously via kswapd 2) Synchronously, via direct reclaim  At page allocation time the allocating task is immediately given a page from the zone free list allowing it to go right back to work doing whatever it was doing, Probably directly or indirectly executing business logic.  Just prior to satisfying the allocation, free pages is checked to see if it has reached the zone low watermark and if so, kswapd is awakened. Kswapd will start scanning pages looking for inactive pages to evict to make room for new page allocations. The work of kswapd allows tasks to continue allocating memory from their respective zone free list without incurring any delay.  When the demand for free pages exceeds the rate that kswapd tasks can supply them, page allocation works differently. Once the allocating task finds that the number of free pages is at or below the zone min watermark, the task will no longer pull pages from the free list. Instead, the task will run the same CPU-bound routines as kswapd to satisfy its own allocation by scanning and evicting pages. This is called a direct reclaim.  The time spent performing a direct reclaim can be substantial, often taking tens to hundreds of milliseconds for small order0 allocations to half a second or more for order9 huge-page allocations. In fact, kswapd is not actually required on a linux system. It exists for the sole purpose of optimizing performance by preventing direct reclaims.  When memory shortfall is sufficient to trigger direct reclaims, they can occur in any task that is running on the system. A single aggressive memory allocating task can set the stage for collateral damage to occur in small tasks that rarely allocate additional memory. Consider the impact of injecting an additional 100ms of latency when nscd allocates memory to facilitate caching of a DNS query.  The presence of direct reclaims 10 years ago was a fairly reliable indicator that too much was being asked of a Linux system. Kswapd was likely wasting time scanning pages that were ineligible for eviction. Adding RAM or reducing the working set size would usually make the problem go away. Since then hardware has evolved to bring a new struggle for kswapd. Storage speeds have increased by orders of magnitude while CPU clock speeds stayed the same or even slowed down in exchange for more cores per package. This presents a throughput problem for a single threaded kswapd that will get worse with each generation of new hardware.  Test Details  NOTE: The tests below were run with shadow entries disabled. See the associated patch and cover letter for details  The tests below were designed with the assumption that a kswapd bottleneck is best demonstrated using filesystem reads. This way, the inactive list will be full of clean pages, simplifying the analysis and allowing kswapd to achieve the highest possible steal rate. Maximum steal rates for kswapd are likely to be the same or lower for any other mix of page types on the system.  Tests were run on a 2U Oracle X7-2L with 52 Intel Xeon Skylake 2GHz cores, 756GB of RAM and 8 x 3.6 TB NVMe Solid State Disk drives. Each drive has an XFS file system mounted separately as /d0 through /d7. SSD drives require multiple concurrent streams to show their potential, so I created 11 250GB zero-filled files on each drive so that I could test with parallel reads.  The test script runs in multiple stages. At each stage, the number of dd tasks run concurrently is increased by 2. I did not include all of the test output for brevity.  During each stage dd tasks are launched to read from each drive in a round robin fashion until the specified number of tasks for the stage has been reached. Then iostat, vmstat and top are started in the background with 10 second intervals. After five minutes, all of the dd tasks are killed and the iostat, vmstat and top output is parsed in order to report the following:  CPU consumption - sy - aggregate kernel mode CPU consumption from vmstat output. The value doesn't tend to fluctuate much so I just grab the highest value. Each sample is averaged over 10 seconds - dd_cpu - for all of the dd tasks averaged across the top samples since there is a lot of variation.  Throughput - in Kbytes - Command is total  This first test performs reads using O_DIRECT in order to show the maximum throughput that can be obtained using these drives. It also demonstrates how rapidly throughput scales as the number of dd tasks are increased.  The dd command for this test looks like this> Throughput was close to peak with only 22 dd tasks. Very little system CPU was consumed as expected as the drives DMA directly into the user address space when using direct IO.  In this next test, the iflag=direct option is removed and we only run the test until the pgscan_kswapd from /proc/vmstat starts to increment. At that point metrics are parsed and reported and the pagecache contents are dropped prior to the next test. Lather, rinse, repeat.  Each read has to pause after the buffer in kernel space is populated while those pages are added to the pagecache and copied into the user address space. For this reason, more parallel streams are required to achieve peak throughput. The copy operation consumes substantially more CPU than direct IO as expected.  The next test measures throughput after kswapd starts running. This is the same test only we wait for kswapd to wake up before we start collecting metrics. The script actually keeps track of a few things that were not mentioned earlier. It tracks direct reclaims and page scans by watching the metrics in /proc/vmstat. CPU consumption for kswapd is tracked the same way it is tracked for dd.  Since the test is 100% reads, you can assume that the page steal rate for kswapd and direct reclaims is almost identical to the scan rate. In the previous test where kswapd was not involved, the system-wide kernel mode CPU consumption with 90 dd tasks was 16%. In this test CPU consumption with 90 tasks is at 43%. With 52 cores, and two kswapd tasks (one per NUMA node), kswapd can only be responsible for a little over 4% of the increase. The rest is likely caused by 51,618 direct reclaims that scanned 1.2 billion pages over the five minute time period of the test.  Same test, more kswapd tasks:  By increasing the number of kswapd threads, throughput increased by ~50% while kernel mode CPU utilization decreased or stayed the same, likely due to a decrease in the number of parallel tasks at any given time doing page replacement. allows you to control the number of kswapd threads per node running on the system. This provides the ability to devote additional CPU resources toward proactive page replacement with the goal of reducing direct reclaims. When direct reclaims are prevented, the CPU consumed by them is prevented as well. Depending on the workload, the result can cause aggregate CPU usage on the system to go up, down or stay the same.  More aggressive page replacement can reduce direct reclaims which cause latency for tasks and decrease throughput when doing filesystem IO through the pagecache. Direct reclaims are recorded using the allocstall counter this. The default value is 1 and the range of acceptible values are 1-16. Always start with lower values in the 2-6 range. Higher values should be justified with testing. If direct reclaims occur in spite of high values, the cost of direct reclaims (in latency) that occur can be higher due to increased lock contention. ","Page replacement is handled in the Linux Kernel in one of two ways:  1) Asynchronously via kswapd 2) Synchronously, via direct reclaim  At page allocation time the allocating task is immediately given a page from the zone free list allowing it to go right back to work doing whatever it was doing, Probably directly or indirectly executing business logic.  Just prior to satisfying the allocation, free pages is checked to see if it has reached the zone low watermark and if so, kswapd is awakened. Kswapd will start scanning pages looking for inactive pages to evict to make room for new page allocations. The work of kswapd allows tasks to continue allocating memory from their respective zone free list without incurring any delay.  When the demand for free pages exceeds the rate that kswapd tasks can supply them, page allocation works differently. Once the allocating task finds that the number of free pages is at or below the zone min watermark, the task will no longer pull pages from the free list. Instead, the task will run the same CPU-bound routines as kswapd to satisfy its own allocation by scanning and evicting pages. This is called a direct reclaim.  The time spent performing a direct reclaim can be substantial, often taking tens to hundreds of milliseconds for small order0 allocations to half a second or more for order9 huge-page allocations. In fact, kswapd is not actually required on a linux system. It exists for the sole purpose of optimizing performance by preventing direct reclaims.  When memory shortfall is sufficient to trigger direct reclaims, they can occur in any task that is running on the system. A single aggressive memory allocating task can set the stage for collateral damage to occur in small tasks that rarely allocate additional memory. Consider the impact of injecting an additional 100ms of latency when nscd allocates memory to facilitate caching of a DNS query.  The presence of direct reclaims 10 years ago was a fairly reliable indicator that too much was being asked of a Linux system. Kswapd was likely wasting time scanning pages that were ineligible for eviction. Adding RAM or reducing the working set size would usually make the problem go away. Since then hardware has evolved to bring a new struggle for kswapd. Storage speeds have increased by orders of magnitude while CPU clock speeds stayed the same or even slowed down in exchange for more cores per package. This presents a throughput problem for a single threaded kswapd that will get worse with each generation of new hardware.  Test Details  NOTE: The tests below were run with shadow entries disabled. See the associated patch and cover letter for details  The tests below were designed with the assumption that a kswapd bottleneck is best demonstrated using filesystem reads. This way, the inactive list will be full of clean pages, simplifying the analysis and allowing kswapd to achieve the highest possible steal rate. Maximum steal rates for kswapd are likely to be the same or lower for any other mix of page types on the system.  Tests were run on a 2U Oracle X7-2L with 52 Intel Xeon Skylake 2GHz cores, 756GB of RAM and 8 x 3.6 TB NVMe Solid State Disk drives. Each drive has an XFS file system mounted separately as /d0 through /d7. SSD drives require multiple concurrent streams to show their potential, so I created 11 250GB zero-filled files on each drive so that I could test with parallel reads.  The test script runs in multiple stages. At each stage, the number of dd tasks run concurrently is increased by 2. I did not include all of the test output for brevity.  During each stage dd tasks are launched to read from each drive in a round robin fashion until the specified number of tasks for the stage has been reached. Then iostat, vmstat and top are started in the background with 10 second intervals. After five minutes, all of the dd tasks are killed and the iostat, vmstat and top output is parsed in order to report the following:  CPU consumption - sy - aggregate kernel mode CPU consumption from vmstat output. The value doesn't tend to fluctuate much so I just grab the highest value. Each sample is averaged over 10 seconds for all of the dd tasks averaged across the top samples since there is a lot of variation.  Throughput - in Kbytes - Command is total  This first test performs reads using O_DIRECT in order to show the maximum throughput that can be obtained using these drives. It also demonstrates how rapidly throughput scales as the number of dd tasks are increased.  The dd command for this test looks like this. Throughput was close to peak with only 22 dd tasks. Very little system CPU was consumed as expected as the drives DMA directly into the user address space when using direct IO.  In this next test, the iflag=direct option is removed and we only run the test until this starts to increment. At that point metrics are parsed and reported and the pagecache contents are dropped prior to the next test. Lather, rinse, repeat.  Each read has to pause after the buffer in kernel space is populated while those pages are added to the pagecache and copied into the user address space. For this reason, more parallel streams are required to achieve peak throughput. The copy operation consumes substantially more CPU than direct IO as expected.  The next test measures throughput after kswapd starts running. This is the same test only we wait for kswapd to wake up before we start collecting metrics. The script actually keeps track of a few things that were not mentioned earlier. It tracks direct reclaims and page scans by watching the metrics in /proc/vmstat. CPU consumption for kswapd is tracked the same way it is tracked for dd.  Since the test is 100% reads, you can assume that the page steal rate for kswapd and direct reclaims is almost identical to the scan rate. In the previous test where kswapd was not involved, the system-wide kernel mode CPU consumption with 90 dd tasks was 16%. In this test CPU consumption with 90 tasks is at 43%. With 52 cores, and two kswapd tasks (one per NUMA node), kswapd can only be responsible for a little over 4% of the increase. The rest is likely caused by 51,618 direct reclaims that scanned 1.2 billion pages over the five minute time period of the test.  Same test, more kswapd tasks:  By increasing the number of kswapd threads, throughput increased by about 50% while kernel mode CPU utilization decreased or stayed the same, likely due to a decrease in the number of parallel tasks at any given time doing page replacement. allows you to control the number of kswapd threads per node running on the system. This provides the ability to devote additional CPU resources toward proactive page replacement with the goal of reducing direct reclaims. When direct reclaims are prevented, the CPU consumed by them is prevented as well. Depending on the workload, the result can cause aggregate CPU usage on the system to go up, down or stay the same.  More aggressive page replacement can reduce direct reclaims which cause latency for tasks and decrease throughput when doing filesystem IO through the pagecache. Direct reclaims are recorded using the allocstall counter this. The default value is 1 and the range of acceptible values are 1-16. Always start with lower values in the 2-6 range. Higher values should be justified with testing. If direct reclaims occur in spite of high values, the cost of direct reclaims (in latency) that occur can be higher due to increased lock contention.  Please do not repost with such a small changes. It is much more important to sort out the big picture first and only then deal with minor implementation details. The more versions you post the more fragmented and messy the discussion will become.
You will have to be patient because this is a rather big change and it will take _quite_ some time to get sorted.",Michal Hocko,mhocko@kernel.org,1,0,7870,1.0,1.0,0.2,0.2,0,0.0,1.0,0.0,0.2
64,258997,259457,uncivil,"Pulled, and then immediately unpulled again. The code causes new compiler warnings, and the warnings are valid. If people don't care enough about their code to even check the warnings, I'm not going to waste one second pulling the resulting garbage. It's that simple.",258997,technical,Please pull from here  to receive the latest Thermal Management updates with top-most commit?  Merge branches 'thermal-core' and 'thermal-soc' into next on top of commit: Specifics:  Fix race condition in imx_thermal_probe().  Add cooling device's statistics in sysfs.  add support for i.MX7 thermal sensor in imx_thermal driver. add support for MT7622 SoC in mtk_thermal driver. Remove unused min/max cpu cooling DT property. A series of fixes on exynos driver. ,"Please pull from here  to receive the latest Thermal Management updates with top-most commit?  Merge branches 'thermal-core' and 'thermal-soc' into next on top of commit: Specifics:  Fix race condition in thermal_probe.  Add cooling device's statistics in sysfs.  add support for i.MX7 thermal sensor in imx_thermal driver. add support for MT7622 SoC in thermal driver. Remove unused min/max cpu cooling DT property. A series of fixes on exynos driver.  Pulled, and then immediately unpulled again. The code causes new compiler warnings, and the warnings are valid. If people don't care enough about their code to even check the warnings, I'm not going to waste one second pulling the resulting garbage. It's that simple.",Linus Torvalds,torvalds@linux-foundation.org,1,0,721,1.0,1.0,0.25,0.5,0,0.0,0.75,0.0,0.0
66,258997,260177,uncivil,Could you please just merge the obvious fix from Arnd instead? [ it was posted two weeks ago and ACKed by me ],260171,technical,Since this condition cannot happen (the driver makes sure of this during probe) I would prefer much simpler fix from Arnd. (I've already ACKed it two weeks ago).   ditto,Since this condition cannot happen (the driver makes sure of this during probe) I would prefer much simpler fix from Arnd. (I've already ACKed it two weeks ago). ditto. Could you please just merge the obvious fix from Arnd instead? [ it was posted two weeks ago and ACKed by me ],Bartlomiej Zolnierkiewicz,b.zolnierkie@samsung.com,1,0,279,0.4626865671641791,1.0,0.5,0.7857142857142857,0,0.5,0.25,0.0,0.0
67,258997,260189,uncivil,The init function is making sure cal_type is one or another. Can you fix it correctly by replacing the 'switch' by a 'if' instead of adding dead branches to please gcc?,260184,technical,It is okay to return 0 because this code-path (the default one) will be never hit by the driver (probe makes sure of it) - the default case is here is just to silence compilation errors..,It is okay to return 0 because this code-path (the default one) will be never hit by the driver (probe makes sure of it) - the default case is here is just to silence compilation errors.. The init function is making sure cal_type is one or another. Can you fix it correctly by replacing the 'switch' by a 'if' instead of adding dead branches to please gcc?,Daniel Lezcano,daniel.lezcano@linaro.org,1,0,356,0.5671641791044776,1.0,0.5,0.9285714285714286,0,0.5,0.25,0.0,0.0
69,259276,259299,uncivil,"Did you actually test this?  The usual reason for wanting m/udelay is that the timing must be exact.  The driver is filled with mdelay()s for this reason.  The one you've picked on is in the init path so it won't affect the runtime in any way.  I also don't think we have the hrtimer machinery for usleep_range() to work properly on parisc, so I don't think the replacement works.",259276,technical,"de4x5_hw_init() is never called in atomic context.  de4x5_hw_init() is only called by de4x5_pci_probe(), which is only  set as .probe"" in struct pci_driver.  Despite never getting called from atomic context, de4x5_hw_init()  calls mdelay() to busily wait. This is not necessary and can be replaced with usleep_range() to  avoid busy waiting.  This is found by a static analysis tool named DCNS written by myself. And I also manually check it.","This function is never called in atomic context.  It is only called by this function, which is only  set as .probe"" in struct pci_driver.  Despite never getting called from atomic context, it calls mdelay() to busily wait. This is not necessary and can be replaced with sleep_range() to  avoid busy waiting.  This is found by a static analysis tool named DCNS written by myself. And I also manually check it. Did you actually test this?  The usual reason for wanting m/udelay is that the timing must be exact.  The driver is filled with mdelay()s for this reason.  The one you've picked on is in the init path so it won't affect the runtime in any way.  I also don't think we have the hrtimer machinery for usleep_range() to work properly on parisc, so I don't think the replacement works.",James Bottomley,James.Bottomley@HansenPartnership.com,1,0,789,1.0,1.0,0.2,0.5,0,0.0,0.0,0.0,0.0
71,261377,261389,uncivil,"This doesn't have to be on separate lines; as written, it just causes confusion. Good find, but your patch is corrupted to the point where any attenpt to fix it up on my side failed. Please resend without corruption, and please provide a Fixes: line.",261377,technical,Upstream commit  Make calibration register value fixed  makes ina2xx_set_shunt() call mutex_lock on an un-initialized mutex. Initialize it prior so we don't get a NULL pointer dereference error  ,"Upstream commit. Make calibration register value fixed  makes this functiion call mutex_lock on an un-initialized mutex. Initialize it prior so we don't get a NULL pointer dereference error. This doesn't have to be on separate lines; as written, it just causes confusion. Good find, but your patch is corrupted to the point where any attenpt to fix it up on my side failed. Please resend without corruption, and please provide a Fixes: line.",Guenter Roeck,linux@roeck-us.net,1,0,441,1.0,1.0,0.25,0.25,0,0.0,0.0,0.0,0.0
72,261866,263843,uncivil,"Sorry, but this is a hack to *try* to make multi-slot work and this isn't sufficient. There were good reasons to why the earlier non-working multi slot support was removed from dw_mmc.
Let me elaborate a bit for your understanding. The core uses a host lock to serialize operations and commands, as to confirm to the SD/SDIO/(e)MMC specs. The above changes gives no guarantees for this. To make that work, we would need a ""mmc bus lock"" to be managed by the core. However, inventing a ""mmc bus lock"" would lead to other problems related to I/O scheduling for upper layers - it simply breaks. For example, I/O requests for one card/slot can then starve I/O requests reaching another card/slot.",261868,technical,This patch adds missing stuff to support multislot mode in DesignWare MMC driver.  The main changes:  Add missing slot switch to __dw_mci_start_request() function. Refactor set_ios function:    a) Calculate common clock which is suitable for all slots instead of directly use clock value provided by mmc core. We calculate common clock as the minimum among each used slot clocks. This clock is calculated in       dw_mci_calc_common_clock() function which is called from set_ios(). b) Disable clock only if no other slots are ON.  c) Setup clock directly in set_ios() only if no other slots       are ON. Otherwise adjust clock in __dw_mci_start_request() function before slot switch.    d) Move timings and bus_width setup to separate funcions.  Use timing field in each slot structure instead of common field in    host structure.  Add locks to serialize access to registers.  NOTE: this patch is based off of v4.17-rc1  NOTE: as of today I tested this changes (in singleslot and multislot    modes) only on Synopsys HSDK board. But I will get ODROID-XU4 board (with Exynos5422 which has DW MMC controller) the next week so I will test it on this board too to catch any regressions. ,"This patch adds missing stuff to support multislot mode in DesignWare MMC driver.  The main changes:  Add missing slot switch to this function. Refactor set_ios function:    a) Calculate common clock which is suitable for all slots instead of directly use clock value provided by mmc core. We calculate common clock as the minimum among each used slot clocks. This clock is calculated in this function which is called from this b) Disable clock only if no other slots are ON.  c) Setup clock directly in this only if no other slots are ON. Otherwise adjust clock in this function before slot switch. d) Move timings and bus_width setup to separate funcions.  Use timing field in each slot structure instead of common field in    host structure.  Add locks to serialize access to registers.  NOTE: this patch is based off of this version NOTE: as of today I tested this changes (in singleslot and multislot    modes) only on Synopsys HSDK board. But I will get ODROID-XU4 board (with Exynos5422 which has DW MMC controller) the next week so I will test it on this board too to catch any regressions.  Sorry, but this is a hack to *try* to make multi-slot work and this isn't sufficient. There were good reasons to why the earlier non-working multi slot support was removed from this.
Let me elaborate a bit for your understanding. The core uses a host lock to serialize operations and commands, as to confirm to the specs. The above changes gives no guarantees for this. To make that work, we would need a ""mmc bus lock"" to be managed by the core. However, inventing a ""mmc bus lock"" would lead to other problems related to I/O scheduling for upper layers - it simply breaks. For example, I/O requests for one card/slot can then starve I/O requests reaching another card/slot.",Ulf Hansson,ulf.hansson@linaro.org,1,0,1775,1.0,1.0,0.125,0.125,0,0.25,0.75,0.25,0.0
73,266017,266025,uncivil,What actually took so long?  Could you analyze further instead of blindly putting the flag?,266017,technical,"On an ASRock E350M1, with Linux 4.17-rc1 according to `initcall_debug` calling `azx_driver_init` takes sometimes more than a few milliseconds, and up to 200 ms.  returned 0 after 49195 usecs ```  Trying to execute the Linux kernel in less than 500 ms, this is quite a hold-up, and therefore request the probe from an async task.  With this change, the test shows, that the function returns earlier.  The same behavior is visible on a Dell OptiPlex 7010. The longer times seem to happen, when the module *e1000e* is probed during the same time.  ","On an ASRock E350M1, with Linux 4.17-rc1 according to `initcall_debug` calling this function takes sometimes more than a few milliseconds, and up to 200 ms.  returned 0 after 49195 usecs. Trying to execute the Linux kernel in less than 500 ms, this is quite a hold-up, and therefore request the probe from an async task.  With this change, the test shows, that the function returns earlier.  The same behavior is visible on a Dell OptiPlex 7010. The longer times seem to happen, when the module *e1000e* is probed during the same time.   What actually took so long?  Could you analyze further instead of blindly putting the flag?",Takashi Iwai,tiwai@suse.de,1,0,629,1.0,1.0,0.3333333333333333,0.7142857142857143,0,0.0,1.0,0.0,0.0
75,266279,266313,uncivil,"Please enlighten me: how do you think this could be exploited? When an application calls VIDIOC_ENUM_FMT from a video0 device, it will just enumerate a hardware functionality, with is constant for a given hardware piece. The way it works is that userspace do something like this in order to read an entire const table. Usually, it doesn't require any special privilege to call this ioctl, but, even if someone changes its permission to 0x400, a simple lsusb output is enough to know what hardware model is there. A lsmod or cat also tells that the tm6000 module was loaded, with is a very good hint that the tm6000 is there or was there in the past.

In the specific case of tm6000, all hardware supports exactly the same formats, as this is usually defined per-driver. So, a quick look at the driver is enough to know exactly what the ioctl would answer.  Also, the net is full of other resources that would allow anyone to get the supported formats for a piece of hardware. Even assuming that the OS doesn't have lsusb, that /proc is not mounted, that video require special permissions, that the potential attacker doesn't have physical access to the equipment (in order to see if an USB board is plugged), etc... What possible harm he could do by identifying a hardware feature? Similar notes for the other patches to drivers/media in this series: let's not just start adding bloatware where not needed. Please notice that I'm fine if you want to submit potential Spectre variant 1 fixups, but if you're willing to do so, please provide an explanation about the potential threat scenarios that you're identifying at the code. It probably makes sense to have somewhere at smatch a place where we could explicitly mark the false-positives, in order to avoid use to receive patches that would just add an extra delay where it is not needed. ",266296,technical,"code->index can be controlled by user-space, hence leading to a potential exploitation of the Spectre variant 1 vulnerability.  Smatch warning: Fix this by sanitizing code->index before using it to index codes.  Notice that given that speculation windows are large, the policy is to kill the speculation on the first load and not worry if it can be completed with a dependent load/store","this index can be controlled by user-space, hence leading to a potential exploitation of the Spectre variant 1 vulnerability.  Smatch warning: Fix this by sanitizing it before using it to index codes.  Notice that given that speculation windows are large, the policy is to kill the speculation on the first load and not worry if it can be completed with a dependent load/store Please enlighten me: how do you think this could be exploited? When an application calls this from a video0 device, it will just enumerate a hardware functionality, with is constant for a given hardware piece. The way it works is that userspace do something like this in order to read an entire const table. Usually, it doesn't require any special privilege to call this ioctl, but, even if someone changes its permission to 0x400, a simple lsusb output is enough to know what hardware model is there. A lsmod or cat also tells that the tm6000 module was loaded, with is a very good hint that the tm6000 is there or was there in the past.

In the specific case of tm6000, all hardware supports exactly the same formats, as this is usually defined per-driver. So, a quick look at the driver is enough to know exactly what the ioctl would answer.  Also, the net is full of other resources that would allow anyone to get the supported formats for a piece of hardware. Even assuming that the OS doesn't have lsusb, that /proc is not mounted, that video require special permissions, that the potential attacker doesn't have physical access to the equipment (in order to see if an USB board is plugged), etc... What possible harm he could do by identifying a hardware feature? Similar notes for the other patches to drivers/media in this series: let's not just start adding bloatware where not needed. Please notice that I'm fine if you want to submit potential Spectre variant 1 fixups, but if you're willing to do so, please provide an explanation about the potential threat scenarios that you're identifying at the code. It probably makes sense to have somewhere at smatch a place where we could explicitly mark the false-positives, in order to avoid use to receive patches that would just add an extra delay where it is not needed. ",Mauro Carvalho Chehab,mchehab@kernel.org,1,0,2207,1.0,1.0,0.07692307692307693,0.5555555555555556,0,0.0,1.0,0.0,0.0
80,266918,269136,uncivil,"I suppose these sort of patches are as much a PITA for the sender
than for the receivers. I hesitated between a single patch, a series or separated patches. In a sense, the single patch would have been the easier for both sides but I guessed it would not have been very well welcomed. Since for a series, you're supposed to CC the whole series to everyone involved, it would have been, or at least at thought so, maximaly noisy for no good reasons. Finally, as all of these patches are totally independent, I thought it would be the best to send them as separated patches, each drivers maintainers being then free to accept, reject or ignore the patch(es) concerning him/her. It seems it was a bad guess, and yes, I see the point of having a series for this. I'll remember all this for the next time (if next time there is, of course, I was already quite hesitant to spend time to prepare and send patches for these issues with enum/integer mix-up). Sorry for the annoyance.",267111,civil,"please don't submit such a huge number of patches all at one time.  Also, please fix the indentation of the functions whose arguments span multiple lines as has been pointed out to you in patch feedback.  Finally, make this a true patch series.  It is so much easier for maintainers to work with a set of changes all doing the same thing if you make them a proper patch series with an appropriate patch ..."" header posting.""","please don't submit such a huge number of patches all at one time.  Also, please fix the indentation of the functions whose arguments span multiple lines as has been pointed out to you in patch feedback.  Finally, make this a true patch series.  It is so much easier for maintainers to work with a set of changes all doing the same thing if you make them a proper patch series with an appropriate patch ..."" header posting."" I suppose these sort of patches are as much a PITA for the sender
than for the receivers. I hesitated between a single patch, a series or separated patches. In a sense, the single patch would have been the easier for both sides but I guessed it would not have been very well welcomed. Since for a series, you're supposed to CC the whole series to everyone involved, it would have been, or at least at thought so, maximaly noisy for no good reasons. Finally, as all of these patches are totally independent, I thought it would be the best to send them as separated patches, each drivers maintainers being then free to accept, reject or ignore the patch(es) concerning him/her. It seems it was a bad guess, and yes, I see the point of having a series for this. I'll remember all this for the next time (if next time there is, of course, I was already quite hesitant to spend time to prepare and send patches for these issues with enum/integer mix-up). Sorry for the annoyance.",Luc Van Oostenryck,luc.vanoostenryck@gmail.com,1,1,1399,1.0,1.0,0.125,0.5,1,1.0,0.0,1.0,0.0
81,281311,281957,uncivil,"Either it does exist, or it doesn't. If it exists, it needs to be fixed.  If it doesn't exist, nothing
needs to be done. Which is the case?",281311,technical,"The write operation to hotplug->enabled"" is protected by the lock on line 1760, but the read operation to this data on line 1755 is not protected by the lock. Thus, there may exist a data race for ""hotplug->enabled"".  To fix this data race, the read operation to ""hotplug->enabled"" is  also protected by the lock.","The write operation to this is protected by the lock on line 1760, but the read operation to this data on line 1755 is not protected by the lock. Thus, there may exist a data race for this.  To fix this data race, the read operation to it is  also protected by the lock. Either it does exist, or it doesn't. If it exists, it needs to be fixed.  If it doesn't exist, nothing needs to be done. Which is the case?",Rafael J. Wysocki,rafael@kernel.org,1,0,410,1.0,1.0,0.25,0.2,0,0.0,0.0,0.0,0.0
82,281311,283024,uncivil,It looks like you are not actually sure what you are doing then.,282919,technical,"I only read the code and find this possible data race. It is not found in real driver execution. I am not sure of it, so I use may"" and ""possible"" here.""","I only read the code and find this possible data race. It is not found in real driver execution. I am not sure of it, so I use may"" and ""possible"" here."" It looks like you are not actually sure what you are doing then.",Rafael J. Wysocki,rafael@kernel.org,1,0,218,0.5567010309278351,1.0,1.0,1.0,1,1.0,0.0,0.0,0.0
85,289026,292839,uncivil,"I do share your view Mike! This all looks so hackish and ad-hoc that I would be tempted to give it an outright nack, but let's here more about why do we need this fiddling at all. I've asked in other email so I guess I will get an answer there but let me just emphasize again that I absolutely detest a possibility to put hugetlb pages into the memcg mix. They just do not belong there. Try to look at previous discussions why it has been decided to have a separate hugetlb pages at all. I am also quite confused why you keep distinguishing surplus hugetlb pages from regular preallocated ones. Being a surplus page is an implementation detail that we use for an internal accounting rather than something to exhibit to the userspace even more than we do currently. Just look at what [sw]hould when you need to adjust accounting - e.g. due to the pool resize. Are you going to uncharge those surplus pages from memcg to reflect their persistence?",292549,civil,"I am sorry that I didn't join the discussion for the previous version but time just didn't allow that. So sorry if I am repeating something already sorted out.   There was a deliberate decision to keep hugetlb and normal"" memory cgroup controllers separate. Mostly because hugetlb memory is an artificial memory subsystem on its own and it doesn't fit into the rest of memcg accounted memory very well. I believe we want to keep that status quo.   Well such a usecase requires an explicit configuration already. Either by using special wrappers or modifying the code. So I would argue that you have quite a good knowlege of the setup. If you need a greater flexibility then just do not use hugetlb at all and rely on THP. [...]   I do not really think this is a good idea. We really do not want to make the current hugetlb code more complex than it is already. The current hugetlb cgroup controller is simple and works at least somehow. I would not add more on top unless there is a _really_ strong usecase behind. Please make sure to describe such a usecase in details before we even start considering the code.   Well, then I would argue that you shouldn't use 64kB pages for your setup or allow THP for smaller sizes. Really hugetlb pages are by no means a substitute here.","I am sorry that I didn't join the discussion for the previous version but time just didn't allow that. So sorry if I am repeating something already sorted out.   There was a deliberate decision to keep hugetlb and normal"" memory cgroup controllers separate. Mostly because hugetlb memory is an artificial memory subsystem on its own and it doesn't fit into the rest of memcg accounted memory very well. I believe we want to keep that status quo.   Well such a usecase requires an explicit configuration already. Either by using special wrappers or modifying the code. So I would argue that you have quite a good knowlege of the setup. If you need a greater flexibility then just do not use hugetlb at all and rely on THP. I do not really think this is a good idea. We really do not want to make the current hugetlb code more complex than it is already. The current hugetlb cgroup controller is simple and works at least somehow. I would not add more on top unless there is a _really_ strong usecase behind. Please make sure to describe such a usecase in details before we even start considering the code.   Well, then I would argue that you shouldn't use 64kB pages for your setup or allow THP for smaller sizes. Really hugetlb pages are by no means a substitute here. I do share your view Mike! This all looks so hackish and ad-hoc that I would be tempted to give it an outright nack, but let's here more about why do we need this fiddling at all. I've asked in other email so I guess I will get an answer there but let me just emphasize again that I absolutely detest a possibility to put hugetlb pages into the memcg mix. They just do not belong there. Try to look at previous discussions why it has been decided to have a separate hugetlb pages at all. I am also quite confused why you keep distinguishing surplus hugetlb pages from regular preallocated ones. Being a surplus page is an implementation detail that we use for an internal accounting rather than something to exhibit to the userspace even more than we do currently. Just look at what [sw]hould when you need to adjust accounting - e.g. due to the pool resize. Are you going to uncharge those surplus pages from memcg to reflect their persistence?",Michal Hocko,mhocko@kernel.org,1,0,2214,1.0,1.0,0.09090909090909091,0.8181818181818182,0,0.6666666666666666,0.3333333333333333,0.0,0.0
89,289431,292003,uncivil,"Where did this come from? XFS doesn't use the underlying blockdev address space, so this does nothing at all and should not be here. So to return errors correctly it needs to capture errors from the log force (i.e. metadata errors such as filesystem shutdowns, journal IO errors, etc), then check for pending data IO errors.",271303,technical,"Thanks, I wasn't sure about xfs. I'll drop this hunk.  FWIW, I think pushing this call down into the sync_fs routines is still probably the right thing to do, regardless of the state of the later patches.   I patterned the name after the call_mmap (and now-defunct call_fsync) helpers. I'll rename it and change it to be non-inlined.","Thanks, I wasn't sure about xfs. I'll drop this hunk.  FWIW, I think pushing this call down into the sync_fs routines is still probably the right thing to do, regardless of the state of the later patches.   I patterned the name after the call_mmap (and now-defunct call_fsync) helpers. I'll rename it and change it to be non-inlined. Where did this come from? XFS doesn't use the underlying blockdev address space, so this does nothing at all and should not be here. So to return errors correctly it needs to capture errors from the log force (i.e. metadata errors such as filesystem shutdowns, journal IO errors, etc), then check for pending data IO errors.",Dave Chinner,david@fromorbit.com,0,0,658,1.0,1.0,0.2,0.7142857142857143,0,1.0,0.0,1.0,0.0
90,303621,305468,uncivil,The SPDX header is explicitly here to remove the license text and create a tag that is in a indirect reference to the license text in LICENSES. It's not going away. I never said we were perfect reviewers. Feel free to help in the process.,304654,technical,"The X11 license notice states explicitly that the notice has to be included in the file.  Wouldn't removing it be a violation of the license?    FYI, this was copied from another .dts file.  All of the other brightness-levels settings in sun files follow similar patterns:","The X11 license notice states explicitly that the notice has to be included in the file.  Wouldn't removing it be a violation of the license?    FYI, this was copied from another .dts file.  All of the other brightness-levels settings in sun files follow similar patterns: The SPDX header is explicitly here to remove the license text and create a tag that is in a indirect reference to the license text in LICENSES. It's not going away. I never said we were perfect reviewers. Feel free to help in the process.",Maxime Ripard,maxime.ripard@bootlin.com,1,0,511,1.0,1.0,0.25,0.25,0,0.2,0.7,0.0,0.0
92,306145,357688,uncivil,But you did it again.... Your email client should not be forcing you to top post. So please don't.,357674,technical,"thanks for your feedback. I was on holiday, thus just delayed, not forgotten... Sorry for top-posting - odd company default mail setup. I checked again phy_write_mmd(), you are right !  Patch with changed implementation will follow.  PHY link failure after cable connect. Please don't top post. And wrap your lines at around 75 characters. Look closely at the two implementations. Look at what mmd_phy_indirect() does. I _think_ these are identical. So don't add your own helper, please use the core code.","thanks for your feedback. I was on holiday, thus just delayed, not forgotten... Sorry for top-posting - odd company default mail setup. I checked again that function, you are right !  Patch with changed implementation will follow.  PHY link failure after cable connect. Please don't top post. And wrap your lines at around 75 characters. Look closely at the two implementations. Look at what this function does. I _think_ these are identical. So don't add your own helper, please use the core code. But you did it again.... Your email client should not be forcing you to top post. So please don't.",Andrew Lunn,andrew@lunn.ch,1,0,597,1.0,1.0,0.3333333333333333,0.75,1,1.0,0.0,0.0,0.0
95,307410,349339,uncivil,I took a closer look at this and it's not necessary. (Note: I do the majority of my testing in a looped-back setup). What you didn't notice is that split_remote() separates the colon whether there is a host or not. It's not passed to ssh or cat (or whatever) directly. So the change you propose will actually break the how it was designed.,314425,technical,Thanks. It would be good to get Acked-bys or Reviewed-bys on the patches you approved.,Thanks. It would be good to get Acked-bys or Reviewed-bys on the patches you approved. I took a closer look at this and it's not necessary. (Note: I do the majority of my testing in a looped-back setup). What you didn't notice is that split_remote() separates the colon whether there is a host or not. It's not passed to ssh or cat (or whatever) directly. So the change you propose will actually break the how it was designed.,Logan Gunthorpe,logang@deltatee.com,1,1,426,1.0,1.0,0.2,0.75,1,1.0,0.0,0.8292682926829268,0.0
96,310967,311378,uncivil,There are no unexpected results. Making a non-fatal error fatal doesn't serve a useful purpose,310967,technical,"When i2c_new_dummy fails, the lack of error-handling code may cause unexpected results.  This patch adds error-handling code after calling i2c_new_dummy.  ","When the new dummy fails, the lack of error-handling code may cause unexpected results.  This patch adds error-handling code after calling the new dummy. There are no unexpected results. Making a non-fatal error fatal doesn't serve a useful purpose",Guenter Roeck,linux@roeck-us.net,1,0,248,1.0,1.0,0.5,0.5,1,0.0,0.0,0.0,0.0
98,331266,331355,uncivil,"What is this crazy union for?  Why are you messing around with ""raw"" kobject attributes?  This is a device, you should never have to mess with sysfs calls or kobject calls or structures directly.  If you do, that's a huge hint something is wrong here. You aren't ""adding"" any attributes here, you are only setting them up (in an odd way, see below...). That's an oddly-hard-coded array size for no good reason :sad:. This works?  You normally have to manually initialize a dynamic attribute.  Why are you doing it this way and not using an attribute group? Why are you using a custom device class for a single device? you need to document the heck out of this in the changelog to help explain all of these odd design decisions.",331349,technical,Same problem here :(,"Same problem here :sad: What is this crazy union for?  Why are you messing around with ""raw"" kobject attributes?  This is a device, you should never have to mess with sysfs calls or kobject calls or structures directly.  If you do, that's a huge hint something is wrong here. You aren't ""adding"" any attributes here, you are only setting them up (in an odd way, see below...). That's an oddly-hard-coded array size for no good reason :sad:. This works?  You normally have to manually initialize a dynamic attribute.  Why are you doing it this way and not using an attribute group? Why are you using a custom device class for a single device? you need to document the heck out of this in the changelog to help explain all of these odd design decisions.",Greg KH,gregkh@linuxfoundation.org,1,0,751,1.0,1.0,0.1,0.05555555555555555,0,0.0,0.0,0.0,0.0
99,331266,331694,uncivil,"Greg (and replying to your other comments as well)... This is an RFC series, it's not meant for you to take at this point, it's about discussing the overall approach to exposing BMC random ""tunables"" as explained in patch 0 of the series. Yes the individual patches aren't yet at the level of polish for a formal submission, we (naively ?) thought that's what the whole RFC tag is about :-)",331356,technical,No changelog :(,"No changelog :sad: (and replying to your other comments as well)... This is an RFC series, it's not meant for you to take at this point, it's about discussing the overall approach to exposing BMC random ""tunables"" as explained in patch 0 of the series. Yes the individual patches aren't yet at the level of polish for a formal submission, we (naively ?) thought that's what the whole RFC tag is about :-)",Benjamin Herrenschmidt,benh@kernel.crashing.org,1,0,404,0.5644171779141104,1.0,0.25,0.6111111111111112,0,0.0,0.0,0.0,0.0
100,331266,331847,uncivil,"Well, it adds documentation :-) You can just read the patch which is ... the documentation :) Yes, you did that's fine. Thanks.",331710,uncivil,"Oh come on, putting a basic here is what this patch does"" comment should be part of every patch, otherwise what is there to comment on if we don't know what is going on in the patch itself?  Anyway, I provided a bunch of feedback to the ""real"" patch in this series...""","Oh come on, putting a basic here is what this patch does"" comment should be part of every patch, otherwise what is there to comment on if we don't know what is going on in the patch itself?  Anyway, I provided a bunch of feedback to the ""real"" patch in this series..."" Well, it adds documentation :smile: You can just read the patch which is ... the documentation :smile: Yes, you did that's fine. Thanks.",Benjamin Herrenschmidt,benh@kernel.crashing.org,1,0,405,0.5766871165644172,1.0,0.3333333333333333,0.7777777777777778,0,0.0,0.0,0.0,0.0
101,331266,331710,uncivil,"Oh come on, putting a basic ""here is what this patch does"" comment should be part of every patch, otherwise what is there to comment on if we don't know what is going on in the patch itself? Anyway, I provided a bunch of feedback to the ""real"" patch in this series...",331694,uncivil,"(and replying to your other comments as well)...  This is an RFC series, it's not meant for you to take at this point, it's about discussing the overall approach to exposing BMC random tunables"" as explained in patch 0 of the series.  Yes the individual patches aren't yet at the level of polish for a formal submission, we (naively ?) thought that's what the whole RFC tag is about :-)""","(and replying to your other comments as well)...  This is an RFC series, it's not meant for you to take at this point, it's about discussing the overall approach to exposing BMC random tunables"" as explained in patch 0 of the series.  Yes the individual patches aren't yet at the level of polish for a formal submission, we (naively ?) thought that's what the whole RFC tag is about :smile:"" Oh come on, putting a basic ""here is what this patch does"" comment should be part of every patch, otherwise what is there to comment on if we don't know what is going on in the patch itself? Anyway, I provided a bunch of feedback to the ""real"" patch in this series...",Greg KH,gregkh@linuxfoundation.org,1,0,659,0.9141104294478528,1.0,0.5,0.9444444444444444,0,0.0,0.0,0.0,0.0
102,336834,337035,uncivil,"Yeah, not going to happen. You grow that structure from 64 bytes to 96 bytes and with that grow the static footprint of the kernel by 512k (in the very best case) possibly again breaking things like sparc (which have a strict limit on the kernel image size). And all that for data that I've never needed and never even considered useful when looking at lockdep output.",336834,technical,"Analyzing the circular locking dependency splat [2], I can see the following skeleton/pattern:  is trying to acquire lock X. same has previously acquired lock Y.     lock Y depends on lock X (hence chance for deadlock).      Print lock dependency chain Print an example of potential scenario leading to real deadlock.     List all locks held by. Print backtrace (seems to be equal to stack dump). The following questions appeared in my mind when analyzing [2]: (A) What is the chronology of consuming the locks? Is it related to     the order seen in the ""dependency chain""? (B) All four locks are reported to be held by the same task.     Indeeed, based on available backtraces, 3 of 4 are acquired during the load by systemd-udevd. However,     there is a different syscall behind this which made we wonder if it is really systemd-udevd consuming this lock. If not, is it still correct to say that systemd-udevd holds all locks? (C) The example of potential unsafe scenario leading to deadlock     puts a special emphasis on the CPU on which the lock is held.     However, except for the last held lock  whose CPU can be extracted from  there is no CPU-related information for the other locks. doesn't match the stack backtrace   (there is no call in the backtrace).   Maybe I misinterpret the report? ","Analyzing the circular locking dependency splat [2], I can see the following skeleton/pattern  is trying to acquire lock X. same has previously acquired lock Y.     lock Y depends on lock X (hence chance for deadlock).      Print lock dependency chain Print an example of potential scenario leading to real deadlock.     List all locks held by. Print backtrace (seems to be equal to stack dump). The following questions appeared in my mind when analyzing [2]: (A) What is the chronology of consuming the locks? Is it related to     the order seen in the ""dependency chain""? (B) All four locks are reported to be held by the same task.     Indeeed, based on available backtraces, 3 of 4 are acquired during the load by systemd-udevd. However,     there is a different syscall behind this which made we wonder if it is really systemd-udevd consuming this lock. If not, is it still correct to say that systemd-udevd holds all locks? (C) The example of potential unsafe scenario leading to deadlock     puts a special emphasis on the CPU on which the lock is held.     However, except for the last held lock  whose CPU can be extracted from  there is no CPU-related information for the other locks. doesn't match the stack backtrace   (there is no call in the backtrace).   Maybe I misinterpret the report?  Yeah, not going to happen. You grow that structure from 64 bytes to 96 bytes and with that grow the static footprint of the kernel by 512k (in the very best case) possibly again breaking things like sparc (which have a strict limit on the kernel image size). And all that for data that I've never needed and never even considered useful when looking at lockdep output.",Peter Zijlstra,peterz@infradead.org,1,0,1672,0.9851632047477745,1.0,0.3333333333333333,0.043478260869565216,0,0.0,0.0,0.0,0.0
103,336834,337316,uncivil,"I  confirm that in case of x86_64, the bss size is increased by around 1 M with standard config. For sparc there seems to be a dedicated CONFIG_LOCKDEP_SMALL, which seems to downsize the lockdep implementation anyway. It's likely because you infer about certain aspects which are not clearly stated in the deadlock report. As example, the original report doesn't say that the process which holds this is different to the process which holds the other locks. On the contrary, it tells the user that all the locks are being held by the same task, which seems to be wrong. You likely also infer about the order of consuming the locks based on the contents of the stack dump associated to each lock. Without doing some mental diffs between the backtraces, it's not possible to see the chronological order of consuming the locks. Actually this only works for backtraces with common history, i.e. there is no clue what is the time/point of acquiring 'cpu_hotplug_lock.rw_sem' relative to the other locks. The patch mostly shares my personal experience of trying to make sense of lockdep output. It's OK if it doesn't reach mainline. I still hope that I can get some feedback from community regarding the actual cpufreq-related issue pointed out in the splat. I can also reproduce it on v4.14, so it appears to be in the kernel for quite some time. Thank you in advance.",337035,uncivil,"Yeah, not going to happen. You grow that structure from 64 bytes to 96 bytes and with that grow the static footprint of the kernel by 512k (in the very best case) possibly again breaking things like sparc (which have a strict limit on the kernel image size).  And all that for data that I've never needed and never even considered useful when looking at lockdep output.","Yeah, not going to happen. You grow that structure from 64 bytes to 96 bytes and with that grow the static footprint of the kernel by 512k (in the very best case) possibly again breaking things like sparc (which have a strict limit on the kernel image size).  And all that for data that I've never needed and never even considered useful when looking at lockdep output. I  confirm that in case of x86_64, the bss size is increased by around 1 M with standard config. For sparc there seems to be a dedicated CONFIG_LOCKDEP_SMALL, which seems to downsize the lockdep implementation anyway. It's likely because you infer about certain aspects which are not clearly stated in the deadlock report. As example, the original report doesn't say that the process which holds this is different to the process which holds the other locks. On the contrary, it tells the user that all the locks are being held by the same task, which seems to be wrong. You likely also infer about the order of consuming the locks based on the contents of the stack dump associated to each lock. Without doing some mental diffs between the backtraces, it's not possible to see the chronological order of consuming the locks. Actually this only works for backtraces with common history, i.e. there is no clue what is the time/point of acquiring it relative to the other locks. The patch mostly shares my personal experience of trying to make sense of lockdep output. It's OK if it doesn't reach mainline. I still hope that I can get some feedback from community regarding the actual cpufreq-related issue pointed out in the splat. I can also reproduce it on v4.14, so it appears to be in the kernel for quite some time. Thank you in advance.",Eugeniu Rosca,erosca@de.adit-jv.com,0,0,1710,1.0,1.0,0.05,0.17391304347826086,1,0.0,0.0,0.0,0.0
107,358863,358900,uncivil,"

These calling conventions are rather suboptimal.  First of all, none of actor callbacks will ever get called directly. There are only 4 callers.  3 of them (all in this) are of this form.  The fourth is this, which itself is an actor callback. So all these ""return -E..."" in the instances are completely pointless; we should just turn filldir_t into pointer-to-function-returning-bool and get rid of that boilerplate, rather than adding more to it. Furthermore, who the hell cares which callback has stepped into it? ""The first time it happened from getdents in a 32 bit process and that's all you'll ever get out of me"" seems to be less than helpful... And frankly, I would prefer this, making that thing return -EUCLEAN or 0.  Quite possibly - inlining it as well...",358863,technical,"When you e.g. run `find` on a directory for which getdents returns filenames"" that contain slashes, `find` passes those ""filenames"" back to the kernel, which then interprets them as paths. That could conceivably cause userspace to do something bad when accessing something like an untrusted USB stick, but I'm not aware of any specific example.  Instead of returning bogus filenames to userspace, return -EUCLEAN.  ","When you e.g. run `find` on a directory for which getdents returns filenames"" that contain slashes, `find` passes those ""filenames"" back to the kernel, which then interprets them as paths. That could conceivably cause userspace to do something bad when accessing something like an untrusted USB stick, but I'm not aware of any specific example.  Instead of returning bogus filenames to userspace, return -EUCLEAN.   

These calling conventions are rather suboptimal.  First of all, none of actor callbacks will ever get called directly. There are only 4 callers.  3 of them (all in this) are of this form.  The fourth is this, which itself is an actor callback. So all these ""return -E..."" in the instances are completely pointless; we should just turn filldir_t into pointer-to-function-returning-bool and get rid of that boilerplate, rather than adding more to it. Furthermore, who the hell cares which callback has stepped into it? ""The first time it happened from getdents in a 32 bit process and that's all you'll ever get out of me"" seems to be less than helpful... And frankly, I would prefer this, making that thing return -EUCLEAN or 0.  Quite possibly - inlining it as well...",Al Viro,viro@ZenIV.linux.org.uk,0,0,1186,1.0,1.0,0.08333333333333333,0.08333333333333333,0,0.0,0.0,0.0,0.0
108,365796,367116,uncivil,Thanks for the review. The problem we have here is there is a potential to control 3 different LED string but only 2 sinks.  So control bank A can control 2 LED strings and control bank b can control 1 LED string. These values represent device level control and configuration of the LED strings to a specific control bank. I racked my brain trying to figure out how to configure the control banks and associated LED strings. These values are for the device configuration itself and the reg below indicates which control bank the LED node is assigned to. Don't see how you could compute this.  There is no easy way to give indication to the driver which LED node belongs to which control bank.  The control-bank-cfg is a device level property and the reg under the child is a LED string level property denoting the Class node to control bank mapping. Furthermore there are 2 device configurations that can be configured to only use 1 bank for all 3 LED strings. This will be answered in your comments in the code. This I can fix it should be a value between 1 and 6.,367099,technical,"Hi!  That's rather long and verbose way to describe a bitmap, right?   Is rbtree good idea? You don't have that many registers.  ....  No error checking required here?   This checks if we have just one bank, I see it. Should it also check the led actually uses the correct bank?   Is not this function done twice for non-error case?   The if is not needed here.   Misleading, this does nothing with regulators.  			","Hi!  That's rather long and verbose way to describe a bitmap, right?   Is rbtree good idea? You don't have that many registers.  ....  No error checking required here?   This checks if we have just one bank, I see it. Should it also check the led actually uses the correct bank?   Is not this function done twice for non-error case?   The if is not needed here.   Misleading, this does nothing with regulators.  			 Thanks for the review. The problem we have here is there is a potential to control 3 different LED string but only 2 sinks.  So control bank A can control 2 LED strings and control bank b can control 1 LED string. These values represent device level control and configuration of the LED strings to a specific control bank. I racked my brain trying to figure out how to configure the control banks and associated LED strings. These values are for the device configuration itself and the reg below indicates which control bank the LED node is assigned to. Don't see how you could compute this.  There is no easy way to give indication to the driver which LED node belongs to which control bank.  The control-bank-cfg is a device level property and the reg under the child is a LED string level property denoting the Class node to control bank mapping. Furthermore there are 2 device configurations that can be configured to only use 1 bank for all 3 LED strings. This will be answered in your comments in the code. This I can fix it should be a value between 1 and 6.",Dan Murphy,dmurphy@ti.com,0,1,1481,0.8010899182561307,1.0,1.0,0.875,0,0.16666666666666666,0.8333333333333334,0.0,0.0
111,365796,367764,uncivil,"It is better do add some complexity to the driver than to the user configurable settings like DT. Besides - you will only need to check if given led-source is already taken by another node. Some description will be needed for sure, but I don't expect it to be overwhelmingly lengthy. Your control-bank-cfg seemed like having much room for improvement, and it would for sure raise questions on why it was implemented that way. Documenting all available combinations of the configuration is seldom the best solution. It often obscures the issue. In your bindings device configuration is scattered among global control-bank-cfg property and child node's reg property. In my proposal each child node contains all the needed configuration, also in the form of two properties - led-sources and reg. IMHO having all the LED class device related configuration in one place simplifies the analysis.",367698,technical,"I agree to use the led-sources but I still believe this approach may be confusing to other sw devs and will lead to configuration issues by users.  This implementation requires the sw dev to know which strings are controlled by which bank. And this method may produce a misconfiguration like something below where HVLED2 is declared in both bank A and bank B.  The driver will need to be intelligent and declare a miss configuration on the above. Not saying this cannot be done but I am not sure why we want to add all of these extra LoC and intelligence in the kernel driver. The driver cannot make assumptions on the intention.  And the device tree documentation will need to pretty much need a lengthy explanation on how to configure the child nodes.  The implementation I suggested removes that ambiguity.  It is a simple integer that is written to the device as part of the device configuration, which the config is a setting for the device.  The child nodes denote which bank the exposed LED node will control.  Removing any need for the sw developers new or old to know the specific device configurations. ","I agree to use the led-sources but I still believe this approach may be confusing to other sw devs and will lead to configuration issues by users.  This implementation requires the sw dev to know which strings are controlled by which bank. And this method may produce a misconfiguration like something below where HVLED2 is declared in both bank A and bank B.  The driver will need to be intelligent and declare a miss configuration on the above. Not saying this cannot be done but I am not sure why we want to add all of these extra LoC and intelligence in the kernel driver. The driver cannot make assumptions on the intention.  And the device tree documentation will need to pretty much need a lengthy explanation on how to configure the child nodes.  The implementation I suggested removes that ambiguity.  It is a simple integer that is written to the device as part of the device configuration, which the config is a setting for the device.  The child nodes denote which bank the exposed LED node will control.  Removing any need for the sw developers new or old to know the specific device configurations.  It is better do add some complexity to the driver than to the user configurable settings like DT. Besides - you will only need to check if given led-source is already taken by another node. Some description will be needed for sure, but I don't expect it to be overwhelmingly lengthy. Your control-bank-cfg seemed like having much room for improvement, and it would for sure raise questions on why it was implemented that way. Documenting all available combinations of the configuration is seldom the best solution. It often obscures the issue. In your bindings device configuration is scattered among global control-bank-cfg property and child node's reg property. In my proposal each child node contains all the needed configuration, also in the form of two properties - led-sources and reg. IMHO having all the LED class device related configuration in one place simplifies the analysis.",Jacek Anaszewski,jacek.anaszewski@gmail.com,1,0,2003,1.0,1.0,0.1111111111111111,0.6666666666666666,0,0.16666666666666666,0.6666666666666666,0.0,0.0
113,372597,372959,uncivil,"This patch was corrupted by your email client, for example it turned TAB characters into sequences of spaces. Please fix this, email a test patch to yourself, and do not resend the patch to this mailing list until you can successfully extract and cleanly apply the test patch you email to yourself. Thank you.",372597,technical,"The tap_queue and the tap_dev"" are loosely coupled, not ""macvlan_dev"".  And I also change one rcu_read_lock's place, seems can reduce rcu critical section a little. ","The tap_queue and the tap_dev"" are loosely coupled, not ""macvlan_dev"".  And I also change one rcu_read_lock's place, seems can reduce rcu critical section a little.  This patch was corrupted by your email client, for example it turned TAB characters into sequences of spaces. Please fix this, email a test patch to yourself, and do not resend the patch to this mailing list until you can successfully extract and cleanly apply the test patch you email to yourself. Thank you.",David Miller,davem@davemloft.net,1,0,475,1.0,1.0,0.3333333333333333,0.3333333333333333,0,0.0,0.0,0.0,0.0
117,378505,378562,uncivil,"Again I'll ask: what is the performance when the log is made large enough that your benchmark is not hammering the slow path? i.e. does running instead of using the default tiny log on your tiny test filesystem make the problem go away? Without that information, we have no idea what the slow path impact on peformance actually is, and whether it is worth persuing optimising slow path behaviour that very, very few production environments see lock contention in....",378507,technical,"In the current log space reservation slowpath code, the log space waiters are waken up by an incoming waiter while holding the lock. As the process of waking up a task can be time consuming, doing it while holding the lock can make spinlock contention, if present, more severe.  This patch changes the slowpath code to use the wake_q for waking up tasks without holding the lock, thus improving performance and reducing spinlock contention level.  Running the AIM7 fserver workload on a 2-socket 24-core 48-thread Broadwell system with a small xfs filesystem on ramfs, the performance increased from 192,666 jobs/min to 285,221 with this change. ","In the current log space reservation slowpath code, the log space waiters are waken up by an incoming waiter while holding the lock. As the process of waking up a task can be time consuming, doing it while holding the lock can make spinlock contention, if present, more severe.  This patch changes the slowpath code to use the wake_q for waking up tasks without holding the lock, thus improving performance and reducing spinlock contention level.  Running the AIM7 fserver workload on a 2-socket 24-core 48-thread Broadwell system with a small xfs filesystem on ramfs, the performance increased from 192,666 jobs/min to 285,221 with this change.  Again I'll ask: what is the performance when the log is made large enough that your benchmark is not hammering the slow path? i.e. does running instead of using the default tiny log on your tiny test filesystem make the problem go away? Without that information, we have no idea what the slow path impact on peformance actually is, and whether it is worth persuing optimising slow path behaviour that very, very few production environments see lock contention in....",Dave Chinner,david@fromorbit.com,0,0,1113,1.0,1.0,0.2,0.6,0,0.0,1.0,0.0,0.0
120,383199,392690,uncivil,"Ick, this is still messy, just try making this. Yeah, it's over 80 columns, but it looks better and is easier to read, right? Also, all your patches have the whitespace turned from tabs into spaces, making them impossible to be applied even if I wanted to :)",383199,technical,Using checkpatch.pl I was able to find a multiline dereference which goes again the coding style for the kernel. I'm still working on my email client so the indentation looks bad here (in gmail) but the arguments for this should go just under the opening ,"Using checkpatch.pl I was able to find a multiline dereference which goes again the coding style for the kernel. I'm still working on my email client so the indentation looks bad here (in gmail) but the arguments for this should go just under the opening  Ick, this is still messy, just try making this. Yeah, it's over 80 columns, but it looks better and is easier to read, right? Also, all your patches have the whitespace turned from tabs into spaces, making them impossible to be applied even if I wanted to :)",Greg KH,gregkh@linuxfoundation.org,1,0,514,1.0,1.0,0.5,0.5,1,1.0,0.0,1.0,0.0
123,391895,397297,uncivil,"I don't call this non-intrusive. I'll beg to differ; this isn't anywhere near something to consider merging. Also 'happened' suggests a certain stage of completeness, this again doesn't qualify. There are known scalability problems with the existing cgroup muck; you just made things a ton worse. The existing cgroup overhead is significant, you also made that many times worse. The cgroup stuff needs cleanups and optimization, not this. That is the whole and only reason you did this; and it doesn't even begin to cover the requirements for it. Not to mention I detest cgroups; for their inherent complixity and the performance costs associated with them.  _If_ we're going to do something for L1TF then I feel it should not depend on cgroups. It is after all, perfectly possible to run a kvm thingy without cgroups. 
Note that in order to avoid PLE and paravirt spinlocks and paravirt tlb-invalidate you have to gang-schedule the _entire_ VM, not just SMT siblings. Now explain to me how you're going to gang-schedule a VM with a good number of vCPU threads (say spanning a number of nodes) and preserving the rest of CFS without it turning into a massive trainwreck? Such things (gang scheduling VMs) _are_ possible, but not within the confines of something like CFS, they are also fairly inefficient because, as you do note, you will have to explicitly schedule idle time for idle vCPUs. Things like the Tableau scheduler are what come to mind; but I'm not sure how to integrate that with a general purpose scheduling scheme. You pretty much have to dedicate a set of CPUs to just scheduling VMs with such a scheduler. And that would call for cpuset-v2 integration along with a new scheduling class. And then people will complain again that partitioning a system isn't dynamic enough and we need magic :/ (and this too would be tricky to virtualize itself). You gloss over a ton of details here; many of which are non trivial and marked broken in your patches. Unless you have solid suggestions on how to deal with all of them, this is a complete non-starter. The per-cpu IRQ/steal time accounting for example. The task timeline isn't the same on every CPU because of those. You now basically require steal time and IRQ load to match between CPUs. That places very strict requirements and effectively breaks virt invariance. That is, the scheduler now behaves significantly different inside a VM than it does outside of it -- without the guest being gang scheduled itself and having physical pinning to reflect the same topology the coschedule=1 thing should not be exposed in a guest. And that is a mayor failing IMO. Also; I think you're sharing a cfs_rq between CPUs. that is broken, the virtual runtime stuff needs nontrivial modifications for multiple CPUs. And if you do that, I've no idea how you're dealing with SMP affinities. You don't even begin to outline how you preserve smp-nice fairness. IOW it's completely friggin useless for L1TF. Have you actually read your own code? What about that atrocious locking you sprinkle all over the place? 'some additional lock contention' doesn't even begin to describe that horror show. Hint: we're not going to increase the lockdep subclasses, and most certainly not for scheduler locking. All in all, I'm not inclined to consider this approach, it complicates an already overly complicated thing (cpu-cgroups) and has a ton of unresolved issues while at the same time it doesn't (and cannot) meet the goal it was made for.",396847,technical,"Here is an extra"" patch containing bug fixes and warning removals, that I have accumulated up to this point.  It goes on top of the other 60 patches. (When it is time for v2, these fixes will be integrated into the appropriate patches within the series.)  The changes are:  1. Avoid a hang with nested scheduled task groups. 2. Get rid of a lockdep warning. 3. Get rid of warnings about missed clock updates. 4. Get rid of ""untested code path"" warnings/reminders (after testing    said code paths).  This should make experimenting with this patch series a little less bumpy.  ","Here is an extra"" patch containing bug fixes and warning removals, that I have accumulated up to this point.  It goes on top of the other 60 patches. (When it is time for v2, these fixes will be integrated into the appropriate patches within the series.)  The changes are:  1. Avoid a hang with nested scheduled task groups. 2. Get rid of a lockdep warning. 3. Get rid of warnings about missed clock updates. 4. Get rid of ""untested code path"" warnings/reminders (after testing    said code paths).  This should make experimenting with this patch series a little less bumpy.   I don't call this non-intrusive. I'll beg to differ; this isn't anywhere near something to consider merging. Also 'happened' suggests a certain stage of completeness, this again doesn't qualify. There are known scalability problems with the existing cgroup muck; you just made things a ton worse. The existing cgroup overhead is significant, you also made that many times worse. The cgroup stuff needs cleanups and optimization, not this. That is the whole and only reason you did this; and it doesn't even begin to cover the requirements for it. Not to mention I detest cgroups; for their inherent complixity and the performance costs associated with them.  _If_ we're going to do something for L1TF then I feel it should not depend on cgroups. It is after all, perfectly possible to run a kvm thingy without cgroups. 
Note that in order to avoid PLE and paravirt spinlocks and paravirt tlb-invalidate you have to gang-schedule the _entire_ VM, not just SMT siblings. Now explain to me how you're going to gang-schedule a VM with a good number of vCPU threads (say spanning a number of nodes) and preserving the rest of CFS without it turning into a massive trainwreck? Such things (gang scheduling VMs) _are_ possible, but not within the confines of something like CFS, they are also fairly inefficient because, as you do note, you will have to explicitly schedule idle time for idle vCPUs. Things like the Tableau scheduler are what come to mind; but I'm not sure how to integrate that with a general purpose scheduling scheme. You pretty much have to dedicate a set of CPUs to just scheduling VMs with such a scheduler. And that would call for cpuset-v2 integration along with a new scheduling class. And then people will complain again that partitioning a system isn't dynamic enough and we need magic :/ (and this too would be tricky to virtualize itself). You gloss over a ton of details here; many of which are non trivial and marked broken in your patches. Unless you have solid suggestions on how to deal with all of them, this is a complete non-starter. The per-cpu IRQ/steal time accounting for example. The task timeline isn't the same on every CPU because of those. You now basically require steal time and IRQ load to match between CPUs. That places very strict requirements and effectively breaks virt invariance. That is, the scheduler now behaves significantly different inside a VM than it does outside of it -- without the guest being gang scheduled itself and having physical pinning to reflect the same topology the coschedule=1 thing should not be exposed in a guest. And that is a mayor failing IMO. Also; I think you're sharing a cfs_rq between CPUs. that is broken, the virtual runtime stuff needs nontrivial modifications for multiple CPUs. And if you do that, I've no idea how you're dealing with SMP affinities. You don't even begin to outline how you preserve smp-nice fairness. IOW it's completely friggin useless for L1TF. Have you actually read your own code? What about that atrocious locking you sprinkle all over the place? 'some additional lock contention' doesn't even begin to describe that horror show. Hint: we're not going to increase the lockdep subclasses, and most certainly not for scheduler locking. All in all, I'm not inclined to consider this approach, it complicates an already overly complicated thing (cpu-cgroups) and has a ton of unresolved issues while at the same time it doesn't (and cannot) meet the goal it was made for.",Peter Zijlstra,peterz@infradead.org,1,0,4057,0.32627291242362527,1.0,0.030303030303030304,0.0661764705882353,0,0.06896551724137931,0.9310344827586207,0.0,0.0
124,391895,397649,uncivil,"Mm... there is certainly room for interpretation. :) For example, it is still possible to set affinities, to use nice, and to tune all the other existing CFS knobs. That is, if you have tuned the scheduler to your workload or your workload depends on some CFS feature to work efficiently (whether on purpose or not), then running with this patch set should not change the behavior of said workload. This patch set should ""just"" give the user the additional ability to coordinate scheduling decisions across multiple CPUs. At least, that's my goal.

If someone doesn't need it, they don't have to use it. Just like task groups. But maybe, people start experimenting with coordinated scheduling decisions -- after all, there is a ton of research on what one *could* do, if there was coscheduling. I did look over much of that research. What I didn't like about many of them, is that evaluation is based on a ""prototype"", that -- while making the point that coscheduling might be beneficial for that use case -- totally screws over the scheduler for any other use case. Like coscheduling based on deterministic, timed context switches across all CPUs. Bye bye interactivity. That is, what I call intrusive.
As mentioned before, existing scheduler features, like preemption, (should) still work as before with this variant of coscheduling, with the same look and feel. And who knows, maybe someone will come up with a use case that moves coscheduling out of its niche; like the auto-grouping feature promoted the use of task groups. 
I agree, that this isn't ready to be merged. Still, the current state is good to start a discussion about the involved mechanics. Are you referring to cgroups in general, or task groups (aka. the cpu controller) specifically?
With respect to scalability: many coscheduling use cases don't require synchronization across the whole system. With this patch set, only those parts that are actually coscheduled are involved in synchronization. So, conceptually, this scales to larger systems from that point of view.
If coscheduling of a larger fraction of the system is required, costs increase. So what? It's a trade-off. It may *still* be beneficial for a use case. If it is, it might get adopted. If not, that particular use case may be considered impractical unless someone comes up with a better implementation of coscheduling.
With respect to the need of cleanups and optimizations: I agree, that task groups are a bit messy. For example, here's my current wish list off the top of my head: 
a) lazy scheduler operations; for example: when dequeuing a task, don't bother walking up the task group hierarchy to dequeue all the SEs -- do it lazily when encountering an empty CFS RQ during picking when we hold the lock anyway.
b) ability to move CFS RQs between CPUs: someone changed the affinity of a cpuset? No problem, just attach the runqueue with all the tasks elsewhere. No need to touch each and every task.
c) light-weight task groups: don't allocate a runqueue for every CPU in the system, when it is known that tasks in the task group will only ever run on at most two CPUs, or so. (And while there is of course a use case for VMs in this, another class of use cases are auxiliary tasks, see eg, [1-5].)
Is this the level of optimizations, you're thinking about? Or do you want to throw away the whole nested CFS RQ experience in the code? It really isn't. But as your mind seems made up, I'm not going to bother to argue. Yes it is. But, for example, you won't have group-based fairness between multiple kvm thingies. Assuming, there is a cgroup-less solution that can prevent simultaneous execution of tasks on a core, when they're not supposed to. How would you tell the scheduler, which tasks these are? You probably don't -- for the same reason, why it is a bad idea to give an endless loop realtime priority. It's just a bad idea. As I said in the text you quoted: coscheduling comes with its own set of advantages and disadvantages. Just because you find one example, where it is a bad idea, doesn't make it a bad thing in general. With gang scheduling as defined by Feitelson and Rudolph, you'd have to explicitly schedule idle time. With coscheduling as defined by Ousterhout, you don't. In this patch set, the scheduling of idle time is ""merely"" a quirk of the implementation. And even with this implementation, there's nothing stopping you from down-sizing the width of the coscheduled set to take out the idle vCPUs dynamically, cutting down on fragmentation. Hence my ""counter"" suggestion in the form of this patch set: Integrated into a general purpose scheduler, no need to partition off a part of the system, not tied to just VM use cases. Yes, I do. :) I wanted a summary, not a design document. Maybe I was a bit to eager in condensing the design to just a few paragraphs... Address them one by one. Probably do some of the optimizations you suggested to just get rid of some of them. It's work in progress. Though, at this stage I am also really interested in things that are broken, that I am not aware of yet. I'll have to read up some more code to make a qualified statement here. It is not shared per se. There's only one CPU (the leader) making the scheduling decision for that runqueue and if another CPU needs to modify the runqueue, it works like it does for CPU runqueues as well: the other CPU works with the leader's time. There are also no tasks in a runqueue when it is responsible for more than one CPU.

Assuming, that a runqueue is responsible for a core and there are runnable tasks within the task group on said core, then there will one SE enqueued in that runqueue, a so called SD-SE (scheduling domain SE, or synchronization domain SE). This SD-SE represents the per CPU runqueues of this core of this task group. (As opposed to a ""normal"" task group SE (TG-SE), which represents just one runqueue in a different task group.) Tasks are still only enqueued in the per CPU runqueues. Works as before (or will work as before): a coscheduled task group has its own set of per CPU runqueues that hold the tasks of this group (per CPU). The load balancer will work on this subset of runqueues as it does on the ""normal"" per CPU runqueues -- smp-nice fairness and all. Do you believe me now, that L1TF is not ""the whole and only reason"" I did this? :grinning:
Currently, there are more code paths than I like, that climb up the parent relation to the top. They need to go, if we want to coschedule larger parts of the system in a more efficient manner. Hence, parts of my wish list further up.
That said, it is not as bad as you make it sound for the following three reasons:
a) The amount of CPUs that compete for a lock is currently governed by the ""cosched_max_level"" command line argument, making it a conscious decision to increase the overall overhead. Hence, coscheduling at, e.g., core level does not have a too serious impact on lock contention.
b) The runqueue locks are usually only taken by the leader of said runqueue. Hence, there is often only one user per lock even at higher levels. The prominent exception at this stage of the patch set is that enqueue and dequeue operations walk up the hierarchy up to the ""cosched_max_level"". And even then, due to lock chaining, multiple enqueue/dequeue operations on different CPUs can bubble up the shared part of the hierarchy in parallel.
c) The scheduling decision does not cause any lock contention by itself. Each CPU only accesses runqueues, where itself is the leader. Hence, once you have a relatively stable situation, lock contention is not an issue.
That's fine. Due to the overhead of nesting cgroups that you mentioned earlier, that many levels in the runqueue hierarchy are likely to be impracticable anyway. For the future, I imagine a more dynamic variant of task groups/scheduling domains, that can provide all the flexibility one would want without that deep of a nesting. At this stage, it is just a way to experiment with larger systems without having to disable lockdep.
Of course, if you have a suggestion for a different locking scheme, we can discuss that as well. The current one, is what I considered most suitable among some alternatives under the premise I was working: integrate coscheduling in a scheduler as an additional feature (instead of, eg, write a scheduler capable of coscheduling). So, I probably haven't considered all alternatives. Even if you're not inclined -- at this stage, if I may be so bold :) -- your feedback is valuable. Thank you for that.",397297,uncivil,"I don't call this non-intrusive.   I'll beg to differ, this isn't anywhere near something to consider merging. Also 'happened' suggests a certain stage of completeness, this again doesn't qualify.   There are known scalability problems with the existing cgroup muck, you just made things a ton worse. The existing cgroup overhead is significant, you also made that many times worse.  The cgroup stuff needs cleanups and optimization, not this.    That is the whole and only reason you did this, and it doesn't even begin to cover the requirements for it.  Not to mention I detest cgroups, for their inherent complixity and the performance costs associated with them.  _If_ we're going to do something for L1TF then I feel it should not depend on cgroups.  It is after all, perfectly possible to run a kvm thingy without cgroups.   Note that in order to avoid PLE and paravirt spinlocks and paravirt tlb-invalidate you have to gang-schedule the _entire_ VM, not just SMT siblings.  Now explain to me how you're going to gang-schedule a VM with a good number of vCPU threads (say spanning a number of nodes) and preserving the rest of CFS without it turning into a massive trainwreck?  Such things (gang scheduling VMs) _are_ possible, but not within the confines of something like CFS, they are also fairly inefficient because, as you do note, you will have to explicitly schedule idle time for idle vCPUs.  Things like the Tableau scheduler are what come to mind, but I'm not sure how to integrate that with a general purpose scheduling scheme. You pretty much have to dedicate a set of CPUs to just scheduling VMs with such a scheduler.  And that would call for cpuset-v2 integration along with a new scheduling class.  And then people will complain again that partitioning a system isn't dynamic enough and we need magic :unhappy:  (and this too would be tricky to virtualize itself)   You gloss over a ton of details here, many of which are non trivial and marked broken in your patches. Unless you have solid suggestions on how to deal with all of them, this is a complete non-starter.  The per-cpu IRQ/steal time accounting for example. The task timeline isn't the same on every CPU because of those.  You now basically require steal time and IRQ load to match between CPUs. That places very strict requirements and effectively breaks virt invariance. That is, the scheduler now behaves significantly different inside a VM than it does outside of it -- without the guest being gang scheduled itself and having physical pinning to reflect the same topology the coschedule=1 thing should not be exposed in a guest. And that is a mayor failing IMO.  Also, I think you're sharing a cfs_rq between CPUs: that is broken, the virtual runtime stuff needs nontrivial modifications for multiple CPUs. And if you do that, I've no idea how you're dealing with SMP affinities.  You don't even begin to outline how you preserve smp-nice fairness.   IOW it's completely friggin useless for L1TF.   Have you actually read your own code?  What about that atrocious locking you sprinkle all over the place? 'some additional lock contention' doesn't even begin to describe that horror show.  Hint: we're not going to increase the lockdep subclasses, and most certainly not for scheduler locking.   All in all, I'm not inclined to consider this approach, it complicates an already overly complicated thing (cpu-cgroups) and has a ton of unresolved issues while at the same time it doesn't (and cannot) meet the goal it was made for.","I don't call this non-intrusive.   I'll beg to differ, this isn't anywhere near something to consider merging. Also 'happened' suggests a certain stage of completeness, this again doesn't qualify.   There are known scalability problems with the existing cgroup muck, you just made things a ton worse. The existing cgroup overhead is significant, you also made that many times worse.  The cgroup stuff needs cleanups and optimization, not this.    That is the whole and only reason you did this, and it doesn't even begin to cover the requirements for it.  Not to mention I detest cgroups, for their inherent complixity and the performance costs associated with them.  _If_ we're going to do something for L1TF then I feel it should not depend on cgroups.  It is after all, perfectly possible to run a kvm thingy without cgroups.   Note that in order to avoid PLE and paravirt spinlocks and paravirt tlb-invalidate you have to gang-schedule the _entire_ VM, not just SMT siblings.  Now explain to me how you're going to gang-schedule a VM with a good number of vCPU threads (say spanning a number of nodes) and preserving the rest of CFS without it turning into a massive trainwreck?  Such things (gang scheduling VMs) _are_ possible, but not within the confines of something like CFS, they are also fairly inefficient because, as you do note, you will have to explicitly schedule idle time for idle vCPUs.  Things like the Tableau scheduler are what come to mind, but I'm not sure how to integrate that with a general purpose scheduling scheme. You pretty much have to dedicate a set of CPUs to just scheduling VMs with such a scheduler.  And that would call for cpuset-v2 integration along with a new scheduling class.  And then people will complain again that partitioning a system isn't dynamic enough and we need magic :unhappy:  (and this too would be tricky to virtualize itself)   You gloss over a ton of details here, many of which are non trivial and marked broken in your patches. Unless you have solid suggestions on how to deal with all of them, this is a complete non-starter.  The per-cpu IRQ/steal time accounting for example. The task timeline isn't the same on every CPU because of those.  You now basically require steal time and IRQ load to match between CPUs. That places very strict requirements and effectively breaks virt invariance. That is, the scheduler now behaves significantly different inside a VM than it does outside of it -- without the guest being gang scheduled itself and having physical pinning to reflect the same topology the coschedule=1 thing should not be exposed in a guest. And that is a mayor failing IMO.  Also, I think you're sharing a cfs_rq between CPUs: that is broken, the virtual runtime stuff needs nontrivial modifications for multiple CPUs. And if you do that, I've no idea how you're dealing with SMP affinities.  You don't even begin to outline how you preserve smp-nice fairness.   IOW it's completely friggin useless for L1TF.   Have you actually read your own code?  What about that atrocious locking you sprinkle all over the place? 'some additional lock contention' doesn't even begin to describe that horror show.  Hint: we're not going to increase the lockdep subclasses, and most certainly not for scheduler locking.   All in all, I'm not inclined to consider this approach, it complicates an already overly complicated thing (cpu-cgroups) and has a ton of unresolved issues while at the same time it doesn't (and cannot) meet the goal it was made for. Mm... there is certainly room for interpretation. :) For example, it is still possible to set affinities, to use nice, and to tune all the other existing CFS knobs. That is, if you have tuned the scheduler to your workload or your workload depends on some CFS feature to work efficiently (whether on purpose or not), then running with this patch set should not change the behavior of said workload. This patch set should ""just"" give the user the additional ability to coordinate scheduling decisions across multiple CPUs. At least, that's my goal.

If someone doesn't need it, they don't have to use it. Just like task groups. But maybe, people start experimenting with coordinated scheduling decisions -- after all, there is a ton of research on what one *could* do, if there was coscheduling. I did look over much of that research. What I didn't like about many of them, is that evaluation is based on a ""prototype"", that -- while making the point that coscheduling might be beneficial for that use case -- totally screws over the scheduler for any other use case. Like coscheduling based on deterministic, timed context switches across all CPUs. Bye bye interactivity. That is, what I call intrusive.
As mentioned before, existing scheduler features, like preemption, (should) still work as before with this variant of coscheduling, with the same look and feel. And who knows, maybe someone will come up with a use case that moves coscheduling out of its niche; like the auto-grouping feature promoted the use of task groups. 
I agree, that this isn't ready to be merged. Still, the current state is good to start a discussion about the involved mechanics. Are you referring to cgroups in general, or task groups (aka. the cpu controller) specifically?
With respect to scalability: many coscheduling use cases don't require synchronization across the whole system. With this patch set, only those parts that are actually coscheduled are involved in synchronization. So, conceptually, this scales to larger systems from that point of view.
If coscheduling of a larger fraction of the system is required, costs increase. So what? It's a trade-off. It may *still* be beneficial for a use case. If it is, it might get adopted. If not, that particular use case may be considered impractical unless someone comes up with a better implementation of coscheduling.
With respect to the need of cleanups and optimizations: I agree, that task groups are a bit messy. For example, here's my current wish list off the top of my head: 
a) lazy scheduler operations; for example: when dequeuing a task, don't bother walking up the task group hierarchy to dequeue all the SEs -- do it lazily when encountering an empty CFS RQ during picking when we hold the lock anyway.
b) ability to move CFS RQs between CPUs: someone changed the affinity of a cpuset? No problem, just attach the runqueue with all the tasks elsewhere. No need to touch each and every task.
c) light-weight task groups: don't allocate a runqueue for every CPU in the system, when it is known that tasks in the task group will only ever run on at most two CPUs, or so. (And while there is of course a use case for VMs in this, another class of use cases are auxiliary tasks, see eg, [1-5].)
Is this the level of optimizations, you're thinking about? Or do you want to throw away the whole nested CFS RQ experience in the code? It really isn't. But as your mind seems made up, I'm not going to bother to argue. Yes it is. But, for example, you won't have group-based fairness between multiple kvm thingies. Assuming, there is a cgroup-less solution that can prevent simultaneous execution of tasks on a core, when they're not supposed to. How would you tell the scheduler, which tasks these are? You probably don't -- for the same reason, why it is a bad idea to give an endless loop realtime priority. It's just a bad idea. As I said in the text you quoted: coscheduling comes with its own set of advantages and disadvantages. Just because you find one example, where it is a bad idea, doesn't make it a bad thing in general. With gang scheduling as defined by Feitelson and Rudolph, you'd have to explicitly schedule idle time. With coscheduling as defined by Ousterhout, you don't. In this patch set, the scheduling of idle time is ""merely"" a quirk of the implementation. And even with this implementation, there's nothing stopping you from down-sizing the width of the coscheduled set to take out the idle vCPUs dynamically, cutting down on fragmentation. Hence my ""counter"" suggestion in the form of this patch set: Integrated into a general purpose scheduler, no need to partition off a part of the system, not tied to just VM use cases. Yes, I do. :) I wanted a summary, not a design document. Maybe I was a bit to eager in condensing the design to just a few paragraphs... Address them one by one. Probably do some of the optimizations you suggested to just get rid of some of them. It's work in progress. Though, at this stage I am also really interested in things that are broken, that I am not aware of yet. I'll have to read up some more code to make a qualified statement here. It is not shared per se. There's only one CPU (the leader) making the scheduling decision for that runqueue and if another CPU needs to modify the runqueue, it works like it does for CPU runqueues as well: the other CPU works with the leader's time. There are also no tasks in a runqueue when it is responsible for more than one CPU.

Assuming, that a runqueue is responsible for a core and there are runnable tasks within the task group on said core, then there will one SE enqueued in that runqueue, a so called SD-SE (scheduling domain SE, or synchronization domain SE). This SD-SE represents the per CPU runqueues of this core of this task group. (As opposed to a ""normal"" task group SE (TG-SE), which represents just one runqueue in a different task group.) Tasks are still only enqueued in the per CPU runqueues. Works as before (or will work as before): a coscheduled task group has its own set of per CPU runqueues that hold the tasks of this group (per CPU). The load balancer will work on this subset of runqueues as it does on the ""normal"" per CPU runqueues -- smp-nice fairness and all. Do you believe me now, that L1TF is not ""the whole and only reason"" I did this? :grinning:
Currently, there are more code paths than I like, that climb up the parent relation to the top. They need to go, if we want to coschedule larger parts of the system in a more efficient manner. Hence, parts of my wish list further up.
That said, it is not as bad as you make it sound for the following three reasons:
a) The amount of CPUs that compete for a lock is currently governed by the ""cosched_max_level"" command line argument, making it a conscious decision to increase the overall overhead. Hence, coscheduling at, e.g., core level does not have a too serious impact on lock contention.
b) The runqueue locks are usually only taken by the leader of said runqueue. Hence, there is often only one user per lock even at higher levels. The prominent exception at this stage of the patch set is that enqueue and dequeue operations walk up the hierarchy up to the ""cosched_max_level"". And even then, due to lock chaining, multiple enqueue/dequeue operations on different CPUs can bubble up the shared part of the hierarchy in parallel.
c) The scheduling decision does not cause any lock contention by itself. Each CPU only accesses runqueues, where itself is the leader. Hence, once you have a relatively stable situation, lock contention is not an issue.
That's fine. Due to the overhead of nesting cgroups that you mentioned earlier, that many levels in the runqueue hierarchy are likely to be impracticable anyway. For the future, I imagine a more dynamic variant of task groups/scheduling domains, that can provide all the flexibility one would want without that deep of a nesting. At this stage, it is just a way to experiment with larger systems without having to disable lockdep.
Of course, if you have a suggestion for a different locking scheme, we can discuss that as well. The current one, is what I considered most suitable among some alternatives under the premise I was working: integrate coscheduling in a scheduler as an additional feature (instead of, eg, write a scheduler capable of coscheduling). So, I probably haven't considered all alternatives. Even if you're not inclined -- at this stage, if I may be so bold :) -- your feedback is valuable. Thank you for that.",Jan H. Schönherr,jschoenh@amazon.de,0,1,12040,1.0,1.0,0.010526315789473684,0.3088235294117647,0,0.06896551724137931,0.9195402298850575,0.0,0.0
125,399771,400133,uncivil,"How can you set a shared variable with no synchronization? A bool is particularly dangerous here, at least on some arches.
",399771,technical,"When link status change needs to be committed and rtnl lock couldn't be taken, avoid redisplay of same link status change message.  ","When link status change needs to be committed and rtnl lock couldn't be taken, avoid redisplay of same link status change message.   How can you set a shared variable with no synchronization? A bool is particularly dangerous here, at least on some arches.
",Eric Dumazet,eric.dumazet@gmail.com,1,0,256,0.2692307692307692,1.0,0.5,0.2,0,0.0,0.9714285714285714,0.0,0.0
126,399771,401526,uncivil,"
If try lock can not grab RTNL, there is no way the current thread can set the  variable without a race, if the word including rtnl_needed is shared by other fields in the structure. Your patch adds a subtle possibility of future bugs, even if it runs fine today. Do not pave the way for future bugs, make your code robust, please.",401073,technical,"Thanks for reviewing the patch. rtnl_needed is not a shared variable, it is part of bonding structure, that is one per bonding driver instance. There can't be two parallel instances of bond_miimon_inspect for a single  bonding driver instance at any given point of time. and only bond_miimon_inspect updates it. That's why I think there is no need of any synchronization here.    Thank you for cautioning us on bool usage. even a u8 can meet our requirement.  we will change it.  but, if time permits can you share more on particularly dangerous here, at least on some arches.","Thanks for reviewing the patch. rtnl_needed is not a shared variable, it is part of bonding structure, that is one per bonding driver instance. There can't be two parallel instances of bond_miimon_inspect for a single  bonding driver instance at any given point of time. and only bond_miimon_inspect updates it. That's why I think there is no need of any synchronization here.    Thank you for cautioning us on bool usage. even a u8 can meet our requirement.  we will change it.  but, if time permits can you share more on particularly dangerous here, at least on some arches. 
If try lock can not grab RTNL, there is no way the current thread can set the  variable without a race, if the word including rtnl_needed is shared by other fields in the structure. Your patch adds a subtle possibility of future bugs, even if it runs fine today. Do not pave the way for future bugs, make your code robust, please.",Eric Dumazet,eric.dumazet@gmail.com,1,0,908,1.0,1.0,0.3333333333333333,0.6,0,0.02857142857142857,0.9428571428571428,0.0,0.14285714285714285
127,402510,413538,uncivil,"It would be very helpful if you cc all involved people on the cover letter instead of just cc'ing your own pile of email addresses. CC'ed now. This is really not helpful. The cover letter and the change logs should contain a summary of that discussion and a proper justification of the proposed change. Just saying 'sysadmins might want to allow' is not useful at all, it's yet another 'I want a pony' thing.

I read through the previous thread and there was a clear request to involve security people into this. Especially those who are deeply involved with hardware side channels. I don't see anyone Cc'ed on the whole series. For the record, I'm not buying the handwavy 'more noise' argument at all. It wants a proper analysis and we need to come up with criteria which PMUs can be exposed at all. All of this want's a proper documentation clearly explaining the risks and scope of these knobs per PMU. Just throwing magic knobs at sysadmins and then saying 'its their problem to figure it out' is not acceptable.",413483,technical,There is a hunk a bit lower in the patch where in perf_pmu_register the  initial setting is assigned from the global sysctl.   Sure!,"There is a hunk a bit lower in the patch where in perf_pmu_register the  initial setting is assigned from the global sysctl.   Sure! It would be very helpful if you cc all involved people on the cover letter instead of just cc'ing your own pile of email addresses. CC'ed now. This is really not helpful. The cover letter and the change logs should contain a summary of that discussion and a proper justification of the proposed change. Just saying 'sysadmins might want to allow' is not useful at all, it's yet another 'I want a pony' thing.

I read through the previous thread and there was a clear request to involve security people into this. Especially those who are deeply involved with hardware side channels. I don't see anyone Cc'ed on the whole series. For the record, I'm not buying the handwavy 'more noise' argument at all. It wants a proper analysis and we need to come up with criteria which PMUs can be exposed at all. All of this want's a proper documentation clearly explaining the risks and scope of these knobs per PMU. Just throwing magic knobs at sysadmins and then saying 'its their problem to figure it out' is not acceptable.",Thomas Gleixner,tglx@linutronix.de,1,0,1149,0.3243626062322946,1.0,0.08333333333333333,0.010869565217391304,0,0.5333333333333333,0.4,0.0,0.0
128,402510,413650,uncivil,"I accept it was by bad to miss adding Cc's on the cover letter, but my own email addresses hopefully should not bother you. It is simply a question of what I have in .gitconfig vs what I forgot to do manually. Okay, for the next round I will expand the cover letter with at least one concrete example on how it is usable and summarize the discussion a bit. Who would you recommend I add? Because I really don't know..
Presumably you see adding fine grained control as diminishing the overall security rather than raising it? Could you explain why? Because incompetent sysadmin will turn it off for some PMU, while without having the fine-grained control they wouldn't turn it off globally? This feature was requested by the exact opposite concern, that in order to access the i915 PMU, one has to compromise the security of the entire system by allowing access to *all* PMU's. Making this ability fine-grained sounds like a logical solution for solving this weakening of security controls. Concrete example was that on video transcoding farms users want to monitor the utilization of GPU engines (like CPU cores) and they can do that via the i915 PMU. But for that to work today they have to dial down the global perf_event_paranoid setting. Obvious improvement was to allow them to only dial down the i915.perf_event_paranoid setting. As such, for this specific use case at least, the security is increased.",413538,uncivil,"It would be very helpful if you cc all involved people on the cover letter instead of just cc'ing your own pile of email addresses. CC'ed now.   This is really not helpful. The cover letter and the change logs should contain a summary of that discussion and a proper justification of the proposed change. Just saying 'sysadmins might want to allow' is not useful at all, it's yet another 'I want a pony' thing.  I read through the previous thread and there was a clear request to involve security people into this. Especially those who are deeply involved with hardware side channels. I don't see anyone Cc'ed on the whole series.  For the record, I'm not buying the handwavy 'more noise' argument at all. It wants a proper analysis and we need to come up with criteria which PMUs can be exposed at all.  All of this want's a proper documentation clearly explaining the risks and scope of these knobs per PMU. Just throwing magic knobs at sysadmins and then saying 'its their problem to figure it out' is not acceptable.","It would be very helpful if you cc all involved people on the cover letter instead of just cc'ing your own pile of email addresses. CC'ed now.   This is really not helpful. The cover letter and the change logs should contain a summary of that discussion and a proper justification of the proposed change. Just saying 'sysadmins might want to allow' is not useful at all, it's yet another 'I want a pony' thing.  I read through the previous thread and there was a clear request to involve security people into this. Especially those who are deeply involved with hardware side channels. I don't see anyone Cc'ed on the whole series.  For the record, I'm not buying the handwavy 'more noise' argument at all. It wants a proper analysis and we need to come up with criteria which PMUs can be exposed at all.  All of this want's a proper documentation clearly explaining the risks and scope of these knobs per PMU. Just throwing magic knobs at sysadmins and then saying 'its their problem to figure it out' is not acceptable. I accept it was by bad to miss adding Cc's on the cover letter, but my own email addresses hopefully should not bother you. It is simply a question of what I have in .gitconfig vs what I forgot to do manually. Okay, for the next round I will expand the cover letter with at least one concrete example on how it is usable and summarize the discussion a bit. Who would you recommend I add? Because I really don't know..
Presumably you see adding fine grained control as diminishing the overall security rather than raising it? Could you explain why? Because incompetent sysadmin will turn it off for some PMU, while without having the fine-grained control they wouldn't turn it off globally? This feature was requested by the exact opposite concern, that in order to access the i915 PMU, one has to compromise the security of the entire system by allowing access to *all* PMU's. Making this ability fine-grained sounds like a logical solution for solving this weakening of security controls. Concrete example was that on video transcoding farms users want to monitor the utilization of GPU engines (like CPU cores) and they can do that via the i915 PMU. But for that to work today they have to dial down the global perf_event_paranoid setting. Obvious improvement was to allow them to only dial down the i915.perf_event_paranoid setting. As such, for this specific use case at least, the security is increased.",Tvrtko Ursulin,tvrtko.ursulin@linux.intel.com,1,0,2429,0.6728045325779037,1.0,0.058823529411764705,0.14130434782608695,0,0.6,0.4,0.0,0.0
129,402510,413698,uncivil,"The keyword in the above sentence is 'just'. You can add as many of yours
as you want as long as everybody else is cc'ed. Sure, and because you don't know you didn't bother to ask around and ignored the review request. I already added Kees and Jann. Please look for the SECCOMP folks in MAINTAINERS. I did not say at all that this might be diminishing security. And the argumentation with 'incompetent sysadmins' is just the wrong attitude.
What I was asking for is proper documentation and this proper documentation is meant for _competent_ sysadmins.
That documentation has to clearly describe what kind of information is accessible and what potential side effects security wise this might have. You cannot expect that even competent sysadmins know offhand what which PMU might expose. And telling them 'Use Google' is just not the right thing to do.
If you can't explain and document it, then providing the knob is just fulfilling somebodys 'I want a pony' request.
Sure, and this wants to be documented in the cover letter and the changelogs.
But this does also require a proper analysis and documentation why it is not a security risk to expose the i915 PMU or what potential security issues this can create, so that the competent sysadmin can make a judgement.
And the same is required for all other PMUs which can be enabled in the same way for unprivileged access. And we might as well come to the conclusion via analysis that for some PMUs unpriviledged access is just not a good idea and exclude them. I surely know a few which qualify for exclusion, so the right approach is to provide this knob only when the risk is analyzed and documented and the PMU has been flagged as candidate for unpriviledged exposure. I.e. opt in and not opt out.",413650,uncivil,"Hi, I accept it was by bad to miss adding Cc's on the cover letter, but my  own email addresses hopefully should not bother you. It is simply a  question of what I have in .gitconfig vs what I forgot to do manually.   Okay, for the next round I will expand the cover letter with at least  one concrete example on how it is usable and summarize the discussion a bit.   Who would you recommend I add? Because I really don't know..   Presumably you see adding fine grained control as diminishing the  overall security rather than raising it? Could you explain why? Because  incompetent sysadmin will turn it off for some PMU, while without having  the fine-grained control they wouldn't turn it off globally?  This feature was requested by the exact opposite concern, that in order  to access the i915 PMU, one has to compromise the security of the entire  system by allowing access to *all* PMU's.  Making this ability fine-grained sounds like a logical solution for  solving this weakening of security controls.  Concrete example was that on video transcoding farms users want to  monitor the utilization of GPU engines (like CPU cores) and they can do  that via the i915 PMU. But for that to work today they have to dial down  the global setting. Obvious improvement was to allow  them to only dial down the setting. As such,  for this specific use case at least, the security is increased.","Hi, I accept it was by bad to miss adding Cc's on the cover letter, but my  own email addresses hopefully should not bother you. It is simply a  question of what I have in .gitconfig vs what I forgot to do manually.   Okay, for the next round I will expand the cover letter with at least  one concrete example on how it is usable and summarize the discussion a bit.   Who would you recommend I add? Because I really don't know..   Presumably you see adding fine grained control as diminishing the  overall security rather than raising it? Could you explain why? Because  incompetent sysadmin will turn it off for some PMU, while without having  the fine-grained control they wouldn't turn it off globally?  This feature was requested by the exact opposite concern, that in order  to access the i915 PMU, one has to compromise the security of the entire  system by allowing access to *all* PMU's.  Making this ability fine-grained sounds like a logical solution for  solving this weakening of security controls.  Concrete example was that on video transcoding farms users want to  monitor the utilization of GPU engines (like CPU cores) and they can do  that via the i915 PMU. But for that to work today they have to dial down  the global setting. Obvious improvement was to allow  them to only dial down the setting. As such,  for this specific use case at least, the security is increased. The keyword in the above sentence is 'just'. You can add as many of yours
as you want as long as everybody else is cc'ed. Sure, and because you don't know you didn't bother to ask around and ignored the review request. I already added Kees and Jann. Please look for the SECCOMP folks in MAINTAINERS. I did not say at all that this might be diminishing security. And the argumentation with 'incompetent sysadmins' is just the wrong attitude.
What I was asking for is proper documentation and this proper documentation is meant for _competent_ sysadmins.
That documentation has to clearly describe what kind of information is accessible and what potential side effects security wise this might have. You cannot expect that even competent sysadmins know offhand what which PMU might expose. And telling them 'Use Google' is just not the right thing to do.
If you can't explain and document it, then providing the knob is just fulfilling somebodys 'I want a pony' request.
Sure, and this wants to be documented in the cover letter and the changelogs.
But this does also require a proper analysis and documentation why it is not a security risk to expose the i915 PMU or what potential security issues this can create, so that the competent sysadmin can make a judgement.
And the same is required for all other PMUs which can be enabled in the same way for unprivileged access. And we might as well come to the conclusion via analysis that for some PMUs unpriviledged access is just not a good idea and exclude them. I surely know a few which qualify for exclusion, so the right approach is to provide this knob only when the risk is analyzed and documented and the PMU has been flagged as candidate for unpriviledged exposure. I.e. opt in and not opt out.",Thomas Gleixner,tglx@linutronix.de,1,0,3142,0.8668555240793201,1.0,0.05,0.31521739130434784,0,0.6,0.4,0.0,0.0
130,402510,413768,uncivil,"Sure, but you also used the word ""pile"" and I would argue that made the rest of your sentence, after and including ""instead"", sound like it not only bothers you I forgot to Cc people on the cover letter, but it also bothers you I included a ""pile"" of my own addresses. If that wasn't your intention in the slightest then I apologise for misreading it. No, not because of that. You are assuming my actions and motivations and constructing a story. ""did not bother"" = negative connotations, ""ignored"" = negative connotations. Note instead the time lapse between this and previous posting of the series, and if you want to assume something, assume things can get missed and forgotten without intent or malice. Thanks! 
Wrong attitude what? I was trying to guess your reasoning (cues in ""presumably"" and a lot of question marks) since it wasn't clear to me why is your position what it is. I did not mention Google. Well it's not a pony, it is mechanism to avoid having to turn off all security. We can hopefully discuss it without ponies. I am happy to work on the mechanics of achieving this once the security guys and all PMU owners get involved. Even though I am not convinced the bar to allow fine-grained control should be evaluating all possible PMUs*, but if the security folks agree that is the case it is fine by me.
The part of my reply you did not quote explains how the fine-grained control improves security in existing deployments. The documentation I added refers to the existing perf_event_paranoid documentation for explanation of security concerns involved. Which is not much in itself. But essentially we both have a PMU and a knob already. I don't see why adding the same knob per-PMU needs much more stringent criteria to be accepted. But as said, that's for security people to decide.",413698,uncivil,"The keyword in the above sentence is 'just'. You can add as many of yours as you want as long as everybody else is cc'ed.   Sure, and because you don't know you didn't bother to ask around and ignored the review request.  I already added them. Please look for the SECCOMP folks in MAINTAINERS.   I did not say at all that this might be diminishing security. And the argumentation with 'incompetent sysadmins' is just the wrong attitude.  What I was asking for is proper documentation and this proper documentation is meant for _competent_ sysadmins.  That documentation has to clearly describe what kind of information is accessible and what potential side effects security wise this might have. You cannot expect that even competent sysadmins know offhand what which PMU might expose. And telling them 'Use Google' is just not the right thing to do.  If you can't explain and document it, then providing the knob is just fulfilling somebodys 'I want a pony' request.   Sure, and this wants to be documented in the cover letter and the changelogs.  But this does also require a proper analysis and documentation why it is not a security risk to expose the i915 PMU or what potential security issues this can create, so that the competent sysadmin can make a judgement.  And the same is required for all other PMUs which can be enabled in the same way for unprivileged access. And we might as well come to the conclusion via analysis that for some PMUs unpriviledged access is just not a good idea and exclude them. I surely know a few which qualify for exclusion, so the right approach is to provide this knob only when the risk is analyzed and documented and the PMU has been flagged as candidate for unpriviledged exposure. I.e. opt in and not opt out.","The keyword in the above sentence is 'just'. You can add as many of yours as you want as long as everybody else is cc'ed.   Sure, and because you don't know you didn't bother to ask around and ignored the review request.  I already added them. Please look for the SECCOMP folks in MAINTAINERS.   I did not say at all that this might be diminishing security. And the argumentation with 'incompetent sysadmins' is just the wrong attitude.  What I was asking for is proper documentation and this proper documentation is meant for _competent_ sysadmins.  That documentation has to clearly describe what kind of information is accessible and what potential side effects security wise this might have. You cannot expect that even competent sysadmins know offhand what which PMU might expose. And telling them 'Use Google' is just not the right thing to do.  If you can't explain and document it, then providing the knob is just fulfilling somebodys 'I want a pony' request.   Sure, and this wants to be documented in the cover letter and the changelogs.  But this does also require a proper analysis and documentation why it is not a security risk to expose the i915 PMU or what potential security issues this can create, so that the competent sysadmin can make a judgement.  And the same is required for all other PMUs which can be enabled in the same way for unprivileged access. And we might as well come to the conclusion via analysis that for some PMUs unpriviledged access is just not a good idea and exclude them. I surely know a few which qualify for exclusion, so the right approach is to provide this knob only when the risk is analyzed and documented and the PMU has been flagged as candidate for unpriviledged exposure. I.e. opt in and not opt out. Sure, but you also used the word ""pile"" and I would argue that made the rest of your sentence, after and including ""instead"", sound like it not only bothers you I forgot to Cc people on the cover letter, but it also bothers you I included a ""pile"" of my own addresses. If that wasn't your intention in the slightest then I apologise for misreading it. No, not because of that. You are assuming my actions and motivations and constructing a story. ""did not bother"" = negative connotations, ""ignored"" = negative connotations. Note instead the time lapse between this and previous posting of the series, and if you want to assume something, assume things can get missed and forgotten without intent or malice. Thanks! 
Wrong attitude what? I was trying to guess your reasoning (cues in ""presumably"" and a lot of question marks) since it wasn't clear to me why is your position what it is. I did not mention Google. Well it's not a pony, it is mechanism to avoid having to turn off all security. We can hopefully discuss it without ponies. I am happy to work on the mechanics of achieving this once the security guys and all PMU owners get involved. Even though I am not convinced the bar to allow fine-grained control should be evaluating all possible PMUs*, but if the security folks agree that is the case it is fine by me.
The part of my reply you did not quote explains how the fine-grained control improves security in existing deployments. The documentation I added refers to the existing perf_event_paranoid documentation for explanation of security concerns involved. Which is not much in itself. But essentially we both have a PMU and a knob already. I don't see why adding the same knob per-PMU needs much more stringent criteria to be accepted. But as said, that's for security people to decide.",Tvrtko Ursulin,tvrtko.ursulin@linux.intel.com,1,0,3558,1.0,1.0,0.05263157894736842,0.532608695652174,0,0.6,0.4,0.0,0.0
131,402510,413778,uncivil,"Guessing my reasonings has nothing to do with you mentioning incompentent sysadmins. I did not say that you mentioned google. But what is a sysadmin supposed to do when there is no documentation aside of using google? And not having documentation is basically the same thing as telling them to use google. If you want to make a pettifogger contest out of this discussion, then we can stop right here. I explained it technically why just adding a knob without further explanation and analysis is not acceptable. Making the knob opt in per PMU does not need all PMU owners to be involved. It allows to add the opt in flag on a case by case basis. The fact, that the existing knob is poorly documented does make an excuse for adding more knobs without documentation. Quite the contrary, if we notice that the existing knob lacks proper documentation, then we should fix that first.",413776,technical,Which paranoia level would be used for the setting in such a case?  Perhaps also CC  on the next version.,"Which paranoia level would be used for the setting in such a case?  Perhaps also CC  on the next version. Guessing my reasonings has nothing to do with you mentioning incompentent sysadmins. I did not say that you mentioned google. But what is a sysadmin supposed to do when there is no documentation aside of using google? And not having documentation is basically the same thing as telling them to use google. If you want to make a pettifogger contest out of this discussion, then we can stop right here. I explained it technically why just adding a knob without further explanation and analysis is not acceptable. Making the knob opt in per PMU does not need all PMU owners to be involved. It allows to add the opt in flag on a case by case basis. The fact, that the existing knob is poorly documented does make an excuse for adding more knobs without documentation. Quite the contrary, if we notice that the existing knob lacks proper documentation, then we should fix that first.",Thomas Gleixner,tglx@linutronix.de,1,0,984,0.2705382436260623,1.0,0.1,0.7391304347826086,0,0.6,0.4,0.0,0.0
132,402510,414000,uncivil,"Ah only if google could simply answer all our questions! It's not like there is or isn't a security risk and that you can say that it is or it isn't in a global way.
Essentially these are channels of information. The channels always exist in form of timing variances for any shared resource (like shared caches or shared memory/IO/interconnect bandwidth) that can be measured. Perfmon counters make the channels generally less noisy, but they do not cause
them. To really close them completely you would need to avoid sharing anything, or not allowing to measure time, neither of which is practical short of an air gap. There are reasonable assesments you can make either way and the answers will be different based on your requirements. There isn't a single answer that works for everyone. 
There are cases where it isn't a problem at all. If you don't have multiple users on the system your tolerance should be extremely high. For users who have multiple users there can be different tradeoffs. So there isn't a single answer, and that is why it is important that this if configurable. ",413936,technical,"Just to make it clear. I'm not against separate settings at all. But I'm against adding knobs for every PMU the kernel supports wholesale without analysis and documentation just because we can and somebody wants it.  Right now we have a single knob, which is poorly documented and that should be fixed first. But some googling gives you the information that allowing unprivilegded access is a security risk. So the security focussed sysadmin will deny access to the PMUs no matter what.  Now we add more knobs without documentation what the exposure and risk of each PMU is. The proposed patch set does this wholesale for every PMU supported by the kernel. So the GPU user will ask the sysadmin to allow him access. How can he make an informed decision? If he grants it then the next user comes around and wants it for something else arguing that the other got it for the GPU already. How can he make an informed decision about that one?  We provide the knobs, so it's also our responsibility towards our users to give them the information about their usage and scope. And every single PMU knob has a different scope.  The documentation of the gazillion of knobs in /proc and /sysfs is not really brilliant, but we should really not continue this bad practice especially not when these knobs have potentially security relevant implcations. Yes, I know, writing documentation is work, but it's valuable and is appreciated by our users.  To make this doable and not blocked by requiring every PMU to be analyzed and documented at once, I suggested to make this opt-in. Do analysis for a given PMU, decide whether it should be exposed at all. If so, document it proper and flip the bit. That way this can be done gradually as the need arises and we can exclude the riskier ones completely.  I don't think this is an unreasonable request as it does not require the i915 folks to look at PMUs they are not familiar with and does not get blocked by waiting on every PMU wizard on the planet to have time.  Start with something like Documentation/admin-guide/perf-security.rst or whatever name fits better and add a proper documentation for the existing knob. With the infrastructure for fine grained access control add the general explanation for fine grained access control. With each PMU which opt's in for the knob, add a section with guidance about scope and risk for this particular one.","Just to make it clear. I'm not against separate settings at all. But I'm against adding knobs for every PMU the kernel supports wholesale without analysis and documentation just because we can and somebody wants it.  Right now we have a single knob, which is poorly documented and that should be fixed first. But some googling gives you the information that allowing unprivilegded access is a security risk. So the security focussed sysadmin will deny access to the PMUs no matter what.  Now we add more knobs without documentation what the exposure and risk of each PMU is. The proposed patch set does this wholesale for every PMU supported by the kernel. So the GPU user will ask the sysadmin to allow him access. How can he make an informed decision? If he grants it then the next user comes around and wants it for something else arguing that the other got it for the GPU already. How can he make an informed decision about that one?  We provide the knobs, so it's also our responsibility towards our users to give them the information about their usage and scope. And every single PMU knob has a different scope.  The documentation of the gazillion of knobs in /proc and /sysfs is not really brilliant, but we should really not continue this bad practice especially not when these knobs have potentially security relevant implcations. Yes, I know, writing documentation is work, but it's valuable and is appreciated by our users.  To make this doable and not blocked by requiring every PMU to be analyzed and documented at once, I suggested to make this opt-in. Do analysis for a given PMU, decide whether it should be exposed at all. If so, document it proper and flip the bit. That way this can be done gradually as the need arises and we can exclude the riskier ones completely.  I don't think this is an unreasonable request as it does not require the i915 folks to look at PMUs they are not familiar with and does not get blocked by waiting on every PMU wizard on the planet to have time.  Start with something like Documentation/admin-guide/perf-security.rst or whatever name fits better and add a proper documentation for the existing knob. With the infrastructure for fine grained access control add the general explanation for fine grained access control. With each PMU which opt's in for the knob, add a section with guidance about scope and risk for this particular one. Ah only if google could simply answer all our questions! It's not like there is or isn't a security risk and that you can say that it is or it isn't in a global way.
Essentially these are channels of information. The channels always exist in form of timing variances for any shared resource (like shared caches or shared memory/IO/interconnect bandwidth) that can be measured. Perfmon counters make the channels generally less noisy, but they do not cause
them. To really close them completely you would need to avoid sharing anything, or not allowing to measure time, neither of which is practical short of an air gap. There are reasonable assesments you can make either way and the answers will be different based on your requirements. There isn't a single answer that works for everyone. 
There are cases where it isn't a problem at all. If you don't have multiple users on the system your tolerance should be extremely high. For users who have multiple users there can be different tradeoffs. So there isn't a single answer, and that is why it is important that this if configurable. ",Andi Kleen,ak@linux.intel.com,0,0,3475,0.9447592067988668,1.0,0.08333333333333333,0.8478260869565217,0,0.6,0.3333333333333333,0.0,0.0
133,402510,414266,uncivil,"I said clearly that I'm not opposed against making it configurable. But because there is no single answer, it's even more important to have proper documentation. And that's all I'm asking for aside of making it opt-in instead of a wholesale expose everything approach.",414076,technical,"Ah, I guess the answer is 0, since you want to see data about what other users are doing.  Does the i915 PMU expose sampling events, counting events, or both? The thing about sampling events is that they AFAIK always let the user pick arbitrary data to collect - like register contents, or userspace stack memory -, and independent of the performance counter being monitored, this kind of access should not be permitted to other contexts. (But it might be that I misunderstand how perf works - I'm not super familiar with its API.)","Ah, I guess the answer is 0, since you want to see data about what other users are doing.  Does the i915 PMU expose sampling events, counting events, or both? The thing about sampling events is that they AFAIK always let the user pick arbitrary data to collect - like register contents, or userspace stack memory -, and independent of the performance counter being monitored, this kind of access should not be permitted to other contexts. (But it might be that I misunderstand how perf works - I'm not super familiar with its API.) I said clearly that I'm not opposed against making it configurable. But because there is no single answer, it's even more important to have proper documentation. And that's all I'm asking for aside of making it opt-in instead of a wholesale expose everything approach.",Thomas Gleixner,tglx@linutronix.de,1,0,800,0.22662889518413598,1.0,0.3333333333333333,0.9782608695652174,0,0.6,0.3333333333333333,0.0,0.0
134,410867,414489,uncivil,"Even though the return type of ndo_start_xmit is netdev_tx_t, negative error codes are
still allowed I believe. Look, reviewing these are pretty stressful for me, because you  aren't documenting your changes and in many cases the transformations look incorrect. I'm tossing the rest of your changes in this area for now, sorry. Please double check your work and resubmit this at some time in the not-too-near future. Thank you.",410867,technical,"The method is defined as returning this, which is a typedef for an enum type, so make sure the implementation in this driver has returns this value, and change the function return type to this  Found by coccinelle","The method is defined as returning this, which is a typedef for an enum type, so make sure the implementation in this driver has returns this value, and change the function return type to this  Found by coccinelle Even though the return type of ndo_start_xmit is netdev_tx_t, negative error codes are
still allowed I believe. Look, reviewing these are pretty stressful for me, because you  aren't documenting your changes and in many cases the transformations look incorrect. I'm tossing the rest of your changes in this area for now, sorry. Please double check your work and resubmit this at some time in the not-too-near future. Thank you.",David Miller,davem@davemloft.net,1,0,641,1.0,1.0,0.2,0.2,0,1.0,0.0,1.0,0.0
135,422694,423291,uncivil,"The way I see it, it is pretty well marked up as is. So, this paragraph is not describing the change. What is not ""proper"" about the existing comment? Yes yes, I *know* that GCC is not very intelligent about it and requires hand-holding, but blaming the existing comment for not *properly* marking an intentional fall through is ... rich. Adding some more context here. Considering the above added context, I have to say that this mindless change is not an improvement, as you have just destroyed the continued sentence from the previous comment. You must have noticed that this was the end of a continued sentence, as you even quoted it in the commit message. The big question is why you did not stop to think and consider the context?
Yes, I'm annoyed by mindless changes. Especially mindless changes aimed at improving readability while in fact making things less readable.
TL;DR, if you are desperate to fix ""the problem"" with this fall through comment, please do so in a way that preserves overall readability. And it would be nice to not blame the existing code for brain damage in GCC and various other static analyzers.",422694,technical,"In preparation to enabling -Wimplicit-fallthrough, mark switch cases where we are expecting to fall through.  Notice that in this particular case, I replaced ...and fall through."" with a proper ""fall through"", which is what GCC is expecting to find.  ","In preparation to enabling -Wimplicit-fallthrough, mark switch cases where we are expecting to fall through.  Notice that in this particular case, I replaced ...and fall through."" with a proper ""fall through"", which is what GCC is expecting to find.   The way I see it, it is pretty well marked up as is. So, this paragraph is not describing the change. What is not ""proper"" about the existing comment? Yes yes, I *know* that GCC is not very intelligent about it and requires hand-holding, but blaming the existing comment for not *properly* marking an intentional fall through is ... rich. Adding some more context here. Considering the above added context, I have to say that this mindless change is not an improvement, as you have just destroyed the continued sentence from the previous comment. You must have noticed that this was the end of a continued sentence, as you even quoted it in the commit message. The big question is why you did not stop to think and consider the context?
Yes, I'm annoyed by mindless changes. Especially mindless changes aimed at improving readability while in fact making things less readable.
TL;DR, if you are desperate to fix ""the problem"" with this fall through comment, please do so in a way that preserves overall readability. And it would be nice to not blame the existing code for brain damage in GCC and various other static analyzers.",Peter Rosin,peda@axentia.se,1,0,1379,1.0,1.0,0.07692307692307693,0.058823529411764705,0,0.0,1.0,0.0,0.0
136,422694,428645,uncivil,"I still object. It would have been so damn easy and it does not take a whole
lot of imagination to quiet down GCC while keeping the comments readable. Just
move the ""and"" to the previous comment, like this. Or add a sentence, like this (which is a bit more fun IMO).",428602,technical,"Thanks. Below are some examples of cases in which the fall-through warning turned out to be an actual bug:  So, yeah. This effort is worth it.","Thanks. Below are some examples of cases in which the fall-through warning turned out to be an actual bug:  So, yeah. This effort is worth it. I still object. It would have been so damn easy and it does not take a whole
lot of imagination to quiet down GCC while keeping the comments readable. Just
move the ""and"" to the previous comment, like this. Or add a sentence, like this (which is a bit more fun IMO).",Peter Rosin,peda@axentia.se,1,0,409,0.3345323741007194,1.0,0.25,0.8235294117647058,0,0.5,0.375,0.0,0.0
137,424089,424518,uncivil,"Which CPU architecture?  Most important architectures appear to define
__HAVE_ARCH_MEMCMP. What the heck does __visible do? This is going to do bad things if the incoming addresses aren't suitably aligned.
Certainly, byte-at-a-time is a pretty lame implementation when the addresses are suitably aligned.  A fallback to the lame version when there is misalignment will be simple to do.  And presumably there will be decent benefits to whoever is actually using this code.  But I'm wondering who is actually using this code!",424089,technical," During testing, I have configured 128 md/raid1's and, while under heavy IO, I started a check on each of them.The CPU utilization went through the ceiling and when looking for the cause (with 'perf top'). I've discovered that ~50% of the time was spend in memcmp() called from process_checks().  With this patch applied, it drops to 4% - 10%."," During testing, I have configured 128 md/raid1's and, while under heavy IO, I started a check on each of them.The CPU utilization went through the ceiling and when looking for the cause (with 'perf top'). I've discovered that ~50% of the time was spend in memcmp() called from process_checks().  With this patch applied, it drops to 4% - 10%. Which CPU architecture?  Most important architectures appear to define
__HAVE_ARCH_MEMCMP. What the heck does __visible do? This is going to do bad things if the incoming addresses aren't suitably aligned.
Certainly, byte-at-a-time is a pretty lame implementation when the addresses are suitably aligned.  A fallback to the lame version when there is misalignment will be simple to do.  And presumably there will be decent benefits to whoever is actually using this code.  But I'm wondering who is actually using this code!",Andrew Morton,akpm@linux-foundation.org,1,0,867,1.0,1.0,0.125,0.125,0,0.0,0.0,0.0,0.0
138,467091,471421,uncivil,"The major feature close to USB is this one and it can be found in others protocols (standardization process). Just to close this topic I3C vs USB, IMO it's wrong to pass the message that the I3C is closer to USB than I2C even more because I3C support the I2C on the fly. Sorry, with the proliferation of sensors I cannot see a multi master sensor network based on USB. Yes, we already talked about secondary master support. I would bet to do something like in i2c, we don't need the same level of complexity found in USB. I agree with the controller folder but not with prefix. Please check what is already in the kernel. In this case and taking what is already in the kernel it will be drivers/i3c/{master, slave, dwc, other with the same architecture as dwc}. I miss to mention PCI but since the beginning refer the slave and the common part. Splitting the driver is something that soon or later I will have to do. If you prefer later I'm ok with that. I think this discussion is starting to be counterproductive with arguing of both parts. Unfortunately I don't see anyone given their inputs too. To be clear, the subsystem is nice and I working with daily. As I said this is something that I dealing now and I'm telling what I think that is not correct.",470763,technical,"My point is, I don't get the relationship between your patch and secondary-master/slave-mode support.   I maintain that functionally, I3C is closer to USB than I2C. That does not mean that it's competing with USB performance-wise, it just means that the SW stack is likely to resemble the USB one (probably a bit simpler, at least at the beginning).    Look at the bus discovery mechanism, the notion of DCR (close to the concept of USB class), or the fact that each dev has a unique manufacturerPID pair (which resemble the product/vendor ID concept) that allows us to easily bind a dev to a driver without requiring a static description.   That's called USB OTG. Okay, to be fair, it's not exactly the same, and the mastership handover in I3C is probably more complex than what we have with USB OTG (I'm not a USB expert, so I might be wrong here).   Maybe.   So you have such a dual-role controller? I mean, Cadence IP has a dummy GPIO mode in its Master IP when is operating in slave mode (secondary master, or main master after it's released the bus), but I'm not sure this was designed for anything else but testing.  What I call a slave controller would be something that lets you reply to SDR/DDR transactions or fill a generic regmap that would be exposed to other masters on the bus. This way we could implement generic slave drivers in Linux (the same way we have gadget drivers). Anything else is likely to be to specific to be exposed as a generic framework.   Hm, not sure I like this idea either. So I see 2 options:  1/ put all controller drivers (both master and slave ones) in a common  directory as you suggest, and prefix them    correctly  2/ place them in separate directories I'm fine either way.   I think I understand your concerns now, but only because you started to mention a few things that were not clearly stated before (at least, I didn't understand it this way), like the fact that your controller (and probably others too) supports dual-role, or the fact that you plan to expose your IP through the PCI bus.","My point is, I don't get the relationship between your patch and secondary-master/slave-mode support.   I maintain that functionally, I3C is closer to USB than I2C. That does not mean that it's competing with USB performance-wise, it just means that the SW stack is likely to resemble the USB one (probably a bit simpler, at least at the beginning).    Look at the bus discovery mechanism, the notion of DCR (close to the concept of USB class), or the fact that each dev has a unique manufacturerPID pair (which resemble the product/vendor ID concept) that allows us to easily bind a dev to a driver without requiring a static description.   That's called USB OTG. Okay, to be fair, it's not exactly the same, and the mastership handover in I3C is probably more complex than what we have with USB OTG (I'm not a USB expert, so I might be wrong here).   Maybe.   So you have such a dual-role controller? I mean, Cadence IP has a dummy GPIO mode in its Master IP when is operating in slave mode (secondary master, or main master after it's released the bus), but I'm not sure this was designed for anything else but testing.  What I call a slave controller would be something that lets you reply to SDR/DDR transactions or fill a generic regmap that would be exposed to other masters on the bus. This way we could implement generic slave drivers in Linux (the same way we have gadget drivers). Anything else is likely to be to specific to be exposed as a generic framework.   Hm, not sure I like this idea either. So I see 2 options:  1/ put all controller drivers (both master and slave ones) in a common  directory as you suggest, and prefix them    correctly  2/ place them in separate directories I'm fine either way.   I think I understand your concerns now, but only because you started to mention a few things that were not clearly stated before (at least, I didn't understand it this way), like the fact that your controller (and probably others too) supports dual-role, or the fact that you plan to expose your IP through the PCI bus. The major feature close to USB is this one and it can be found in others protocols (standardization process). Just to close this topic I3C vs USB, IMO it's wrong to pass the message that the I3C is closer to USB than I2C even more because I3C support the I2C on the fly. Sorry, with the proliferation of sensors I cannot see a multi master sensor network based on USB. Yes, we already talked about secondary master support. I would bet to do something like in i2c, we don't need the same level of complexity found in USB. I agree with the controller folder but not with prefix. Please check what is already in the kernel. In this case and taking what is already in the kernel it will be drivers/i3c/{master, slave, dwc, other with the same architecture as dwc}. I miss to mention PCI but since the beginning refer the slave and the common part. Splitting the driver is something that soon or later I will have to do. If you prefer later I'm ok with that. I think this discussion is starting to be counterproductive with arguing of both parts. Unfortunately I don't see anyone given their inputs too. To be clear, the subsystem is nice and I working with daily. As I said this is something that I dealing now and I'm telling what I think that is not correct.",vitor,vitor.soares@synopsys.com,1,0,3299,0.869182389937107,1.0,0.06666666666666667,0.016666666666666666,0,0.36363636363636365,0.5454545454545454,0.0,0.0
139,467091,471458,uncivil,"I think you didn't read my reply carefully. I'm not saying I3C == USB, I'm just saying that the way you interact with an I3C from a SW PoV is not at all the same as you would do for an I2C device. Do you deny that? Looks like there's a misunderstanding here. The question is not whether I3C will replace I2C or USB, of course it's meant to overcome the limitations of I2C. I'm just pointing out that, if we have to expose I3C devices, we should look at what other discoverable buses do (PCI, USB, ...), not what I2C does. 
There's a difference between a secondary master that waits for its time to become the currrent master, and a secondary master that provides I3C device features when it's acting as a slave (sensor, GPIO controller, ...). So far we focused on supporting the former. If there's a need for the latter, then we should start thinking about the slave framework...
Can you detail a bit more what you have in mind? I don't think we can do like I2C, simply because we need to expose a valid DCR  manuf-ID/PID so that other masters can bind the device to the appropriate driver on their side. Plus, if we're about to expose generic profiles, we likely don't want each I3C slave controller driver to do that on its own.
If we mix everything in the same subdir, I'd like to have an easy way to quickly identify those that are slave controllers and those that are master controllers. For the dual-role thing, maybe we can consider them as master (ones with advances slave features).
Would you be okay with drivers/i3c/controllers/{designware,dw}/..., so that you can have all designware drivers (for both slave and master blocks) in the same dir? For those that are placed directly under drivers/i3c/controllers/... (because they only have one .c file), I'd like to keep a standard prefix. And again, I'm questioning the necessity of per-IP directories at the root level. I'm not against per-IP directories, as long as they are classified like other HW blocks. No it's not vain, it's how we do discuss things in the community. I'm not saying I'm always right, but I need to understand the problems you're trying to solve to take a decision, and I don't think you initially gave all the details I needed to understand your PoV. That's a bit clearer now, even if I still disagree on a few aspects. They will come. Come on! All I've seen so far are complaints on tiny details, it definitely doesn't prevent you from adding new features.",471421,uncivil,"he major feature close to USB is this one and it can be found in others  protocols (standardization process).  Just to close this topic I3C vs USB, IMO it's wrong to pass the message  that the I3C is closer to USB than I2C even more because I3C support the  I2C on the fly.     Sorry, with the proliferation of sensors I cannot see a multi master  sensor network based on USB. Yes, we already talked about secondary master support.     I would bet to do something like in i2c, we don't need the same level of  complexity found in USB.  I agree with the controller folder but not with prefix. Please check  what is already in the kernel. In this case and taking what is already in the kernel it will be  drivers/i3c/{master, slave, dwc, other with the same architecture as dwc}.     I miss to mention PCI but since the beginning refer the slave and the  common part.  Splitting the driver is something that soon or later I will have to do.  If you prefer later I'm ok with that.   I think this discussion is starting to be counterproductive with arguing  of both parts. Unfortunately I don't see anyone given their inputs too.  To be clear, the subsystem is nice and I working with daily. As I said  this is something that I dealing now and I'm telling what I think that  is not correct.","he major feature close to USB is this one and it can be found in others  protocols (standardization process).  Just to close this topic I3C vs USB, IMO it's wrong to pass the message  that the I3C is closer to USB than I2C even more because I3C support the  I2C on the fly.     Sorry, with the proliferation of sensors I cannot see a multi master  sensor network based on USB. Yes, we already talked about secondary master support.     I would bet to do something like in i2c, we don't need the same level of  complexity found in USB.  I agree with the controller folder but not with prefix. Please check  what is already in the kernel. In this case and taking what is already in the kernel it will be  drivers/i3c/{master, slave, dwc, other with the same architecture as dwc}.     I miss to mention PCI but since the beginning refer the slave and the  common part.  Splitting the driver is something that soon or later I will have to do.  If you prefer later I'm ok with that.   I think this discussion is starting to be counterproductive with arguing  of both parts. Unfortunately I don't see anyone given their inputs too.  To be clear, the subsystem is nice and I working with daily. As I said  this is something that I dealing now and I'm telling what I think that  is not correct. I think you didn't read my reply carefully. I'm not saying I3C == USB, I'm just saying that the way you interact with an I3C from a SW PoV is not at all the same as you would do for an I2C device. Do you deny that? Looks like there's a misunderstanding here. The question is not whether I3C will replace I2C or USB, of course it's meant to overcome the limitations of I2C. I'm just pointing out that, if we have to expose I3C devices, we should look at what other discoverable buses do (PCI, USB, ...), not what I2C does. 
There's a difference between a secondary master that waits for its time to become the currrent master, and a secondary master that provides I3C device features when it's acting as a slave (sensor, GPIO controller, ...). So far we focused on supporting the former. If there's a need for the latter, then we should start thinking about the slave framework...
Can you detail a bit more what you have in mind? I don't think we can do like I2C, simply because we need to expose a valid DCR  manuf-ID/PID so that other masters can bind the device to the appropriate driver on their side. Plus, if we're about to expose generic profiles, we likely don't want each I3C slave controller driver to do that on its own.
If we mix everything in the same subdir, I'd like to have an easy way to quickly identify those that are slave controllers and those that are master controllers. For the dual-role thing, maybe we can consider them as master (ones with advances slave features).
Would you be okay with drivers/i3c/controllers/{designware,dw}/..., so that you can have all designware drivers (for both slave and master blocks) in the same dir? For those that are placed directly under drivers/i3c/controllers/... (because they only have one .c file), I'd like to keep a standard prefix. And again, I'm questioning the necessity of per-IP directories at the root level. I'm not against per-IP directories, as long as they are classified like other HW blocks. No it's not vain, it's how we do discuss things in the community. I'm not saying I'm always right, but I need to understand the problems you're trying to solve to take a decision, and I don't think you initially gave all the details I needed to understand your PoV. That's a bit clearer now, even if I still disagree on a few aspects. They will come. Come on! All I've seen so far are complaints on tiny details, it definitely doesn't prevent you from adding new features.",Boris Brezillon,boris.brezillon@bootlin.com,1,0,3729,1.0,1.0,0.034482758620689655,0.26666666666666666,0,0.36363636363636365,0.5454545454545454,0.0,0.5454545454545454
140,467091,479249,uncivil,"If you want. Actually that's the most interesting part for me: discussing how we want to support I3C slave controllers or mixed master/slave controllers. All the driver split we're talking about here is just bikeshedding. Ok. I don't see why. If the driver is simple enough to fit in one file, there's no reason to create a new subdir. You think your DW IP is so complex and configurable that it requires several source files, fine, but please don't force others to do the same. Yes. You mean, inside a sub-folder? It depends what you do with those source files. If they are to be exposed directly as modules, then they should be prefixed. On the other hand, if you create a single module out of several source files, source files don't need to be prefixed, as long as the resulting module as a proper prefix.
I'm not saying the discussion is useless, just that it's happening way too early compared to the other things we should work on. If you were adding support for slaves, and were doing this split as part of this patch series explaining that part of the code between slave and master can be shared, then we wouldn't have this debate. But right now, you're telling me that we need to split the DW driver to prepare for features that have not even been discussed/proposed. That's what I'm complaining about.",478983,technical,"Sorry for the delayed response. I think this should be discuss in another thread. Do you agree? Yes, that was what I trying to tell you. For me this might be the best  option.  I would like to avoid having dual role i3c driver in a master folder. I don't disagree, and for those that have more than one file they should  be in a folder, right?  What prefix do you have in mind for those files inside a folder? No, it's not. But as you can see to slipt the driver in parts this  subject has some relevance.","Sorry for the delayed response. I think this should be discuss in another thread. Do you agree? Yes, that was what I trying to tell you. For me this might be the best  option.  I would like to avoid having dual role i3c driver in a master folder. I don't disagree, and for those that have more than one file they should  be in a folder, right?  What prefix do you have in mind for those files inside a folder? No, it's not. But as you can see to slipt the driver in parts this  subject has some relevance. If you want. Actually that's the most interesting part for me: discussing how we want to support I3C slave controllers or mixed master/slave controllers. All the driver split we're talking about here is just bikeshedding. Ok. I don't see why. If the driver is simple enough to fit in one file, there's no reason to create a new subdir. You think your DW IP is so complex and configurable that it requires several source files, fine, but please don't force others to do the same. Yes. You mean, inside a sub-folder? It depends what you do with those source files. If they are to be exposed directly as modules, then they should be prefixed. On the other hand, if you create a single module out of several source files, source files don't need to be prefixed, as long as the resulting module as a proper prefix.
I'm not saying the discussion is useless, just that it's happening way too early compared to the other things we should work on. If you were adding support for slaves, and were doing this split as part of this patch series explaining that part of the code between slave and master can be shared, then we wouldn't have this debate. But right now, you're telling me that we need to split the DW driver to prepare for features that have not even been discussed/proposed. That's what I'm complaining about.",Boris Brezillon,boris.brezillon@bootlin.com,1,0,1818,0.4918238993710692,1.0,0.0625,0.75,1,1.0,0.0,0.0,0.0
141,476403,477115,uncivil,So I strongly disagree with this. Anybody that has trouble with 0/1 vs false/true needs to stay the heck away from C. I would suggest we delete that stupid coccinelle scripts that generates these pointless warns.,476592,technical,Adding the current maintainers on CC.  ,Adding the current maintainers on CC.   So I strongly disagree with this. Anybody that has trouble with 0/1 vs false/true needs to stay the heck away from C. I would suggest we delete that stupid coccinelle scripts that generates these pointless warns.,Peter Zijlstra,peterz@infradead.org,1,0,252,0.3082191780821918,1.0,0.3333333333333333,0.07142857142857142,0,1.0,0.0,0.5,0.0
142,476403,477136,uncivil,Not to mention that WARN is gramatically incorrect. We're not assigning 'bool' to 0/1 but the other way around. What crap..,477115,uncivil,So I strongly disagree with this. Anybody that has trouble with 0/1 vs false/true needs to stay the heck away from C.  I would suggest we delete that stupid coccinelle scripts that generates these pointless warns.,So I strongly disagree with this. Anybody that has trouble with 0/1 vs false/true needs to stay the heck away from C.  I would suggest we delete that stupid coccinelle scripts that generates these pointless warns. Not to mention that WARN is gramatically incorrect. We're not assigning 'bool' to 0/1 but the other way around. What crap..,Peter Zijlstra,peterz@infradead.org,1,0,337,0.4383561643835616,1.0,0.3333333333333333,0.2857142857142857,0,1.0,0.0,0.0,0.0
143,476403,478120,uncivil,"Then those tools are broken per the C spec. The C language spec, specifies _Bool as an integer type wide enough to at least store 0 and 1. IOW, 0 and 1 are perfectly valid valus to assign to a _Bool. And fundamentally that has to be so. That's how computers work. 0 is false, 1 is true. The kernel is not the place to try and abstract such stuff, C is our portable assembler. We muck with hardware, we'd better know how the heck it works.",477173,technical,"Personally, I would prefer that assignments involving boolean variables use true or false.  It seems more readable.  Potentially better for tools as well.  But if the community really prefers 0 and 1, then the test can be deleted.","Personally, I would prefer that assignments involving boolean variables use true or false.  It seems more readable.  Potentially better for tools as well.  But if the community really prefers 0 and 1, then the test can be deleted. Then those tools are broken per the C spec. The C language spec, specifies _Bool as an integer type wide enough to at least store 0 and 1. IOW, 0 and 1 are perfectly valid valus to assign to a _Bool. And fundamentally that has to be so. That's how computers work. 0 is false, 1 is true. The kernel is not the place to try and abstract such stuff, C is our portable assembler. We muck with hardware, we'd better know how the heck it works.",Peter Zijlstra,peterz@infradead.org,1,0,669,1.0,1.0,0.125,0.5,0,1.0,0.0,0.0,0.0
144,498594,573986,uncivil,What's advertisement there? Huch? Care to tell what's a lie instead of making bold statements?,573878,technical,"Ping? Jonathan, can you pick this up?  ","Ping? Jonathan, can you pick this up?   What's advertisement there? Huch? Care to tell what's a lie instead of making bold statements?",Thomas Gleixner,tglx@linutronix.de,1,1,134,0.04457652303120357,1.0,0.3333333333333333,0.0375,0,0.32270916334661354,0.6772908366533864,0.0,0.0
145,498594,573990,uncivil,"""No problem here, no performance issues, nothing to be seen unless you
are running VM."" Take a care to look at the patch I submitted? Lie: A system with an up to date kernel is protected against attacks from malicious user space applications. 3GB system running 32bit kernel is not protected. Same is true for really big 64bit systems. If I do what dmesg suggests, this becomes untrue: The Linux kernel contains a mitigation for this attack vector, PTE inversion, which is permanently enabled and has no performance impact. Limiting memory to 2GB _is_ going to have severe perfomance impact.",573986,uncivil,What's advertisement there?   Huch? Care to tell what's a lie instead of making bold statements?,"What's advertisement there?   Huch? Care to tell what's a lie instead of making bold statements? ""No problem here, no performance issues, nothing to be seen unless you
are running VM."" Take a care to look at the patch I submitted? Lie: A system with an up to date kernel is protected against attacks from malicious user space applications. 3GB system running 32bit kernel is not protected. Same is true for really big 64bit systems. If I do what dmesg suggests, this becomes untrue: The Linux kernel contains a mitigation for this attack vector, PTE inversion, which is permanently enabled and has no performance impact. Limiting memory to 2GB _is_ going to have severe perfomance impact.",Pavel Machek,pavel@ucw.cz,1,0,688,0.20208023774145617,1.0,0.09090909090909091,0.075,0,0.32270916334661354,0.6772908366533864,0.0,0.0
147,498594,574882,uncivil,"I agree that this statement is incorrect.

Calling this a lie is a completly unjustified personal attack on those who
spent quite a lot of time on writing up documentation in the first
place. It's suggesting that this document was written with malicious intent
and the purpose of deceiving someone. Care to explain why you are assuming
this to be the case?


Sure. That still does not justify the ""changelog"" you provided.


It's interesting that quite some people were actually happy about that
document. Sorry, that we weren't able to live up to your high standards.


What is the advertisement part again?


It's a document targeted at system administrators and it definitely should
not be burried somewhere in Documentation/x86. As there are more documents
being worked on for the other issues, I have a patch ready which moves that
stuff into a separate hardware vulnerabilites folder in the admin-guide.

FWIW, to the best of my knowledge the documentation about writing
changelogs is neither incorrect nor is it optional to adhere to it.


The 'Affected processors' section right below this is very clear about this being an Intel only issue (for now). So what exactly is the point of this change?
On x86-32? That's incorrect, because there are a lot of x86-32 systems which are not affected. Also it has nothing to do with the bit-width of the hardware. A 32bit kernel booted on a 64bit capable CPU has the same issue. For further correctness, this needs to mention that !PAE enabled kernels cannot do PTE inversion at all. The 2G limitation is not a general limitation. The limitation depends on the number of physical address bits supported by the cache (not the number of physical addresss bits exposed as pins) and is definitely not hardcoded to 2G. Just because your machine emits the 2G number does not make it universally correct. On a system with 36bit physical address space the limit is 32G and on some CPUs that's actually wrong as well, see: override_cache_bits. Quoting yourself, Where is the explanation for the 'really big 64bit systems' issue for correctness sake?",574206,civil,"I would really like to get an ack from the people who have been deep into this first.  If you can get that, and preferably resubmit with a less condescending changelog, I can pick it up.","I would really like to get an ack from the people who have been deep into this first.  If you can get that, and preferably resubmit with a less condescending changelog, I can pick it up. I agree that this statement is incorrect.

Calling this a lie is a completly unjustified personal attack on those who
spent quite a lot of time on writing up documentation in the first
place. It's suggesting that this document was written with malicious intent
and the purpose of deceiving someone. Care to explain why you are assuming
this to be the case?


Sure. That still does not justify the ""changelog"" you provided.


It's interesting that quite some people were actually happy about that
document. Sorry, that we weren't able to live up to your high standards.


What is the advertisement part again?


It's a document targeted at system administrators and it definitely should
not be burried somewhere in Documentation/x86. As there are more documents
being worked on for the other issues, I have a patch ready which moves that
stuff into a separate hardware vulnerabilites folder in the admin-guide.

FWIW, to the best of my knowledge the documentation about writing
changelogs is neither incorrect nor is it optional to adhere to it.


The 'Affected processors' section right below this is very clear about this being an Intel only issue (for now). So what exactly is the point of this change?
On x86-32? That's incorrect, because there are a lot of x86-32 systems which are not affected. Also it has nothing to do with the bit-width of the hardware. A 32bit kernel booted on a 64bit capable CPU has the same issue. For further correctness, this needs to mention that !PAE enabled kernels cannot do PTE inversion at all. The 2G limitation is not a general limitation. The limitation depends on the number of physical address bits supported by the cache (not the number of physical addresss bits exposed as pins) and is definitely not hardcoded to 2G. Just because your machine emits the 2G number does not make it universally correct. On a system with 36bit physical address space the limit is 32G and on some CPUs that's actually wrong as well, see: override_cache_bits. Quoting yourself, Where is the explanation for the 'really big 64bit systems' issue for correctness sake?",Thomas Gleixner,tglx@linutronix.de,1,1,2275,0.6508172362555721,1.0,0.04,0.2125,0,0.32270916334661354,0.6733067729083665,0.0,0.0
148,498594,576302,uncivil,"So how should it be called? I initally used less strong words, only to get ""Care to tell what's a lie instead of making bold statements?"" back. Also look at the timing of the thread. Ok, now can we have that document updated to meet the standards? Making it very clear from the begining this is x86-only issue. Yes, you can kind-of figure it out from the next section... except for Intel StrongArm. Next sentence speaks about ""present bit"" of ""page table entry"". That may be confusing for people familiar with other architectures, which may not have such bit. We should mention this is x86 before using x86-specific terminology. Ok. I don't know the detailed limits for each system; what about this?",574882,uncivil,"I agree that this statement is incorrect.  Calling this a lie is a completly unjustified personal attack on those who spent quite a lot of time on writing up documentation in the first place. It's suggesting that this document was written with malicious intent and the purpose of deceiving someone. Care to explain why you are assuming this to be the case? Sure. That still does not justify the changelog"" you provided.   It's interesting that quite some people were actually happy about that document. Sorry, that we weren't able to live up to your high standards.   What is the advertisement part again?   It's a document targeted at system administrators and it definitely should not be burried somewhere in Documentation/x86. As there are more documents being worked on for the other issues, I have a patch ready which moves that stuff into a separate hardware vulnerabilites folder in the admin-guide.  FWIW, to the best of my knowledge the documentation about writing changelogs is neither incorrect nor is it optional to adhere to it.   The 'Affected processors' section right below this is very clear about this being an Intel only issue (for now). So what exactly is the point of this change?   On x86-32? That's incorrect, because there are a lot of x86-32 systems which are not affected. Also it has nothing to do with the bit-width of the hardware. A 32bit kernel booted on a 64bit capable CPU has the same issue. For further correctness, this needs to mention that !PAE enabled kernels cannot do PTE inversion at all.   The 2G limitation is not a general limitation. The limitation depends on the number of physical address bits supported by the cache (not the number of physical addresss bits exposed as pins) and is definitely not hardcoded to 2G. Just because your machine emits the 2G number does not make it universally correct. On a system with 36bit physical address space the limit is 32G and on some CPUs that's actually wrong as well, see: override_cache_bits().  Quoting yourself:   Where is the explanation for the 'really big 64bit systems' issue for correctness sake?""","I agree that this statement is incorrect.  Calling this a lie is a completly unjustified personal attack on those who spent quite a lot of time on writing up documentation in the first place. It's suggesting that this document was written with malicious intent and the purpose of deceiving someone. Care to explain why you are assuming this to be the case? Sure. That still does not justify the changelog"" you provided.   It's interesting that quite some people were actually happy about that document. Sorry, that we weren't able to live up to your high standards.   What is the advertisement part again?   It's a document targeted at system administrators and it definitely should not be burried somewhere in Documentation/x86. As there are more documents being worked on for the other issues, I have a patch ready which moves that stuff into a separate hardware vulnerabilites folder in the admin-guide.  FWIW, to the best of my knowledge the documentation about writing changelogs is neither incorrect nor is it optional to adhere to it.   The 'Affected processors' section right below this is very clear about this being an Intel only issue (for now). So what exactly is the point of this change?   On x86-32? That's incorrect, because there are a lot of x86-32 systems which are not affected. Also it has nothing to do with the bit-width of the hardware. A 32bit kernel booted on a 64bit capable CPU has the same issue. For further correctness, this needs to mention that !PAE enabled kernels cannot do PTE inversion at all.   The 2G limitation is not a general limitation. The limitation depends on the number of physical address bits supported by the cache (not the number of physical addresss bits exposed as pins) and is definitely not hardcoded to 2G. Just because your machine emits the 2G number does not make it universally correct. On a system with 36bit physical address space the limit is 32G and on some CPUs that's actually wrong as well, see: override_cache_bits().  Quoting yourself:   Where is the explanation for the 'really big 64bit systems' issue for correctness sake?"" So how should it be called? I initally used less strong words, only to get ""Care to tell what's a lie instead of making bold statements?"" back. Also look at the timing of the thread. Ok, now can we have that document updated to meet the standards? Making it very clear from the begining this is x86-only issue. Yes, you can kind-of figure it out from the next section... except for Intel StrongArm. Next sentence speaks about ""present bit"" of ""page table entry"". That may be confusing for people familiar with other architectures, which may not have such bit. We should mention this is x86 before using x86-specific terminology. Ok. I don't know the detailed limits for each system; what about this?",Pavel Machek,pavel@ucw.cz,1,0,2795,0.8142644873699851,1.0,0.07692307692307693,0.525,0,0.32669322709163345,0.6733067729083665,0.0,0.04780876494023904
149,498594,590551,uncivil,"You called it a lie from the very beginning or what do you think made me
tell you that? Here is what you said. Nice try. What is 'the standards'? Your's or is there a general agreement? It's pretty clear, but yes admittedly we forgot to mention that Intel StrongARM is not affected. That's truly important because its widely deployed in the cloud space and elsewhere. X86 terminology? Care to check how pte_present() is implemented across the architectures? Most of them use the PRESENT bit naming convention, just a few use VALID. That's truly confusing and truly x86 specific. It's not about detailed limits for particular systems. It's about the way the limit is determined on certain class of systems. And that can be deduced from the code. If you want to provide more accurate documentation then you better come up with something which is helpful instead of completely useless blurb like the below. How is the admin going to figure that out? What kind of systems might be affected by this? No. The mitigation is available when the kernel provides it. Numbers are irrelevant because that documentation has to be applicable for stable kernels as well. And what is a recent -stable kernel? Also the PAE part needs to go to a completely different section.",576302,uncivil,"So how should it be called? I initally used less strong words, only to get Care to tell what's a lie instead of making bold statements?"" back. Also look at the timing of the thread.   Ok, now can we have that document updated to meet the standards?   Making it very clear from the begining this is x86-only issue. Yes, you can kind-of figure it out from the next section... except for Intel StrongArm.  Next sentence speaks about ""present bit"" of ""page table entry"". That may be confusing for people familiar with other architectures, which may not have such bit. We should mention this is x86 before using x86-specific terminology.   Ok.   I don't know the detailed limits for each system, what about this?  Terminal Fault  1 Terminal Fault is a hardware vulnerability which allows unprivileged -speculative access to data which is available in the Level 1 Data Cache -when the page table entry controlling the virtual address, which is used -for the access, has the Present bit cleared or other reserved bits set. L1 Terminal Fault is a hardware vulnerability on most recent Intel x86 CPUs which allows unprivileged speculative access to data which is available in the Level 1 Data Cache when the page table entry controlling the virtual address, which is used for the access, has the Present bit cleared or other reserved bits set.    Affected processors  Attack scenarios     deterministic and more practical.       The Linux kernel contains a mitigation for this attack vector, PTE -   inversion, which is permanently enabled and has no performance -   impact. The kernel ensures that the address bits of PTEs, which are not -   marked present, never point to cacheable physical memory space. - -   A system with an up to date kernel is protected against attacks from -   malicious user space applications.    inversion, which has no measurable performance impact in most    configurations. The kernel ensures that the address bits of PTEs,    which are not marked present, never point to cacheable physical    memory space. For mitigation to be effective, physical memory needs    to be limited in some configurations.     Mitigation is present in kernels v4.19 and newer, and in    recent -stable kernels. PAE needs to be enabled for mitigation to    work.    2. Malicious guest in a virtual machine  ]","So how should it be called? I initally used less strong words, only to get Care to tell what's a lie instead of making bold statements?"" back. Also look at the timing of the thread.   Ok, now can we have that document updated to meet the standards?   Making it very clear from the begining this is x86-only issue. Yes, you can kind-of figure it out from the next section... except for Intel StrongArm.  Next sentence speaks about ""present bit"" of ""page table entry"". That may be confusing for people familiar with other architectures, which may not have such bit. We should mention this is x86 before using x86-specific terminology.   Ok.   I don't know the detailed limits for each system, what about this?  Terminal Fault  1 Terminal Fault is a hardware vulnerability which allows unprivileged -speculative access to data which is available in the Level 1 Data Cache -when the page table entry controlling the virtual address, which is used -for the access, has the Present bit cleared or other reserved bits set. L1 Terminal Fault is a hardware vulnerability on most recent Intel x86 CPUs which allows unprivileged speculative access to data which is available in the Level 1 Data Cache when the page table entry controlling the virtual address, which is used for the access, has the Present bit cleared or other reserved bits set.    Affected processors  Attack scenarios     deterministic and more practical.       The Linux kernel contains a mitigation for this attack vector, PTE -   inversion, which is permanently enabled and has no performance -   impact. The kernel ensures that the address bits of PTEs, which are not -   marked present, never point to cacheable physical memory space. - -   A system with an up to date kernel is protected against attacks from -   malicious user space applications.    inversion, which has no measurable performance impact in most    configurations. The kernel ensures that the address bits of PTEs,    which are not marked present, never point to cacheable physical    memory space. For mitigation to be effective, physical memory needs    to be limited in some configurations.     Mitigation is present in kernels v4.19 and newer, and in    recent -stable kernels. PAE needs to be enabled for mitigation to    work.    2. Malicious guest in a virtual machine  ] You called it a lie from the very beginning or what do you think made me
tell you that? Here is what you said. Nice try. What is 'the standards'? Your's or is there a general agreement? It's pretty clear, but yes admittedly we forgot to mention that Intel StrongARM is not affected. That's truly important because its widely deployed in the cloud space and elsewhere. X86 terminology? Care to check how pte_present() is implemented across the architectures? Most of them use the PRESENT bit naming convention, just a few use VALID. That's truly confusing and truly x86 specific. It's not about detailed limits for particular systems. It's about the way the limit is determined on certain class of systems. And that can be deduced from the code. If you want to provide more accurate documentation then you better come up with something which is helpful instead of completely useless blurb like the below. How is the admin going to figure that out? What kind of systems might be affected by this? No. The mitigation is available when the kernel provides it. Numbers are irrelevant because that documentation has to be applicable for stable kernels as well. And what is a recent -stable kernel? Also the PAE part needs to go to a completely different section.",Thomas Gleixner,tglx@linutronix.de,1,1,3566,1.0,1.0,0.05,0.6875,0,0.3745019920318725,0.6254980079681275,0.04780876494023904,0.6254980079681275
150,498594,770007,uncivil,"Hi! Actually, I still call it a lie. Document clearly says that bug is fixed in non-virtualized cases, when in fact it depends on PAE and limited memory. At this point I want you to fix it yourself. Lying about security bugs being fixed when they are not is not cool. I tried to be helpful and submit a patch, but I don't feel like you are cooperating on getting the patch applied.",590551,uncivil,"You called it a lie from the very beginning or what do you think made me tell you that? Here is what you said:   Nice try.   What is 'the standards'? Your's or is there a general agreement?   It's pretty clear, but yes admittedly we forgot to mention that Intel StrongARM is not affected. That's truly important because its widely deployed in the cloud space and elsewhere.   X86 terminology? Care to check how pte_present() is implemented across the architectures? Most of them use the PRESENT bit naming convention, just a few use VALID. That's truly confusing and truly x86 specific.   It's not about detailed limits for particular systems. It's about the way the limit is determined on certain class of systems. And that can be deduced from the code.  If you want to provide more accurate documentation then you better come up with something which is helpful instead of completely useless blurb like the below:   How is the admin going to figure that out? What kind of systems might be affected by this?   No. The mitigation is available when the kernel provides it. Numbers are irrelevant because that documentation has to be applicable for stable kernels as well. And what is a recent -stable kernel?  Also the PAE part needs to go to a completely different section.","You called it a lie from the very beginning or what do you think made me tell you that? Here is what you said:   Nice try.   What is 'the standards'? Your's or is there a general agreement?   It's pretty clear, but yes admittedly we forgot to mention that Intel StrongARM is not affected. That's truly important because its widely deployed in the cloud space and elsewhere.   X86 terminology? Care to check how pte_present() is implemented across the architectures? Most of them use the PRESENT bit naming convention, just a few use VALID. That's truly confusing and truly x86 specific.   It's not about detailed limits for particular systems. It's about the way the limit is determined on certain class of systems. And that can be deduced from the code.  If you want to provide more accurate documentation then you better come up with something which is helpful instead of completely useless blurb like the below:   How is the admin going to figure that out? What kind of systems might be affected by this?   No. The mitigation is available when the kernel provides it. Numbers are irrelevant because that documentation has to be applicable for stable kernels as well. And what is a recent -stable kernel?  Also the PAE part needs to go to a completely different section. Hi! Actually, I still call it a lie. Document clearly says that bug is fixed in non-virtualized cases, when in fact it depends on PAE and limited memory. At this point I want you to fix it yourself. Lying about security bugs being fixed when they are not is not cool. I tried to be helpful and submit a patch, but I don't feel like you are cooperating on getting the patch applied.",Pavel Machek,pavel@denx.de,1,0,1654,0.4933135215453195,1.0,0.16666666666666666,0.9375,1,1.0,0.0,0.6254980079681275,0.0
151,511533,512783,uncivil,"Again, no.",511533,technical,Remove unusual_cypress.h which is included more than once. ,"Remove unusual_cypress.h which is included more than once.  Again, no.",Greg KH,gregkh@linuxfoundation.org,1,0,70,1.0,1.0,1.0,1.0,1,1.0,0.0,1.0,0.0
153,522705,522783,uncivil,"I would drop this patch for being too ugly and if nothing else, for lack of users (epoll will no longer need dlock).",522702,technical,"To enable the use of dlock-list in an interrupt handler, a new irqsafe mode can now be specified at dlock-list allocation time as an additional argument to alloc_dlock_list_heads(). With that mode specified, the spin_lock_irqsave/spin_unlock_irqrestore pair will be used instead of the regular lock and unlock calls. There is a slight chance that the list may become empty just  	 * before the lock is acquired. So an additional check is --","To enable the use of dlock-list in an interrupt handler, a new irqsafe mode can now be specified at dlock-list allocation time as an additional argument to alloc_dlock_list_heads(). With that mode specified, the spin_lock_irqsave/spin_unlock_irqrestore pair will be used instead of the regular lock and unlock calls. There is a slight chance that the list may become empty just  	 * before the lock is acquired. So an additional check is -- I would drop this patch for being too ugly and if nothing else, for lack of users (epoll will no longer need dlock).",Davidlohr Bueso,dave@stgolabs.net,1,0,557,1.0,1.0,1.0,1.0,0,0.0,1.0,0.0,0.0
155,539613,546377,uncivil,"Since when is the cover letter mandatory? I understand that is helps for a complicated patch set to explain the problem and solution in the cover letter, but for this simple test case addition what's the point? And there is nothing forcing a cover letter in the documentation. Also double tags seams to be quite common for selftest. See git logtools.",546296,civil,You are missing a cover letter from this patch set. Please have it in v2. Also use tag instead of having two tags in the short summaries. Now they look a bit weird.  ,"You are missing a cover letter from this patch set. Please have it in v2. Also use tag instead of having two tags in the short summaries. Now they look a bit weird.   Since when is the cover letter mandatory? I understand that is helps for a complicated patch set to explain the problem and solution in the cover letter, but for this simple test case addition what's the point? And there is nothing forcing a cover letter in the documentation. Also double tags seams to be quite common for selftest. See git logtools.",Tadeusz Struk,tadeusz.struk@intel.com,0,1,517,1.0,1.0,0.2,0.5555555555555556,0,0.7142857142857143,0.14285714285714285,0.0,0.14285714285714285
156,541450,541515,uncivil,"I'm not sure that forcing a library on users is a good reason to break UAPI. The patch is going into the latest, but can also be backported on future stables. I don't think ""not fixing it because it's not fixed yet"" is a good reason to keep things the way they are. But maybe that's just me. Given that the structure has already been extended several times, there is pretty much nothing to keep this from happening again and again.",541509,technical,"This should be safe to copy an arbitrary amount, the only restriction is that optlen can't exceed the size of the buffer receiving the data in the kernel.  From that standpoint your patch is safe.  However,  that exposes the problem of checking any tail data on the userspace buffer.  That is to say, if you want to ensure that any extra data that gets sent from userspace isn't 'set', you would have to copy that extra data in consumable chunks and check them individaully, and that screams DOS to me (i.e. imagine a user passing in a 4GB buffer, and having to wait for the kernel to copy each X sized chunk, looking for non-zero values).","This should be safe to copy an arbitrary amount, the only restriction is that optlen can't exceed the size of the buffer receiving the data in the kernel.  From that standpoint your patch is safe.  However,  that exposes the problem of checking any tail data on the userspace buffer.  That is to say, if you want to ensure that any extra data that gets sent from userspace isn't 'set', you would have to copy that extra data in consumable chunks and check them individaully, and that screams DOS to me (i.e. imagine a user passing in a 4GB buffer, and having to wait for the kernel to copy each X sized chunk, looking for non-zero values). I'm not sure that forcing a library on users is a good reason to break UAPI. The patch is going into the latest, but can also be backported on future stables. I don't think ""not fixing it because it's not fixed yet"" is a good reason to keep things the way they are. But maybe that's just me. Given that the structure has already been extended several times, there is pretty much nothing to keep this from happening again and again.",Julien Gomes,julien@arista.com,0,1,1071,0.24434876210979548,1.0,0.2,0.0196078431372549,0,0.0,1.0,0.0,0.0
157,541450,541516,uncivil,"There probably is a decent compromise to find between ""not accepting a single additional byte"" and accepting several GB. For example how likely is it that the growth of this structure make it go over a page? I would hope not at all. By choosing a large but decent high limit, I think we can find a future-compatible compromise that doesn't rely on a preliminary getsockopt() just for structure trucation decision...",541515,uncivil,"I'm not sure that forcing a library on users is a good reason to break UAPI.   The patch is going into the latest, but can also be backported on future stables. I don't think not fixing it because it's not fixed yet"" is a good reason to keep things the way they are. But maybe that's just me. Given that the structure has already been extended several times, there is pretty much nothing to keep this from happening again and again.   --""","I'm not sure that forcing a library on users is a good reason to break UAPI.   The patch is going into the latest, but can also be backported on future stables. I don't think not fixing it because it's not fixed yet"" is a good reason to keep things the way they are. But maybe that's just me. Given that the structure has already been extended several times, there is pretty much nothing to keep this from happening again and again.   --"" There probably is a decent compromise to find between ""not accepting a single additional byte"" and accepting several GB. For example how likely is it that the growth of this structure make it go over a page? I would hope not at all. By choosing a large but decent high limit, I think we can find a future-compatible compromise that doesn't rely on a preliminary getsockopt() just for structure trucation decision...",Julien Gomes,julien@arista.com,0,1,854,0.18945102260495156,1.0,0.25,0.43137254901960786,0,0.0,1.0,0.0,0.0
158,541450,542126,uncivil,"Thats a misleading statement.  We've never supported running newer applications on older kernels, and no one is forcing anyone to use the lksctp-tools library, I was only suggesting that, if we were to support this compatibility, that might be a place to offer it. Its also worth noting that we have precident for this.  If you look at the git log, this particular structure has been extended about 6 times in the life of sctp.
Also misleading, as it assumes that we're not intentionally doing this.  I get wanting to support running applications built for newer kernels on older kernels, but thats just not something that we do, and to say thats broken is misleading.  Older applications are required to run on newer kernels, but not vice versa, which is what you are asking for. 
And yes, this patch can be backported to older stable kernels, but by that same token, so can the patches that extend the struct, which would also fix the problem, while supporting the newer features, which seems to me to be the better solution for applications which are looking for that support.",541519,technical,"And I was just reminded about huge pages. But still, my point of finding a compromise still stands.","And I was just reminded about huge pages. But still, my point of finding a compromise still stands. Thats a misleading statement.  We've never supported running newer applications on older kernels, and no one is forcing anyone to use the lksctp-tools library, I was only suggesting that, if we were to support this compatibility, that might be a place to offer it. Its also worth noting that we have precident for this.  If you look at the git log, this particular structure has been extended about 6 times in the life of sctp.
Also misleading, as it assumes that we're not intentionally doing this.  I get wanting to support running applications built for newer kernels on older kernels, but thats just not something that we do, and to say thats broken is misleading.  Older applications are required to run on newer kernels, but not vice versa, which is what you are asking for. 
And yes, this patch can be backported to older stable kernels, but by that same token, so can the patches that extend the struct, which would also fix the problem, while supporting the newer features, which seems to me to be the better solution for applications which are looking for that support.",Neil Horman,nhorman@tuxdriver.com,1,0,1179,0.2518837459634015,1.0,0.125,0.11764705882352941,0,0.0,1.0,0.0,0.0
159,541450,543076,uncivil,"I disagree with this, at least as a unilateral statement.  I would assert that an old program, within the constraints of the issue being discussed here, will run perfectly well, when built and run against a new kernel.
At issue is the size of the structure sctp_event_subscribe, and the fact that in several instances over the last few years, its been extended to be larger and encompass more events to subscribe to. Nominally an application will use this structure (roughly) as follows. Assume this code will be built and run against kernel versions A and B, in which:
A) has a struct with a size of 9 bytes
B) has a struct with a size of 10 bytes (due to the added
field)
That gives us 4 cases to handle
1) Application build against kernel A and run on kernel A.  This works fine, the sizes of the struct in question will always match
2) Application is built against kernel A and run on kernel B.  In this case, everything will work because the application passes a buffer of size 9, and the kernel accepts it, because it allows for buffers to be shorter than the current struct sctp_event_subscribe size. The kernel simply operates on the options available in the buffer.  The application is none the wiser, because it has no knoweldge of the new option, nor should it because it was built against kernel A, that never offered that option
3) Application is built against kernel B and run on kernel B.  This works fine for the same reason as (1).
4) Application is built against kernel B and run on kernel A.  This will break because the application is passing a buffer that is larger than what the kernel expects, and rightly so.   The application is passing in a buffer that is incompatible with what the running kernel expects.

We could look into ways in which to detect the cases in which this might be 'ok', but I don't see why we should bother, because at some point its still an error to pass in an incompatible buffer.  In my mind this is no different than trying to run a program that allocates hugepages on a kernel that doesn't support hugepages (just to make up an example).  Applications built against newer kernel can't expect all the features/semantics/etc to be identical to older kernels.

It shouldn't.  Assuming you have a program built against headers from kernel B (above), if you set a field in the structure that only exists in kernel B, and try to run it on kernel A, you will get an EINVAL return, which is correct behavior because you are attempting to deliver information to the kernel that kernel A (the running kernel) doesn't know about.  Thats correct behavior. I won't disagree about the niceness of versioning, but that ship has sailed.To be clear,  this is situation (1) above, and yeah, running on the kernel you built your application against should always work from a compatibility standpoint. Yes, but this is alawys the case for structures that change.  If you have an application built against kernel (B), and uses structure fields that only exist in that version of the kernel (and not earlier) will fail to compile when built against kernel (A) headers, and thats expected.  This happens with any kernel api that exists in a newer kernel but not an older kernel. Any time you make a system call to the kernel, you have to be prepared to handle the resulting error condition, thats not unexpected.  To assume that a system call will always work is bad programming practice.",542900,technical,More confusing than I intended...  With the current kernel and headers a 'new program' (one that needs the new options) will fail to run on an old kernel - which is good. However a recompilation of an 'old program' (that doesn't use the new options) will also fail to run on an old kernel - which is bad.  Changing the kernel to ignore extra events flags breaks the 'new' program.  Versioning the structure now (even though it should have been done earlier) won't change the behaviour of existing binaries.  However a recompilation of an 'old' program would use the 'old' structure and work on old kernels. Attempts to recompile a 'new' program will fail - until the structure name (or some #define to enable the extra fields) is changed.  Breaking compilations is much better than unexpected run-time behaviour. ,"More confusing than I intended...  With the current kernel and headers a 'new program' (one that needs the new options) will fail to run on an old kernel - which is good. However a recompilation of an 'old program' (that doesn't use the new options) will also fail to run on an old kernel - which is bad.  Changing the kernel to ignore extra events flags breaks the 'new' program.  Versioning the structure now (even though it should have been done earlier) won't change the behaviour of existing binaries.  However a recompilation of an 'old' program would use the 'old' structure and work on old kernels. Attempts to recompile a 'new' program will fail - until the structure name (or some #define to enable the extra fields) is changed.  Breaking compilations is much better than unexpected run-time behaviour.  I disagree with this, at least as a unilateral statement.  I would assert that an old program, within the constraints of the issue being discussed here, will run perfectly well, when built and run against a new kernel.
At issue is the size of the structure sctp_event_subscribe, and the fact that in several instances over the last few years, its been extended to be larger and encompass more events to subscribe to. Nominally an application will use this structure (roughly) as follows. Assume this code will be built and run against kernel versions A and B, in which:
A) has a struct with a size of 9 bytes
B) has a struct with a size of 10 bytes (due to the added
field)
That gives us 4 cases to handle
1) Application build against kernel A and run on kernel A.  This works fine, the sizes of the struct in question will always match
2) Application is built against kernel A and run on kernel B.  In this case, everything will work because the application passes a buffer of size 9, and the kernel accepts it, because it allows for buffers to be shorter than the current struct sctp_event_subscribe size. The kernel simply operates on the options available in the buffer.  The application is none the wiser, because it has no knoweldge of the new option, nor should it because it was built against kernel A, that never offered that option
3) Application is built against kernel B and run on kernel B.  This works fine for the same reason as (1).
4) Application is built against kernel B and run on kernel A.  This will break because the application is passing a buffer that is larger than what the kernel expects, and rightly so.   The application is passing in a buffer that is incompatible with what the running kernel expects.

We could look into ways in which to detect the cases in which this might be 'ok', but I don't see why we should bother, because at some point its still an error to pass in an incompatible buffer.  In my mind this is no different than trying to run a program that allocates hugepages on a kernel that doesn't support hugepages (just to make up an example).  Applications built against newer kernel can't expect all the features/semantics/etc to be identical to older kernels.

It shouldn't.  Assuming you have a program built against headers from kernel B (above), if you set a field in the structure that only exists in kernel B, and try to run it on kernel A, you will get an EINVAL return, which is correct behavior because you are attempting to deliver information to the kernel that kernel A (the running kernel) doesn't know about.  Thats correct behavior. I won't disagree about the niceness of versioning, but that ship has sailed.To be clear,  this is situation (1) above, and yeah, running on the kernel you built your application against should always work from a compatibility standpoint. Yes, but this is alawys the case for structures that change.  If you have an application built against kernel (B), and uses structure fields that only exist in that version of the kernel (and not earlier) will fail to compile when built against kernel (A) headers, and thats expected.  This happens with any kernel api that exists in a newer kernel but not an older kernel. Any time you make a system call to the kernel, you have to be prepared to handle the resulting error condition, thats not unexpected.  To assume that a system call will always work is bad programming practice.",Neil Horman,nhorman@tuxdriver.com,1,0,4231,0.9214208826695371,1.0,0.038461538461538464,0.5098039215686274,0,0.16666666666666666,0.8333333333333334,0.0,0.16666666666666666
160,541450,544269,uncivil,"What a complete mess we have here. Use new socket option numbers next time, do not change the size and/or layout of existing socket options. This whole thread, if you read it, is basically ""if we compatability this way, that breaks, and if we do compatability this other way oh shit this other thing doesn't work."" I think we really need to specifically check for the difference sizes that existed one by one, clear out the part not given by the user, and backport this as far back as possible in a way that in the older kernels we see if the user is actually trying to use the new features and if so error out. Which, btw, is terrible behavior.  Newly compiled apps should work on older kernels if they don't try to use the new features, and if they can the ones that want to try to use the new features should be able to fall back when that feature isn't available in a non-ambiguous and precisely defined way. The fact that the use of the new feature is hidden in the new structure elements is really rotten. This patch, at best, needs some work and definitely a longer and more detailed commit message.",543076,uncivil,"I disagree with this, at least as a unilateral statement.  I would assert that an old program, within the constraints of the issue being discussed here, will run perfectly well, when built and run against a new kernel.  At issue is the size of the structure sctp_event_subscribe, and the fact that in several instances over the last few years, its been extended to be larger and encompass more events to subscribe to.  Nominally an application will use this structure (roughly) as follows:  Assume this code will be built and run against kernel versions A and B, in which: A) has a struct sctp_event_subscribe with a size of 9 bytes B) has a struct sctp_event_subscribe with a size of 10 bytes (due to the added field sctp_sender_dry_event)  That gives us 4 cases to handle  1) Application build against kernel A and run on kernel A.  This works fine, the sizes of the struct in question will always match  2) Application is built against kernel A and run on kernel B.  In this case, everything will work because the application passes a buffer of size 9, and the kernel accepts it, because it allows for buffers to be shorter than the current struct sctp_event_subscribe size. The kernel simply operates on the options available in the buffer.  The application is none the wiser, because it has no knoweldge of the new option, nor should it because it was built against kernel A, that never offered that option  3) Application is built against kernel B and run on kernel B.  This works fine for the same reason as (1).  4) Application is built against kernel B and run on kernel A.  This will break because the application is passing a buffer that is larger than what the kernel expects, and rightly so.   The application is passing in a buffer that is incompatible with what the running kernel expects.  We could look into ways in which to detect the cases in which this might be 'ok', but I don't see why we should bother, because at some point its still an error to pass in an incompatible buffer.  In my mind this is no different than trying to run a program that allocates hugepages on a kernel that doesn't support hugepages (just to make up an example).  Applications built against newer kernel can't expect all the features/semantics/etc to be identical to older kernels.  It shouldn't.  Assuming you have a program built against headers from kernel B (above), if you set a field in the structure that only exists in kernel B, and try to run it on kernel A, you will get an EINVAL return, which is correct behavior because you are attempting to deliver information to the kernel that kernel A (the running kernel) doesn't know about.  Thats correct behavior.  I won't disagree about the niceness of versioning, but that ship has sailed.  To be clear,  this is situation (1) above, and yeah, running on the kernel you built your application against should always work from a compatibility standpoint.   Yes, but this is alawys the case for structures that change.  If you have an application built against kernel (B), and uses structure fields that only exist in that version of the kernel (and not earlier) will fail to compile when built against kernel (A) headers, and thats expected.  This happens with any kernel api that exists in a newer kernel but not an older kernel.  Any time you make a system call to the kernel, you have to be prepared to handle the resulting error condition, thats not unexpected.  To assume that a system call will always work is bad programming practice.  ","I disagree with this, at least as a unilateral statement.  I would assert that an old program, within the constraints of the issue being discussed here, will run perfectly well, when built and run against a new kernel.  At issue is the size of the structure sctp_event_subscribe, and the fact that in several instances over the last few years, its been extended to be larger and encompass more events to subscribe to.  Nominally an application will use this structure (roughly) as follows:  Assume this code will be built and run against kernel versions A and B, in which: A) has a struct sctp_event_subscribe with a size of 9 bytes B) has a struct sctp_event_subscribe with a size of 10 bytes (due to the added field sctp_sender_dry_event)  That gives us 4 cases to handle  1) Application build against kernel A and run on kernel A.  This works fine, the sizes of the struct in question will always match  2) Application is built against kernel A and run on kernel B.  In this case, everything will work because the application passes a buffer of size 9, and the kernel accepts it, because it allows for buffers to be shorter than the current struct sctp_event_subscribe size. The kernel simply operates on the options available in the buffer.  The application is none the wiser, because it has no knoweldge of the new option, nor should it because it was built against kernel A, that never offered that option  3) Application is built against kernel B and run on kernel B.  This works fine for the same reason as (1).  4) Application is built against kernel B and run on kernel A.  This will break because the application is passing a buffer that is larger than what the kernel expects, and rightly so.   The application is passing in a buffer that is incompatible with what the running kernel expects.  We could look into ways in which to detect the cases in which this might be 'ok', but I don't see why we should bother, because at some point its still an error to pass in an incompatible buffer.  In my mind this is no different than trying to run a program that allocates hugepages on a kernel that doesn't support hugepages (just to make up an example).  Applications built against newer kernel can't expect all the features/semantics/etc to be identical to older kernels.  It shouldn't.  Assuming you have a program built against headers from kernel B (above), if you set a field in the structure that only exists in kernel B, and try to run it on kernel A, you will get an EINVAL return, which is correct behavior because you are attempting to deliver information to the kernel that kernel A (the running kernel) doesn't know about.  Thats correct behavior.  I won't disagree about the niceness of versioning, but that ship has sailed.  To be clear,  this is situation (1) above, and yeah, running on the kernel you built your application against should always work from a compatibility standpoint.   Yes, but this is alawys the case for structures that change.  If you have an application built against kernel (B), and uses structure fields that only exist in that version of the kernel (and not earlier) will fail to compile when built against kernel (A) headers, and thats expected.  This happens with any kernel api that exists in a newer kernel but not an older kernel.  Any time you make a system call to the kernel, you have to be prepared to handle the resulting error condition, thats not unexpected.  To assume that a system call will always work is bad programming practice.   What a complete mess we have here. Use new socket option numbers next time, do not change the size and/or layout of existing socket options. This whole thread, if you read it, is basically ""if we compatability this way, that breaks, and if we do compatability this other way oh shit this other thing doesn't work."" I think we really need to specifically check for the difference sizes that existed one by one, clear out the part not given by the user, and backport this as far back as possible in a way that in the older kernels we see if the user is actually trying to use the new features and if so error out. Which, btw, is terrible behavior.  Newly compiled apps should work on older kernels if they don't try to use the new features, and if they can the ones that want to try to use the new features should be able to fall back when that feature isn't available in a non-ambiguous and precisely defined way. The fact that the use of the new feature is hidden in the new structure elements is really rotten. This patch, at best, needs some work and definitely a longer and more detailed commit message.",David Miller,davem@davemloft.net,1,0,4604,1.0,1.0,0.125,0.27450980392156865,0,0.5,0.5,0.16666666666666666,0.0
161,546823,547238,uncivil,Looking more flexible does not make it more correct.,547224,technical,Basic C programming course:   The prototype must be available before the declaration of the global  function.  Oh well....,Basic C programming course:   The prototype must be available before the declaration of the global  function.  Oh well.... Looking more flexible does not make it more correct.,Thomas Gleixner,tglx@linutronix.de,1,0,175,1.0,1.0,1.0,1.0,0,0.0,0.0,0.0,0.0
163,72369,470502,uncivil,"I mean the level of a resource in IOMEM tree (the one that's printed from here). 1-st level means its parent is root and so on. If it's not a problem anymore IIUC, can we revert the change as it still breaks for the reasons I described above? Nothing prevents - true, but that's plainly wrong from OS point of view to grab physical ranges for something without knowing what's actually behind on that platform. I think we shouldn't consider this as a valid thing to do and don't try to workaround initially incorrect code.",470438,technical,"What do you mean by 1st and 2nd level?     Pretty much. (3) is true in the sense that memory is first allocated from hostmem_resource (which is non-dom0 RAM).    Not anymore, as far as that particular commit is concerned, but that's because of this, (x86/PCI: Move and shrink AMD 64-bit window to avoid conflict"") which was introduced after balloon patch. IIRC there were some issues with unrelated to balloon.    The concern is that in principle nothing prevents someone else to do exact same thing this commit did, which is grab something from right above end of RAM as the kernel sees it. And that can be done at any point.   ","What do you mean by 1st and 2nd level?     Pretty much. (3) is true in the sense that memory is first allocated from hostmem_resource (which is non-dom0 RAM).    Not anymore, as far as that particular commit is concerned, but that's because of this, (x86/PCI: Move and shrink AMD 64-bit window to avoid conflict"") which was introduced after balloon patch. IIRC there were some issues with unrelated to balloon.    The concern is that in principle nothing prevents someone else to do exact same thing this commit did, which is grab something from right above end of RAM as the kernel sees it. And that can be done at any point.    I mean the level of a resource in IOMEM tree (the one that's printed from here). 1-st level means its parent is root and so on. If it's not a problem anymore IIUC, can we revert the change as it still breaks for the reasons I described above? Nothing prevents - true, but that's plainly wrong from OS point of view to grab physical ranges for something without knowing what's actually behind on that platform. I think we shouldn't consider this as a valid thing to do and don't try to workaround initially incorrect code.",Igor Druzhinin,igor.druzhinin@citrix.com,0,0,1151,1.0,1.0,0.16666666666666666,0.16666666666666666,0,0.9970760233918129,0.0,0.0,0.0
